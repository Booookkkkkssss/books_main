{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0507cc-012d-49ec-ae0a-88088ddab247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup \n",
    "import time\n",
    "import sketch\n",
    "\n",
    "from parsel import Selector\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a8c35-1ecb-4d9d-9d35-7b24b637763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://www.goodreads.com/list/show/7.Best_Books_of_the_21st_Century?page=1'\n",
    "\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad166445-8c6c-48c3-b1d2-69997928bd26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d207b0-2587-41b8-91f6-d1b8eebc463c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "page1 = soup.find_all('a', class_='bookTitle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0019f-6f37-44de-affc-b98974fe9e41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "page1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78bfc1-956c-4553-9523-481a1efb72ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = page1[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98727d76-77a7-462f-91a8-d99b44a47288",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3ab82-9729-4c6f-8c04-aa4d7b5051e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r'\\d.*', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901bbdae-de93-452a-9637-9be5bd1e685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(page1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7814832-3232-474a-8578-af5002f67227",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ids = []\n",
    "\n",
    "for i in range(0, len(page1)):\n",
    "    \n",
    "    href = page1[i]['href']\n",
    "               \n",
    "    book_ids.append(re.findall(r'\\d.*', href))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce64b047-1ed1-471a-909e-5e54ad7750d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "book_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5481f649-17df-429f-b269-5a43b99e7112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "books = []\n",
    "\n",
    "for i in range(1, 51):\n",
    "    \n",
    "    url = f'https://www.goodreads.com/list/show/7.Best_Books_of_the_21st_Century?page={i}'\n",
    "\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    page = soup.find_all('a', class_='bookTitle')\n",
    "    \n",
    "    print(response.status_code)\n",
    "    \n",
    "    for i in range(0, len(page)):\n",
    "    \n",
    "        href = page[i]['href']\n",
    "               \n",
    "        books.append(re.findall(r'\\d.*', href))\n",
    "        \n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad2061-ba2e-4354-bcca-c2aa57e10f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8091f4-2ff7-4216-97fc-f4185015278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_5000_list = []\n",
    "\n",
    "#url = 'https://www.goodreads.com/book/show/' + book_id\n",
    "\n",
    "\n",
    "for i in range(len(books)):\n",
    "    \n",
    "    book = books[i][0]\n",
    "    \n",
    "    books_5000_list.append(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac195a5-757d-4662-a802-f370541d3c96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "books_5000_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594488b4-03bd-430f-bf2c-1de3bec9698e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(books_5000_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ecd21-6da1-4f97-984e-a0fff55156a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_2000 = books[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd228015-c7b3-4c80-97bf-f19327dadf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(books_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeeaa5e-5946-4c8b-9978-262eb0e02e92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "books_2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306244d5-d955-4dcd-a5e9-c26bc78fbb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_2000_list = []\n",
    "\n",
    "#url = 'https://www.goodreads.com/book/show/' + book_id\n",
    "\n",
    "\n",
    "for i in range(len(books_2000)):\n",
    "    \n",
    "    book = books[i][0]\n",
    "    \n",
    "    books_2000_list.append(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f8c6ff-0649-44da-8307-f46848549730",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(books_2000_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15532e11-0ebb-4dd3-a703-cfd244ccf9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"5000_book_ids.txt\", \"w\") as output:\n",
    "#    output.write(str(book_list))\n",
    "    for i in books_5000_list:\n",
    "        output.write(i + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1c6f1-b6cd-4c72-a7ac-384ac74c37ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"2000_book_ids.txt\", \"w\") as output:\n",
    "#    output.write(str(book_list))\n",
    "    for i in books_2000_list:\n",
    "        output.write(i + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1aa34-8992-4d6d-aedc-6c0eb9998d98",
   "metadata": {},
   "source": [
    "## running through gathering all of the data for one book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7d2d5-b016-469d-a21c-cd9fbbd2101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'https://www.goodreads.com/book/show/'\n",
    "\n",
    "df = pd.read_csv('2000_book_ids.txt', header= None, names = ['book_tag'])\n",
    "\n",
    "practice = base +  df['book_tag'][0]\n",
    "practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab05e3-2a8d-4fae-a325-fed5b85bc556",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(practice)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a020c6e-4a3d-448a-aca3-7a3102fadbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect = pd.DataFrame(columns = ['title','summary','year_published','author','review_count',\n",
    "                                  'number_of_ratings','length','genre','rating','list','reviews'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afb0f49-8cc5-4b92-825c-50c544c563ca",
   "metadata": {},
   "source": [
    "## getting the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061874c3-06d1-4ee6-bd43-98595e8dbf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h1', attrs={'class': 'Text Text__title1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae261df-6cd8-4f85-bcda-648d81daa62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag = soup.find('h1', attrs={'class': 'Text Text__title1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d10fcb-124f-42d8-b035-b40651006606",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag['aria-label'].split(': ')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf524a11-1f6c-4f5c-8542-f03c38168d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = title_tag['aria-label'].split(': ')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ed3a7-25a3-4af0-bb67-4cf2f9b02313",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect.loc[0, 'title'] = title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b48a51-dae1-4bbf-ae40-78ad71d64494",
   "metadata": {},
   "source": [
    "## getting the author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5400a2-a3c7-4af1-a904-ea672a40bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('span', class_ = \"ContributorLink__name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f4006-5031-4812-9917-b2e0cdf11980",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('span', class_ = \"ContributorLink__name\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c05351b-a4d9-498d-bdcf-0a1006a518aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "author = soup.find('span', class_ = \"ContributorLink__name\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2b70b9-5f7f-4645-8f51-5fa6d915dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect.loc[0, 'author'] = author"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b58109e-9b0d-42cf-9c2b-f059835b84bc",
   "metadata": {},
   "source": [
    "## average rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacd3316-fe4c-4698-a29b-8d83667c7d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('div', class_= 'RatingStatistics__rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e6b43-2fc3-4c89-87fe-b3af6afb65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('div', class_= 'RatingStatistics__rating')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d603aa32-c7c9-478b-ac28-75ab282785d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = soup.find_all('div', class_= 'RatingStatistics__rating')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50d4641-d630-4f35-baa3-d27eb890f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect.loc[0, 'rating'] = rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b943ff-db94-4bbc-a201-77d1bf27e0b9",
   "metadata": {},
   "source": [
    "## num of reviews and ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab73824-5905-4c63-8d2c-b342fcb89467",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('div', class_ = \"RatingStatistics__meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2434a063-fa77-42a9-b3a0-44af64ebb012",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = soup.find_all('div', class_ = \"RatingStatistics__meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b30de-6743-4d67-9f8d-2e3f7d8169fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_span = soup.find('span', {'data-testid': 'ratingsCount'})\n",
    "review_span = soup.find('span', {'data-testid': 'reviewsCount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47aedb5-9fe6-41b2-aee9-a2f096c6272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_text = rating_span.text.strip()\n",
    "review_text = review_span.text.strip()\n",
    "\n",
    "rating_text, review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805cfb7f-3a9e-453c-82bd-06ab600931da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_text = re.sub('[^0-9]', '', rating_text)\n",
    "review_text = re.sub('[^0-9]', '', review_text)\n",
    "rating_text , review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123acb0-533e-4bcf-823e-7632a70c97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect.loc[0, 'review_count'] = review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b3f1d-d18c-44d7-9db4-7ed77a67d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect.loc[0, 'number_of_ratings'] = rating_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fafbd9-7e85-474f-8b6a-051e178fcf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b17a24f-989d-48d5-b801-391b9739cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect = collect.drop(columns='rating_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382f18a4-d1d5-49a3-81e4-c741338a41ee",
   "metadata": {},
   "source": [
    "## summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2ab2d9-c2fd-48d5-b921-f6686495a99a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup.find_all('span', class_ = \"Formatted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3427542c-ea2b-4ee6-82a2-1d5c458ef155",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = soup.find_all('span', class_ = \"Formatted\")[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e3ee0b-0922-460b-a388-6254e0bdfcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect.loc[0, 'summary'] = summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9ac623-a2c8-4e3e-9a34-3d0390a3f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c0cd5-40eb-4b49-ade0-b7ea33b19fc9",
   "metadata": {},
   "source": [
    "## genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab93b65-a8f4-4ade-b43d-dc2ba919ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('a', class_='Button Button--tag-inline Button--small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4155cc-de2a-4f10-919f-c8c88ee369af",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('a', {'class': 'Button Button--tag-inline Button--small'}).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aadd02-806c-4e2c-a887-ed3df0255fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = soup.find('a', {'class': 'Button Button--tag-inline Button--small'}).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e44e4a-0da2-446c-aa44-cc8a5eba1776",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb0831a-16ef-4e22-a315-8c9c45ce60b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect.loc[0, 'genre'] = genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950713a7-66bb-4f41-b2c4-9e647c033fe5",
   "metadata": {},
   "source": [
    "## page count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ad6f1b-2587-4ff7-b632-208b41c46a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('p').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7558baa7-bdb6-4a17-8690-24a8177a68c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = soup.find('p').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a1d6c-2f94-4b08-9411-da99afac6177",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = re.sub('[^0-9]', '', page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8fd84-70d0-498d-96e3-a3ddea8f8cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect.loc[0, 'length'] = page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720807c8-469b-47fd-ad0f-7759b1166bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9318de-ccaa-44c7-a2e9-a84ea0cd623f",
   "metadata": {},
   "source": [
    "## publishing year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1193d-3bcf-4df7-961b-68712bd0611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(soup.find_all('p')[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf70430-a31b-4ef7-972c-6bc18430dd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = (soup.find_all('p')[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c074685-96cb-42d5-9e1b-226ef57deddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = year[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ce3af-f7a3-4f98-98eb-c2087dd01eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68225d30-fca8-4f40-8b80-674617098fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect.loc[0, 'year_published'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cd4759-ea60-43f2-b81e-83d8bb9a3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3b8640-f35f-48d0-9375-1f6d5830d607",
   "metadata": {},
   "source": [
    "## reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e49248-41b6-4ff9-81e8-6d209eafbef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup.find_all('section',class_ = \"ReviewText__content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25dce52-90d6-4884-9ae6-251df1758669",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = soup.find_all('section',class_ = \"ReviewText__content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfc552-57fb-4178-be24-a13228608b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_reviews = []\n",
    "for i in range (0,len (reviews)):\n",
    "    rev = soup.find_all('section',class_ = \"ReviewText__content\")[i].text\n",
    "    ls_reviews.append(rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daca07b-80ed-43e5-ad48-4c7c1e36b520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range (0,len(reviews)):\n",
    "    \n",
    "    print(ls_reviews[i])\n",
    "    print('\\n')\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34552014-35f3-4d54-8b4f-945fcc177cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect.loc[0, 'reviews'] = ls_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7298773-6184-4a97-b19a-7b7e4aa78659",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect = collect.drop(columns='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7542f45e-d4ad-4da3-a7f4-2a71276af5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399c56fc-30aa-49a8-afc3-30844a55d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61eb318-cb70-4cb6-b0da-35e47e09fe7e",
   "metadata": {},
   "source": [
    "## series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ccc1b8-ae8f-4537-b8d8-f5723d2716db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eedb02a-2a94-4ead-a3ec-5dfaba10f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup.find('a', {'class': 'Button Button--tag-inline Button--small'}).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb308eb0-5c2f-4ec6-a3af-419eb909bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('div', class_='WorkDetails')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33345e70-88b0-4afa-b505-67c3b1a1cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('body', {'class': 'DescListItem'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3401c8-0b83-45d3-92ea-9dd79795d34d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup.find('a')['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8543d4-6859-498a-89c6-3c5d92f2c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('dd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed3fc3-6d12-4fe4-8621-12eb6983e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7222d09-c2d2-40c3-84e9-2f53d69e03a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('fiction-and-non-fiction-top-best-sellers.csv', header= None)\n",
    "\n",
    "base = 'https://www.goodreads.com/book/show/'\n",
    "\n",
    "collect = pd.DataFrame(columns = ['title','summary','year_published','author','review_count',\n",
    "                                  'number_of_ratings','length','genre','rating','reviews'])\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "service = Service('/path/to/chromedriver') # replace with the path to your chromedriver executable\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i, item in enumerate(df['book_tag']):\n",
    "    \n",
    "    url = base + item\n",
    "    driver.get(url)\n",
    "    # Wait for the page to load\n",
    "    wait = WebDriverWait(driver, 30)\n",
    "    wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'Text__title1')))\n",
    "\n",
    "    # Convert the page source to a BeautifulSoup object\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    print(driver.execute_script('return document.readyState'))  # should print 'complete' \n",
    "    print(f'URL:              {url}')\n",
    "    # print(f'Request Response: {response.status_code}')\n",
    "    print(f'Request Number:   {counter+1}')\n",
    "    \n",
    "    #--------title-------------------------------------------\n",
    "    \n",
    "    # save to Variable\n",
    "    title_tag = soup.find('h1', attrs={'class': 'Text Text__title1'}) #.text\n",
    "    # looking at the h1 tag aria.        \n",
    "    title = title_tag['aria-label'].split(': ')[1]\n",
    "    print(f'Book Title: {title}')\n",
    "    \n",
    "    #----author-----------------------------------------------\n",
    "    \n",
    "    # find where author is stored\n",
    "    soup.find('span', class_ = \"ContributorLink__name\")\n",
    "    # save the text to a variable\n",
    "    auth = soup.find('span', class_ = \"ContributorLink__name\").text\n",
    "    print(f'Book Author: {auth}')\n",
    "    \n",
    "    #----rating-----------------------------------------------\n",
    "    \n",
    "    # \n",
    "    rating = soup.find_all('div', class_= 'RatingStatistics__rating')[0].text\n",
    "    print(f'Overall Rating: {rating}')\n",
    "    \n",
    "    #----genre------------------------------------------------\n",
    "    \n",
    "    try:\n",
    "        genre = soup.find('a', {'class': 'Button Button--tag-inline Button--small'}).get_text()\n",
    "        print(f'Genre: {genre}')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    #----rating and review counts------------------------------\n",
    "    \n",
    "    stats = soup.find_all('div', class_ = \"RatingStatistics__meta\")\n",
    "    \n",
    "    rating_span = soup.find('span', {'data-testid': 'ratingsCount'})\n",
    "    review_span = soup.find('span', {'data-testid': 'reviewsCount'})\n",
    "    \n",
    "    rating_text = rating_span.text.strip()\n",
    "    review_text = review_span.text.strip()\n",
    "    \n",
    "    rating_text = re.sub('[^0-9]', '', rating_text)\n",
    "    review_text = re.sub('[^0-9]', '', review_text)\n",
    "    print(f'Number of Ratings: {rating_text}')\n",
    "    print(f'Number of Reviews: {review_text}')\n",
    "         \n",
    "    #----summary------------------------------\n",
    "    \n",
    "    summary = soup.find_all('span', class_ = \"Formatted\")[0].text\n",
    "           \n",
    "    #----# of pages------------------------------\n",
    "    \n",
    "    page = soup.find('p').text\n",
    "    page = re.sub('[^0-9]', '', page)\n",
    "    print(f'Number of Pages: {page}')\n",
    "          \n",
    "    #--------year--------------------------\n",
    "    \n",
    "    year = (soup.find_all('p')[1].text)\n",
    "    year = year[-4:]\n",
    "    print(f'Year Published: {year}')\n",
    "    \n",
    "    #--------reviews--------------------------\n",
    "\n",
    "    # reviews = soup.find_all('section',class_ = \"ReviewText__content\")\n",
    "          \n",
    "    # ls_reviews = []\n",
    "    # for i in range (0,len (reviews)):\n",
    "    #    rev = soup.find_all('section',class_ = \"ReviewText__content\")[i].text\n",
    "    #    ls_reviews.append(rev)\n",
    "    \n",
    "    print('---------------------------------------------')\n",
    "        \n",
    "    collect.loc[counter, ['title','summary','year_published','author','review_count','number_of_ratings',\n",
    "                          'length','genre','rating']] = title, summary, year, auth, review_text, rating_text, page, genre, rating  \n",
    "    counter += 1 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70621bdd-d148-444e-a0b3-9e3ee0678f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df1.append(collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9101d-7f85-4b58-99e4-c3e03af4bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[~df['book_tag'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00112f89-cad6-47db-a320-08c9edcbd5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df1.drop_duplicates(subset='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92196364-02af-41a8-8ae9-081d4e52d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('almost_there.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f9925-0156-4b47-93cc-1618270d8a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff019de-99f0-4dfe-88be-28d49e6d585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('almost_there.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3848dfc-b8d6-4fa0-a62e-33abba790e42",
   "metadata": {},
   "source": [
    "## testing beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66de016-5ca2-4aa3-abf9-9f18aae533fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.goodreads.com/book/show/11735983-insurgent'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a96366a-5672-4de7-be59-7aa28d7a7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15d013-5e21-45ef-9806-bb51c637cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag = soup.find('h1', attrs={'class': 'Text Text__title1'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e7f3c2-f60e-4199-88e0-01a91ce4b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db3e49-e802-4123-aa06-d6d1414f20f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # looking at the h1 tag aria.\n",
    "title = title_tag['aria-label'].split(': ')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3770e35-e786-40bb-ba9c-b6b6b033a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a22274-76be-4e48-be0c-7e35d650b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ec0f0-9423-4367-9739-249ab3990766",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag = soup.find('h1', attrs={'class': 'Text Text__title1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd950f70-4366-4a21-9c33-b350ff0afb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2000_book_ids.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e9bc1-6928-46cd-8459-b23bfa0778e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b343413-c16e-4265-9484-ca5ba027a377",
   "metadata": {},
   "source": [
    "## selenium practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d2e4ce-f756-40bc-9570-b1eaa0c86cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from parsel import Selector\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5470e27e-a36c-4063-84f7-75c17ebdfb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ef3ce1-526e-4275-947b-2a814dadfe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://the-internet.herokuapp.com/login'\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "driver.find_element(By.XPATH, \"//*[@id='username']\").send_keys('tomsmith')\n",
    "driver.find_element(By.XPATH, \"//*[@id='password']\").send_keys('SuperSecretPassword!')\n",
    "driver.find_element(By.XPATH, '//*[@id=\"login\"]/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf83bb-38fb-4ab9-b7a4-3d9b7f1b877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old syntax for the above\n",
    "# driver.find_element_by_xpath('//*[@id=\"username\"]').send_keys('tomsmith')\n",
    "# driver.find_element_by_xpath('//*[@id=\"password\"]').send_keys('SuperSecretPassword!')\n",
    "# driver.find_element_by_xpath('//*[@id=\"login\"]/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf9e692-1b27-4641-a349-ddbba55674cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://the-internet.herokuapp.com/dynamic_loading/2'\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "driver.find_element(By.XPATH, '//*[@id=\"start\"]/button').click()\n",
    "#implicit wait\n",
    "driver.implicitly_wait(10)\n",
    "text = driver.find_element(By.XPATH, \"//*[@id='finish']/h4\").text\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e358b9-d4a6-4214-aebb-75fb1ffb6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba89f5ff-c853-40e0-91c0-52ac209e1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.youtube.com/@TinaHuang1/videos'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c7434b-f7ef-4e28-9eb1-f63e53e5709a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a10ca2c-1e09-4530-bbab-4586cd864faa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configure webdriver\n",
    "options = Options()\n",
    "options.headless = False  # hide GUI\n",
    "options.add_argument(\"--window-size=1920,1080\")  # set window size to native GUI size\n",
    "options.add_argument(\"start-maximized\")  # ensure window is full-screen\n",
    "...\n",
    "# configure chrome browser to not load images and javascript\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_experimental_option(\n",
    "    # this will disable image loading\n",
    "    \"prefs\", {\"profile.managed_default_content_settings.images\": 2}\n",
    ")\n",
    "...\n",
    "driver = webdriver.Chrome(options=options, chrome_options=chrome_options)\n",
    "driver.get(\"https://www.twitch.tv/directory/game/Art\")\n",
    "# wait for page to load\n",
    "element = WebDriverWait(driver=driver, timeout=5).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-target=directory-first-item]'))\n",
    ")\n",
    "print(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad5b4d-6dde-4cc6-8a73-dfd56c3245c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = Selector(text=driver.page_source)\n",
    "parsed = []\n",
    "for item in sel.xpath(\"//div[contains(@class,'tw-tower')]/div[@data-target]\"):\n",
    "    parsed.append({\n",
    "        'title': item.css('h3::text').get(),\n",
    "        'url': item.css('.tw-link::attr(href)').get(),\n",
    "        'username': item.css('.tw-link::text').get(),\n",
    "        'tags': item.css('.tw-tag ::text').getall(),\n",
    "        'viewers': ''.join(item.css('.tw-media-card-stat::text').re(r'(\\d+)')),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536194b7-4eb1-40cd-8e30-fee4aa0f845d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2504cd1-eddd-452c-95fc-692df9713ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    reviews = soup.find_all('section',class_ = \"ReviewText__content\")\n",
    "          \n",
    "    ls_reviews = []\n",
    "    for i in range (0,len (reviews)):\n",
    "        rev = soup.find_all('section',class_ = \"ReviewText__content\")[i].text\n",
    "        ls_reviews.append(rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5d207-a3a2-485a-909c-1d92f76bee20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc521ef1-d79f-4fc5-8bdb-cd1c2d83d038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collectS = pd.DataFrame(columns = ['title','summary','year_published','author','review_count','number_of_ratings','length','genre','rating','reviews'])\n",
    "\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "service = Service('/path/to/chromedriver') # replace with the path to your chromedriver executable\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "for i, item in enumerate(df['book_tag']):\n",
    "\n",
    "    print(counter)\n",
    "\n",
    "    url = base + item\n",
    "    driver.get(url)\n",
    "    # Wait for the page to load\n",
    "    wait = WebDriverWait(driver, 30)\n",
    "    wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'Text__title1')))\n",
    "\n",
    "    # Convert the page source to a BeautifulSoup object\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    print(driver.execute_script('return document.readyState'))  # should print 'complete'\n",
    "\n",
    "    #--------title-------------------------------------------\n",
    "\n",
    "    # save to Variable\n",
    "    title_tag = soup.find('h1', attrs={'class': 'Text Text__title1'})\n",
    "    # looking at the h1 tag aria.\n",
    "    title = title_tag['aria-label'].split(': ')[1]\n",
    "    print(title)\n",
    "\n",
    "    #----author-----------------------------------------------\n",
    "\n",
    "    # find where author is stored\n",
    "    soup.find('span', class_=\"ContributorLink__name\")\n",
    "    # save the text to a variable\n",
    "    auth = soup.find('span', class_=\"ContributorLink__name\").text\n",
    "    print(auth)\n",
    "\n",
    "    #----rating-----------------------------------------------\n",
    "\n",
    "    rating = soup.find_all('div', class_='RatingStatistics__rating')[0].text\n",
    "    print(rating)\n",
    "\n",
    "    #----rating and review counts------------------------------\n",
    "\n",
    "    stats = soup.find_all('div', class_=\"RatingStatistics__meta\")\n",
    "\n",
    "    rating_span = soup.find('span', {'data-testid': 'ratingsCount'})\n",
    "    review_span = soup.find('span', {'data-testid': 'reviewsCount'})\n",
    "\n",
    "    rating_text = rating_span.text.strip()\n",
    "    review_text = review_span.text.strip()\n",
    "\n",
    "    rating_text = re.sub('[^0-9]', '', rating_text)\n",
    "    review_text = re.sub('[^0-9]', '', review_text)\n",
    "    print(f'{rating_text} , {review_text}')\n",
    "\n",
    "    #----summary------------------------------\n",
    "    summary = soup.find_all('span', class_=\"Formatted\")[0].text\n",
    "\n",
    "    #----# of pages------------------------------\n",
    "    page = soup.find('p').text\n",
    "    page = re.sub('[^0-9]', '', page)\n",
    "    print(page)\n",
    "\n",
    "    #--------year--------------------------\n",
    "    year = (soup.find_all('p')[1].text)\n",
    "    year = year[-4:]\n",
    "    print(year)\n",
    "\n",
    "    #--------genre--------------------------\n",
    "    try:\n",
    "        genre = soup.find('a', {'class': 'Button Button--tag-inline Button--small'}).get_text()\n",
    "        print(genre)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    #--------reviews--------------------------\n",
    "    # reviews = soup.find_all('section', class_=\"ReviewText__content\")\n",
    "\n",
    "    # ls_reviews = []\n",
    "    # for i in range(0, len(reviews)):\n",
    "    #    rev = reviews[i].text  # using `reviews` instead of `soup`\n",
    "    #    ls_reviews.append(rev)\n",
    "\n",
    "\n",
    "    print('\\n')\n",
    "    print(counter)\n",
    "    \n",
    "    collectS.loc[counter, ['title', 'summary', 'year_published', 'author', 'review_count', 'number_of_ratings', 'length', 'genre', 'rating', 'reviews']] = title, summary, year, auth, review_text, rating_text, page, genre, rating, ls_reviews\n",
    "    counter = counter + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d741f66-8ca1-4616-99a7-d7ee8b70de9f",
   "metadata": {},
   "source": [
    "## gathering the data into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4ec484-1706-4164-8255-2093d2ef879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = pd.read_csv('first_207_in_books.csv')\n",
    "#df2 = pd.read_csv('second_149_in_books.csv')\n",
    "#df3 = pd.read_csv('third_45_in_books.csv')\n",
    "#df4 = pd.read_csv('fourth_102_in_books.csv')\n",
    "#df5 = pd.read_csv('fifth_375_in_books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f2ae1-790f-4041-9907-1f969b533473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df6 = pd.read_csv('sixth_355_in_books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4dcf0f-a51d-42e3-8fea-098e47c61f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1 = df_1.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab69a4d3-7d59-438e-9053-ee004f89c782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1 = df_1.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11105bc4-d62b-4d08-a508-53796dc7b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1 = df_1.append(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9632d27f-8650-4ec0-9c22-9670f8c280a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1 = df_1.append(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f881efa6-dac4-485e-a3bf-1be43d60e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1 = df_1.append(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f46df-9e75-4384-977f-da43860a12b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1 = df_1.append(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730fb918-6369-4819-a0f4-f0fb3f7136e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1 = df_1.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdac025-7200-4093-9091-0f3689d56024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1['title'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b0b825-7f1c-4279-b5cf-b3f32505e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df_1.drop_duplicates(subset='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19964a2-1cfb-4adb-bd0f-ba7b1aabbf3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53eccd9-86b7-4024-9aa4-7a5726e2866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a008cc-d435-48dc-a6bf-7157e81d9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df1.drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab52d7f-df7b-46ec-9797-8daeba681880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst = df1['genre'].value_counts().tail(65).index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab6c72-a3e7-4244-ad56-d4f3911bf36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df1[~df1['genre'].isin(lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084fd24-7d38-4165-9079-195902d11412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab019688-876c-42c5-b962-179ca2ea16c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.to_csv('almost_there.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdba1c12-8c61-4638-9cbc-07c63dc8d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69bff37-46cf-4fe2-a3d4-440d6edabbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('almost_there.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4724e3-6534-4003-a32d-7e4c3c792bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f41003-4327-4026-a008-7327cb5f8a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd082e-22f1-4665-8b41-673aa7ef7bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c262618-6839-48cb-8cb2-9721b25fd04f",
   "metadata": {},
   "source": [
    "## Creating a useable function from a combo of the above loop and Manny's selenium function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6565aa-4b32-4b2b-93a6-a5da3df47631",
   "metadata": {},
   "source": [
    "### But first, creating the function to get the urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d2acb3-73ba-4841-aee9-f7e7b3309769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_urls(filename, rng=15):\n",
    "    '''\n",
    "    This function will take in an optional range and scrape and then format the url of a\n",
    "    books page to be input into a file to use for further scraping. Needs additional work to get it to work in a more universal way, \n",
    "    but functions as is. Need to edit function url for each different web page currently.\n",
    "    '''\n",
    "    books = []\n",
    "    # initial loop to gather the data from Goodreads\n",
    "    for i in range(1, rng):\n",
    "        # The url where the books are gathered. This is the part that needs tweaking so that the function can just take in a url. \n",
    "        # Need to research how to format the string properly.\n",
    "        url = f'https://www.goodreads.com/list/show/264.Books_That_Everyone_Should_Read_At_Least_Once?page={i}'\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')  \n",
    "        page = soup.find_all('a', class_='bookTitle')\n",
    "        # Checking the status code as function runs\n",
    "        print(response.status_code)\n",
    "        # Appending the gathered data into a list of lists\n",
    "        for i in range(0, len(page)):\n",
    "            # Referencing the specific section of the hmtl to find the url\n",
    "            href = page[i]['href']\n",
    "            # Appending the url onto the list after shaving off the unneeded part with Regex   \n",
    "            books.append(re.findall(r'\\d.*', href))\n",
    "            # books.append(href)\n",
    "        # A short sleep timer so Goodreads doesn't get upset\n",
    "        time.sleep(3)        \n",
    "    books_list = []\n",
    "    #url = 'https://www.goodreads.com/book/show/' + book_id\n",
    "    # Short loop to turn the above created list of lists into a list for better formatting\n",
    "    for i in range(len(books)):\n",
    "        book = books[i][0]\n",
    "        books_list.append(book)\n",
    "    # Creating/Updating a file formatted properly for use later    \n",
    "    with open(filename, \"w\") as output:\n",
    "    # output.write(str(books_list))\n",
    "        for i in books_list:\n",
    "            output.write(i + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b472ca17-7515-4e5c-b311-d47b57dfd5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_book_urls('book_urls.txt', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e4866d-606a-405f-a5b2-db0fc3a2eb04",
   "metadata": {},
   "source": [
    "### From here, functionalizing each piece of info needed to be scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29c38f-8802-494c-adcf-a1a100c74b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles(df, link_col):\n",
    "    \n",
    "    options = Options()\n",
    "    options.headless = True\n",
    "    service = Service('/path/to/chromedriver') # replace with the path to your chromedriver executable\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    \n",
    "    base = 'https://www.goodreads.com/book/show/'\n",
    "    \n",
    "    url = base + item\n",
    "    # Wait for page to load\n",
    "    wait = WebDriverWait(driver, 30)\n",
    "    wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'Text__title1')))\n",
    "        \n",
    "    # Convert the page source to a Beautiful Soup object\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "    print(driver.execute_script('return document.readyState'))  # Should print 'complete' \n",
    "    # Save to variable\n",
    "    title_tag = soup.find('h1', attrs={'class': 'Text Text__title1'}) #.text\n",
    "    # Looking at the h1 tag aria.        \n",
    "    title = title_tag['aria-label'].split(': ')[1]\n",
    "    print(f'URL:              {url}')\n",
    "    print(f'Book Title:       {title}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555cbd3-0687-432a-bfcd-185e91eee138",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('book_urls.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0a1769-4503-4576-be28-9b23b9b4484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={0:'links'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60069a8f-82f2-4652-a7f6-b4577a699663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b6a7c4-db3a-4631-adcd-f35b74906e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'https://www.goodreads.com/book/show/'\n",
    "\n",
    "df = pd.read_csv('2000_book_ids.txt', header= None, names = ['book_tag'])\n",
    "\n",
    "practice = base +  df['book_tag'][0]\n",
    "practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff97e1-eb07-4168-a9e9-37ec19fa6679",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(practice)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78345186-a044-46ad-86d1-06999fc4fe74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a76b9-8fc5-4890-8b63-37be26305c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect = pd.DataFrame(columns = ['title','summary','year_published','author','review_count',\n",
    "                                  'number_of_ratings','length','genre','rating','list','reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5214b-012d-4ab2-9eda-1ed17d11c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h1', attrs={'class': 'Text Text__title1'})\n",
    "\n",
    "title_tag = soup.find('h1', attrs={'class': 'Text Text__title1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064ff8d-ad5c-4ffc-aa4a-7b149c17e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = title_tag['aria-label'].split(': ')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846fffaf-d124-40d0-9bb7-ecf278f943a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418f5e6f-2fcc-4719-a551-cd5c9ade10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect.loc[0, 'title'] = title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f898f8-a111-4e69-af46-65767f9bc4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f0fb4-e37f-4255-b1bc-ae1b19454f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8a6d6a-bd93-413f-850e-76e85d3cc39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c895684-f427-4192-949a-4f4528ceb1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d7d6f-fdf7-482c-8be2-1f708032d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bad_books_links(df):\n",
    "    # Check if links.txt exists, read the last link as the starter_link\n",
    "    if os.path.exists(\"links.txt\"):\n",
    "        with open(\"links.txt\", \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            starter_link = lines[-1].strip()\n",
    "    else:\n",
    "        starter_link = \"https://www.goodreads.com/book/show/3450744-nudge\"\n",
    "\n",
    "    # Add new column called 'link' to df\n",
    "    df['link'] = \"\"\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    # Open a text file for writing\n",
    "    with open(\"links.txt\", \"a\") as file:\n",
    "\n",
    "        # If row_index.txt exists, read the last index and start from the next row\n",
    "        if os.path.exists(\"row_index.txt\"):\n",
    "            with open(\"row_index.txt\", \"r\") as index_file:\n",
    "                last_index = int(index_file.read().strip())\n",
    "                start_index = last_index + 1\n",
    "        else:\n",
    "            start_index = 0\n",
    "\n",
    "        for index, row in df.iloc[start_index:].iterrows():\n",
    "            # loading initial webpage\n",
    "            driver.get(starter_link)\n",
    "\n",
    "            # current row content to use in query\n",
    "            title = row['Title']\n",
    "            author = row['Author']\n",
    "\n",
    "            try:\n",
    "                # add wait for page to finish loading\n",
    "                WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"Header\"]/div[2]/div[2]/section/form/input[1]')))\n",
    "\n",
    "                # search GoodReads for \"title author\"\n",
    "                search_bar = driver.find_element_by_xpath('//*[@id=\"Header\"]/div[2]/div[2]/section/form/input[1]')\n",
    "                search_bar.send_keys(title + \" \" + author)\n",
    "                search_bar.submit()\n",
    "\n",
    "                # add wait for page to finish loading\n",
    "                WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CLASS_NAME, 'bookTitle')))\n",
    "\n",
    "                # extract 1st search result link from page\n",
    "                links = driver.find_element_by_class_name('bookTitle')\n",
    "                row_value = links.get_attribute('href')\n",
    "\n",
    "                # append value to new column called 'link'\n",
    "                df.at[index, 'link'] = row_value\n",
    "\n",
    "                # Update starter_link\n",
    "                starter_link = row_value\n",
    "\n",
    "                # Write the row_value to the text file\n",
    "                file.write(f\"{row_value}\\n\")\n",
    "\n",
    "            except:\n",
    "                # If no search results or timeout, continue to the next row\n",
    "                continue\n",
    "\n",
    "            finally:\n",
    "                # Save current row index to row_index.txt\n",
    "                with open(\"row_index.txt\", \"w\") as index_file:\n",
    "                    index_file.write(str(index))\n",
    "\n",
    "    driver.quit()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39b690-be02-43a7-9135-af60174a1549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99791edb-35a3-427b-b7b2-e00cd3c55742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf91ac-8f43-41b6-9a6c-ef96d5397ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_info(filename, col):\n",
    "    \n",
    "    df = pd.read_csv(filename, header= None, names = [col])\n",
    "\n",
    "    base = 'https://www.goodreads.com/book/show/'\n",
    "\n",
    "    collect = pd.DataFrame(columns = ['title','summary','year_published','author','review_count',\n",
    "                                  'number_of_ratings','length','genre','rating','reviews'])\n",
    "\n",
    "    options = Options()\n",
    "    options.headless = True\n",
    "    service = Service('/path/to/chromedriver') # replace with the path to your chromedriver executable\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for i, item in enumerate(df['book_tag'][375:]):\n",
    "    \n",
    "        url = base + item\n",
    "        driver.get(url)\n",
    "        # Wait for the page to load\n",
    "        wait = WebDriverWait(driver, 30)\n",
    "        wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'Text__title1')))\n",
    "\n",
    "        # Convert the page source to a BeautifulSoup object\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        print(driver.execute_script('return document.readyState'))  # should print 'complete' \n",
    "        print(f'URL:              {url}')\n",
    "        # print(f'Request Response: {response.status_code}')\n",
    "        print(f'Request Number:   {counter+1}')\n",
    "    \n",
    "        #--------title-------------------------------------------\n",
    "    \n",
    "        # save to Variable\n",
    "        title_tag = soup.find('h1', attrs={'class': 'Text Text__title1'}) #.text\n",
    "        # looking at the h1 tag aria.        \n",
    "        title = title_tag['aria-label'].split(': ')[1]\n",
    "        print(f'Book Title: {title}')\n",
    "    \n",
    "        #----author-----------------------------------------------\n",
    "    \n",
    "        # find where author is stored\n",
    "        soup.find('span', class_ = \"ContributorLink__name\")\n",
    "        # save the text to a variable\n",
    "        auth = soup.find('span', class_ = \"ContributorLink__name\").text\n",
    "        print(f'Book Author: {auth}')\n",
    "    \n",
    "        #----rating-----------------------------------------------\n",
    "    \n",
    "        # \n",
    "        rating = soup.find_all('div', class_= 'RatingStatistics__rating')[0].text\n",
    "        print(f'Overall Rating: {rating}')\n",
    "    \n",
    "        #----genre------------------------------------------------\n",
    "    \n",
    "        try:\n",
    "            genre = soup.find('a', {'class': 'Button Button--tag-inline Button--small'}).get_text()\n",
    "            print(f'Genre: {genre}')\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "        #----rating and review counts------------------------------\n",
    "    \n",
    "        stats = soup.find_all('div', class_ = \"RatingStatistics__meta\")\n",
    "    \n",
    "        rating_span = soup.find('span', {'data-testid': 'ratingsCount'})\n",
    "        review_span = soup.find('span', {'data-testid': 'reviewsCount'})\n",
    "    \n",
    "        rating_text = rating_span.text.strip()\n",
    "        review_text = review_span.text.strip()\n",
    "    \n",
    "        rating_text = re.sub('[^0-9]', '', rating_text)\n",
    "        review_text = re.sub('[^0-9]', '', review_text)\n",
    "        print(f'Number of Ratings: {rating_text}')\n",
    "        print(f'Number of Reviews: {review_text}')\n",
    "         \n",
    "        #----summary------------------------------\n",
    "    \n",
    "        summary = soup.find_all('span', class_ = \"Formatted\")[0].text\n",
    "           \n",
    "        #----# of pages------------------------------\n",
    "    \n",
    "        page = soup.find('p').text\n",
    "        page = re.sub('[^0-9]', '', page)\n",
    "        print(f'Number of Pages: {page}')\n",
    "          \n",
    "        #--------year--------------------------\n",
    "    \n",
    "        year = (soup.find_all('p')[1].text)\n",
    "        year = year[-4:]\n",
    "        print(f'Year Published: {year}')\n",
    "    \n",
    "        #--------reviews--------------------------\n",
    "\n",
    "        # reviews = soup.find_all('section',class_ = \"ReviewText__content\")\n",
    "          \n",
    "        # ls_reviews = []\n",
    "        # for i in range (0,len (reviews)):\n",
    "        #    rev = soup.find_all('section',class_ = \"ReviewText__content\")[i].text\n",
    "        #    ls_reviews.append(rev)\n",
    "    \n",
    "        print('---------------------------------------------')\n",
    "        \n",
    "        collect.loc[counter, ['title','summary','year_published','author','review_count','number_of_ratings',\n",
    "                          'length','genre','rating']] = title, summary, year, auth, review_text, rating_text, page, genre, rating  \n",
    "        counter += 1 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d012d0-5ece-430b-a56f-18a1a55e8dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e4cc8ef-3433-47e9-9fbd-40bada3d778a",
   "metadata": {},
   "source": [
    "### subsetting each part of the loop into a function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
