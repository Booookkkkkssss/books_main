{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "641a0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import prepare as pr \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ce7413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pr.prep_data('all_books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b498658",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98f8b250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>year_published</th>\n",
       "      <th>author</th>\n",
       "      <th>review_count</th>\n",
       "      <th>number_of_ratings</th>\n",
       "      <th>length</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_summary</th>\n",
       "      <th>successful</th>\n",
       "      <th>lemmatized_summary</th>\n",
       "      <th>neg</th>\n",
       "      <th>neutral</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice's Adventures in Wonderland: A Pop-Up Ada...</td>\n",
       "      <td>Alice's Adventures in Wonderland is Robert Sa...</td>\n",
       "      <td>2003</td>\n",
       "      <td>Robert Sabuda</td>\n",
       "      <td>157</td>\n",
       "      <td>26214</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.34</td>\n",
       "      <td>[]</td>\n",
       "      <td>alice's adventures in wonderland a popup adapt...</td>\n",
       "      <td>alice's adventures in wonderland is robert sa...</td>\n",
       "      <td>False</td>\n",
       "      <td>alice adventure wonderland robert sabuda amaze...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.9718</td>\n",
       "      <td>very positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Just Me in the Tub</td>\n",
       "      <td>Taking a bath is a big job. Mercer Mayer's fam...</td>\n",
       "      <td>1994</td>\n",
       "      <td>Gina Mayer</td>\n",
       "      <td>62</td>\n",
       "      <td>19212</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Childrens</td>\n",
       "      <td>4.25</td>\n",
       "      <td>[]</td>\n",
       "      <td>just me in the tub</td>\n",
       "      <td>taking a bath is a big job. mercer mayer's fam...</td>\n",
       "      <td>False</td>\n",
       "      <td>take bath big job mercer mayer famous little c...</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>very positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Rats in the Walls</td>\n",
       "      <td>\"The Rats in the Walls\" is a short story by H....</td>\n",
       "      <td>1924</td>\n",
       "      <td>H.P. Lovecraft</td>\n",
       "      <td>531</td>\n",
       "      <td>9155</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Horror</td>\n",
       "      <td>4.01</td>\n",
       "      <td>[]</td>\n",
       "      <td>the rats in the walls</td>\n",
       "      <td>the rats in the walls is a short story by h.p....</td>\n",
       "      <td>False</td>\n",
       "      <td>rat wall short lovecraft write augustseptember...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.1779</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ralph S. Mouse by Beverly Cleary: Teacher Guide</td>\n",
       "      <td>NOTE: This is not the book by Beverly Cleary, ...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gloria Levine</td>\n",
       "      <td>50</td>\n",
       "      <td>15889</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Childrens</td>\n",
       "      <td>4.00</td>\n",
       "      <td>[]</td>\n",
       "      <td>ralph s. mouse by beverly cleary teacher guide</td>\n",
       "      <td>note this is not the book by beverly cleary, b...</td>\n",
       "      <td>False</td>\n",
       "      <td>note beverly cleary guide teacher accompany ti...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>very positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Hill We Climb: An Inaugural Poem for the C...</td>\n",
       "      <td>Librarian Note: Alternative Cover Edition for ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Amanda Gorman</td>\n",
       "      <td>2720</td>\n",
       "      <td>28125</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>4.57</td>\n",
       "      <td>[]</td>\n",
       "      <td>the hill we climb an inaugural poem for the co...</td>\n",
       "      <td>librarian note alternative cover edition for t...</td>\n",
       "      <td>False</td>\n",
       "      <td>librarian note alternative cover isbn january ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>very positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>The Ink Black Heart</td>\n",
       "      <td>The latest installment in the highly acclaimed...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Robert Galbraith</td>\n",
       "      <td>6016</td>\n",
       "      <td>54070</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>4.12</td>\n",
       "      <td>[]</td>\n",
       "      <td>the ink black heart</td>\n",
       "      <td>the latest installment in the highly acclaimed...</td>\n",
       "      <td>False</td>\n",
       "      <td>latest installment highly acclaim internationa...</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.9437</td>\n",
       "      <td>very negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>The Fiery Cross</td>\n",
       "      <td>The year is 1771, and war is coming. Jamie Fra...</td>\n",
       "      <td>2001</td>\n",
       "      <td>Diana Gabaldon</td>\n",
       "      <td>8425</td>\n",
       "      <td>199251</td>\n",
       "      <td>1443.0</td>\n",
       "      <td>Historical Fiction</td>\n",
       "      <td>4.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the fiery cross</td>\n",
       "      <td>the year is 1771, and war is coming. jamie fra...</td>\n",
       "      <td>False</td>\n",
       "      <td>year war come jamie frasers wife tell little w...</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.7239</td>\n",
       "      <td>very negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3852</th>\n",
       "      <td>War and Peace</td>\n",
       "      <td>Tolstoy's epic masterpiece intertwines the liv...</td>\n",
       "      <td>1869</td>\n",
       "      <td>Leo Tolstoy</td>\n",
       "      <td>15480</td>\n",
       "      <td>308202</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>war and peace</td>\n",
       "      <td>tolstoy's epic masterpiece intertwines the liv...</td>\n",
       "      <td>False</td>\n",
       "      <td>tolstoy epic masterpiece intertwine life priva...</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>very positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3853</th>\n",
       "      <td>The Norton Anthology of English Literature, Vo...</td>\n",
       "      <td>Firmly grounded by the hallmark strengths of a...</td>\n",
       "      <td>1962</td>\n",
       "      <td>M.H. Abrams</td>\n",
       "      <td>179</td>\n",
       "      <td>9045</td>\n",
       "      <td>2904.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the norton anthology of english literature, vo...</td>\n",
       "      <td>firmly grounded by the hallmark strengths of a...</td>\n",
       "      <td>False</td>\n",
       "      <td>firmly ground hallmark strength norton antholo...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.8176</td>\n",
       "      <td>very positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854</th>\n",
       "      <td>In Search of Lost Time</td>\n",
       "      <td>On the surface a traditional \"Bildungsroman\" d...</td>\n",
       "      <td>1927</td>\n",
       "      <td>Marcel Proust</td>\n",
       "      <td>767</td>\n",
       "      <td>11725</td>\n",
       "      <td>4211.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.35</td>\n",
       "      <td>[]</td>\n",
       "      <td>in search of lost time</td>\n",
       "      <td>on the surface a traditional bildungsroman des...</td>\n",
       "      <td>False</td>\n",
       "      <td>surface traditional bildungsroman describe nar...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.8145</td>\n",
       "      <td>very negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3665 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     Alice's Adventures in Wonderland: A Pop-Up Ada...   \n",
       "1                                    Just Me in the Tub   \n",
       "2                                 The Rats in the Walls   \n",
       "4       Ralph S. Mouse by Beverly Cleary: Teacher Guide   \n",
       "7     The Hill We Climb: An Inaugural Poem for the C...   \n",
       "...                                                 ...   \n",
       "3849                                The Ink Black Heart   \n",
       "3851                                    The Fiery Cross   \n",
       "3852                                      War and Peace   \n",
       "3853  The Norton Anthology of English Literature, Vo...   \n",
       "3854                             In Search of Lost Time   \n",
       "\n",
       "                                                summary  year_published  \\\n",
       "0      Alice's Adventures in Wonderland is Robert Sa...            2003   \n",
       "1     Taking a bath is a big job. Mercer Mayer's fam...            1994   \n",
       "2     \"The Rats in the Walls\" is a short story by H....            1924   \n",
       "4     NOTE: This is not the book by Beverly Cleary, ...            2000   \n",
       "7     Librarian Note: Alternative Cover Edition for ...            2021   \n",
       "...                                                 ...             ...   \n",
       "3849  The latest installment in the highly acclaimed...            2022   \n",
       "3851  The year is 1771, and war is coming. Jamie Fra...            2001   \n",
       "3852  Tolstoy's epic masterpiece intertwines the liv...            1869   \n",
       "3853  Firmly grounded by the hallmark strengths of a...            1962   \n",
       "3854  On the surface a traditional \"Bildungsroman\" d...            1927   \n",
       "\n",
       "                author  review_count  number_of_ratings  length  \\\n",
       "0        Robert Sabuda           157              26214    12.0   \n",
       "1           Gina Mayer            62              19212    24.0   \n",
       "2       H.P. Lovecraft           531               9155    25.0   \n",
       "4        Gloria Levine            50              15889    28.0   \n",
       "7        Amanda Gorman          2720              28125    29.0   \n",
       "...                ...           ...                ...     ...   \n",
       "3849  Robert Galbraith          6016              54070  1408.0   \n",
       "3851    Diana Gabaldon          8425             199251  1443.0   \n",
       "3852       Leo Tolstoy         15480             308202  1700.0   \n",
       "3853       M.H. Abrams           179               9045  2904.0   \n",
       "3854     Marcel Proust           767              11725  4211.0   \n",
       "\n",
       "                   genre  rating reviews  \\\n",
       "0               Classics    4.34      []   \n",
       "1              Childrens    4.25      []   \n",
       "2                 Horror    4.01      []   \n",
       "4              Childrens    4.00      []   \n",
       "7                 Poetry    4.57      []   \n",
       "...                  ...     ...     ...   \n",
       "3849             Mystery    4.12      []   \n",
       "3851  Historical Fiction    4.25     NaN   \n",
       "3852            Classics    4.15     NaN   \n",
       "3853            Classics    4.22     NaN   \n",
       "3854            Classics    4.35      []   \n",
       "\n",
       "                                          cleaned_title  \\\n",
       "0     alice's adventures in wonderland a popup adapt...   \n",
       "1                                    just me in the tub   \n",
       "2                                 the rats in the walls   \n",
       "4        ralph s. mouse by beverly cleary teacher guide   \n",
       "7     the hill we climb an inaugural poem for the co...   \n",
       "...                                                 ...   \n",
       "3849                                the ink black heart   \n",
       "3851                                    the fiery cross   \n",
       "3852                                      war and peace   \n",
       "3853  the norton anthology of english literature, vo...   \n",
       "3854                             in search of lost time   \n",
       "\n",
       "                                        cleaned_summary  successful  \\\n",
       "0      alice's adventures in wonderland is robert sa...       False   \n",
       "1     taking a bath is a big job. mercer mayer's fam...       False   \n",
       "2     the rats in the walls is a short story by h.p....       False   \n",
       "4     note this is not the book by beverly cleary, b...       False   \n",
       "7     librarian note alternative cover edition for t...       False   \n",
       "...                                                 ...         ...   \n",
       "3849  the latest installment in the highly acclaimed...       False   \n",
       "3851  the year is 1771, and war is coming. jamie fra...       False   \n",
       "3852  tolstoy's epic masterpiece intertwines the liv...       False   \n",
       "3853  firmly grounded by the hallmark strengths of a...       False   \n",
       "3854  on the surface a traditional bildungsroman des...       False   \n",
       "\n",
       "                                     lemmatized_summary    neg  neutral  \\\n",
       "0     alice adventure wonderland robert sabuda amaze...  0.000    0.627   \n",
       "1     take bath big job mercer mayer famous little c...  0.008    0.781   \n",
       "2     rat wall short lovecraft write augustseptember...  0.015    0.985   \n",
       "4     note beverly cleary guide teacher accompany ti...  0.000    0.809   \n",
       "7     librarian note alternative cover isbn january ...  0.000    0.784   \n",
       "...                                                 ...    ...      ...   \n",
       "3849  latest installment highly acclaim internationa...  0.143    0.806   \n",
       "3851  year war come jamie frasers wife tell little w...  0.130    0.798   \n",
       "3852  tolstoy epic masterpiece intertwine life priva...  0.087    0.781   \n",
       "3853  firmly ground hallmark strength norton antholo...  0.000    0.874   \n",
       "3854  surface traditional bildungsroman describe nar...  0.079    0.863   \n",
       "\n",
       "        pos  compound      sentiment  \n",
       "0     0.373    0.9718  very positive  \n",
       "1     0.211    0.9811  very positive  \n",
       "2     0.000   -0.1779       negative  \n",
       "4     0.191    0.8570  very positive  \n",
       "7     0.216    0.9690  very positive  \n",
       "...     ...       ...            ...  \n",
       "3849  0.051   -0.9437  very negative  \n",
       "3851  0.072   -0.7239  very negative  \n",
       "3852  0.132    0.7430  very positive  \n",
       "3853  0.126    0.8176  very positive  \n",
       "3854  0.058   -0.8145  very negative  \n",
       "\n",
       "[3665 rows x 19 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfe159ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b08ced",
   "metadata": {},
   "source": [
    "# Clean DataFrame for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ceea385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genre'] = df.genre.astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc5da92",
   "metadata": {},
   "source": [
    "# create dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "913d1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ready_df(df):\n",
    "    \n",
    "    # drop columns we do not want to model on\n",
    "    df = df.drop(columns= ['title','summary','year_published','author','reviews','cleaned_title','cleaned_summary'])\n",
    "    \n",
    "    # creating dummies for genre and sentient\n",
    "    df['genre'] = df.genre.astype('object')\n",
    "    dummy_df = pd.get_dummies(df[['genre','sentiment']], dummy_na=False, drop_first=[True, True])\n",
    "    \n",
    "    # add dummies to dataframe \n",
    "    df = pd.concat([df, dummy_df],axis= 1)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80bab2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ready_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20b21a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_count</th>\n",
       "      <th>number_of_ratings</th>\n",
       "      <th>length</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>successful</th>\n",
       "      <th>lemmatized_summary</th>\n",
       "      <th>neg</th>\n",
       "      <th>neutral</th>\n",
       "      <th>pos</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Short Stories</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_Travel</th>\n",
       "      <th>genre_Urban Fantasy</th>\n",
       "      <th>genre_Vampires</th>\n",
       "      <th>genre_Young Adult</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_very negative</th>\n",
       "      <th>sentiment_very positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157</td>\n",
       "      <td>26214</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.34</td>\n",
       "      <td>False</td>\n",
       "      <td>alice adventure wonderland robert sabuda amaze...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.373</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>19212</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Childrens</td>\n",
       "      <td>4.25</td>\n",
       "      <td>False</td>\n",
       "      <td>take bath big job mercer mayer famous little c...</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>531</td>\n",
       "      <td>9155</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Horror</td>\n",
       "      <td>4.01</td>\n",
       "      <td>False</td>\n",
       "      <td>rat wall short lovecraft write augustseptember...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>15889</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Childrens</td>\n",
       "      <td>4.00</td>\n",
       "      <td>False</td>\n",
       "      <td>note beverly cleary guide teacher accompany ti...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.191</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2720</td>\n",
       "      <td>28125</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>4.57</td>\n",
       "      <td>False</td>\n",
       "      <td>librarian note alternative cover isbn january ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.216</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>6016</td>\n",
       "      <td>54070</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>4.12</td>\n",
       "      <td>False</td>\n",
       "      <td>latest installment highly acclaim internationa...</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>8425</td>\n",
       "      <td>199251</td>\n",
       "      <td>1443.0</td>\n",
       "      <td>Historical Fiction</td>\n",
       "      <td>4.25</td>\n",
       "      <td>False</td>\n",
       "      <td>year war come jamie frasers wife tell little w...</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.072</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3852</th>\n",
       "      <td>15480</td>\n",
       "      <td>308202</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.15</td>\n",
       "      <td>False</td>\n",
       "      <td>tolstoy epic masterpiece intertwine life priva...</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.132</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3853</th>\n",
       "      <td>179</td>\n",
       "      <td>9045</td>\n",
       "      <td>2904.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.22</td>\n",
       "      <td>False</td>\n",
       "      <td>firmly ground hallmark strength norton antholo...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854</th>\n",
       "      <td>767</td>\n",
       "      <td>11725</td>\n",
       "      <td>4211.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.35</td>\n",
       "      <td>False</td>\n",
       "      <td>surface traditional bildungsroman describe nar...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.058</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3665 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      review_count  number_of_ratings  length               genre  rating  \\\n",
       "0              157              26214    12.0            Classics    4.34   \n",
       "1               62              19212    24.0           Childrens    4.25   \n",
       "2              531               9155    25.0              Horror    4.01   \n",
       "4               50              15889    28.0           Childrens    4.00   \n",
       "7             2720              28125    29.0              Poetry    4.57   \n",
       "...            ...                ...     ...                 ...     ...   \n",
       "3849          6016              54070  1408.0             Mystery    4.12   \n",
       "3851          8425             199251  1443.0  Historical Fiction    4.25   \n",
       "3852         15480             308202  1700.0            Classics    4.15   \n",
       "3853           179               9045  2904.0            Classics    4.22   \n",
       "3854           767              11725  4211.0            Classics    4.35   \n",
       "\n",
       "      successful                                 lemmatized_summary    neg  \\\n",
       "0          False  alice adventure wonderland robert sabuda amaze...  0.000   \n",
       "1          False  take bath big job mercer mayer famous little c...  0.008   \n",
       "2          False  rat wall short lovecraft write augustseptember...  0.015   \n",
       "4          False  note beverly cleary guide teacher accompany ti...  0.000   \n",
       "7          False  librarian note alternative cover isbn january ...  0.000   \n",
       "...          ...                                                ...    ...   \n",
       "3849       False  latest installment highly acclaim internationa...  0.143   \n",
       "3851       False  year war come jamie frasers wife tell little w...  0.130   \n",
       "3852       False  tolstoy epic masterpiece intertwine life priva...  0.087   \n",
       "3853       False  firmly ground hallmark strength norton antholo...  0.000   \n",
       "3854       False  surface traditional bildungsroman describe nar...  0.079   \n",
       "\n",
       "      neutral    pos  ...  genre_Short Stories genre_Thriller  genre_Travel  \\\n",
       "0       0.627  0.373  ...                    0              0             0   \n",
       "1       0.781  0.211  ...                    0              0             0   \n",
       "2       0.985  0.000  ...                    0              0             0   \n",
       "4       0.809  0.191  ...                    0              0             0   \n",
       "7       0.784  0.216  ...                    0              0             0   \n",
       "...       ...    ...  ...                  ...            ...           ...   \n",
       "3849    0.806  0.051  ...                    0              0             0   \n",
       "3851    0.798  0.072  ...                    0              0             0   \n",
       "3852    0.781  0.132  ...                    0              0             0   \n",
       "3853    0.874  0.126  ...                    0              0             0   \n",
       "3854    0.863  0.058  ...                    0              0             0   \n",
       "\n",
       "      genre_Urban Fantasy  genre_Vampires  genre_Young Adult  \\\n",
       "0                       0               0                  0   \n",
       "1                       0               0                  0   \n",
       "2                       0               0                  0   \n",
       "4                       0               0                  0   \n",
       "7                       0               0                  0   \n",
       "...                   ...             ...                ...   \n",
       "3849                    0               0                  0   \n",
       "3851                    0               0                  0   \n",
       "3852                    0               0                  0   \n",
       "3853                    0               0                  0   \n",
       "3854                    0               0                  0   \n",
       "\n",
       "      sentiment_neutral  sentiment_positive  sentiment_very negative  \\\n",
       "0                     0                   0                        0   \n",
       "1                     0                   0                        0   \n",
       "2                     0                   0                        0   \n",
       "4                     0                   0                        0   \n",
       "7                     0                   0                        0   \n",
       "...                 ...                 ...                      ...   \n",
       "3849                  0                   0                        1   \n",
       "3851                  0                   0                        1   \n",
       "3852                  0                   0                        0   \n",
       "3853                  0                   0                        0   \n",
       "3854                  0                   0                        1   \n",
       "\n",
       "      sentiment_very positive  \n",
       "0                           1  \n",
       "1                           1  \n",
       "2                           0  \n",
       "4                           1  \n",
       "7                           1  \n",
       "...                       ...  \n",
       "3849                        0  \n",
       "3851                        0  \n",
       "3852                        1  \n",
       "3853                        1  \n",
       "3854                        0  \n",
       "\n",
       "[3665 rows x 50 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c33b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68bc0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d037db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns= ['title','summary','year_published','author','reviews','cleaned_title','cleaned_summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "327b363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(df[['genre','sentiment']], dummy_na=False, drop_first=[True, True])\n",
    "col_list = dummy_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44797c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, dummy_df],axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf51e9",
   "metadata": {},
   "source": [
    "# split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "737ac621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ae34efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, target):\n",
    "    train, test = train_test_split(df, test_size=.2, random_state=42, stratify=df[target])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a102190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split(df,'successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "7bf063f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train =  train.drop(columns= \"successful\")\n",
    "y_train = train['successful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "dd66c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.drop(columns= \"successful\")\n",
    "y_test = test['successful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "c8838faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reset_index(drop= True)\n",
    "y_train = y_train.reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "b9ad80ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_test = x_test.reset_index(drop= True)\n",
    "y_test = y_test.reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "081047f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xandy_set(train,test):\n",
    "    \n",
    "    # creating train and test (x and y) subsets\n",
    "    X_train =  train.drop(columns= \"successful\")\n",
    "    y_train = train['successful']\n",
    "    \n",
    "    # creating train and test (x and y) subsets\n",
    "    X_test = test.drop(columns= \"successful\")\n",
    "    y_test = test['successful']\n",
    "    \n",
    "    # reset index, (no sorting or reordering)\n",
    "    X_train = X_train.reset_index(drop= True)\n",
    "    y_train = y_train.reset_index(drop= True)\n",
    "    X_test = X_test.reset_index(drop= True)\n",
    "    y_test = y_test.reset_index(drop= True)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20ef9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = Xandy_set(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50654a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "8fc5ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bd299cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(X_train, X_test):\n",
    "    \n",
    "    # create a subset of numerical column\n",
    "    xtrainnums = X_train[['review_count','number_of_ratings','length','rating']]\n",
    "    \n",
    "    number_list = ['review_count','number_of_ratings','length','rating']\n",
    "\n",
    "    # Note that we only call .fit with the training data\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    \n",
    "    # fit training data to scaler, not transforming here\n",
    "    scaler.fit(xtrainnums)\n",
    "    \n",
    "    # transform the numerical values that we want based on the trained fit scaler\n",
    "    X_train_scaled = scaler.transform(X_train[number_list])\n",
    "    X_test_scaled = scaler.transform(X_test[number_list])\n",
    "    \n",
    "    # create a dataframe\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns= [number_list])\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns= [number_list])\n",
    "    \n",
    "    \n",
    "    # add the 'neg','neutral','pos','compound' from x_train to the scaled data. reset\n",
    "    X_train_scaled[['neg','neutral','pos','compound']] = X_train[['neg','neutral','pos','compound']].reset_index(drop = True)\n",
    "    X_test_scaled[['neg','neutral','pos','compound']] = X_test[['neg','neutral','pos','compound']].reset_index(drop = True)\n",
    "\n",
    "    # create a list of the dummies \n",
    "    dummies = X_train.columns.tolist()[11:]\n",
    "    \n",
    "    # add dummies to dataframe\n",
    "    X_train_scaled = pd.concat([X_train_scaled, X_train[dummies]],axis = 1 )\n",
    "    X_test_scaled = pd.concat([X_test_scaled, X_test[dummies]],axis = 1 )\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    return X_train_scaled, X_test_scaled\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eef99760",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled = scaling(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c392d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a86639f",
   "metadata": {},
   "source": [
    "# creating a min max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a3ef66c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainnum = x_train.select_dtypes(exclude= ['string','object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "8698b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainnum = xtrainnum.drop(columns = ['neg','pos','neutral','compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "245ce37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainnum = xtrainnum[['review_count','number_of_ratings','length','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e2f80968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "cca69ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "# Note that we only call .fit with the training data,\n",
    "# but we use .transform to apply the scaling to all the data splits.\n",
    "scaler.fit(xtrainnum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "f33bb2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_ls = xtrainnum.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "4bdc3b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['review_count', 'number_of_ratings', 'length', 'rating']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "595f572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = scaler.transform(x_train[number_ls])\n",
    "x_test_scaled = scaler.transform(x_test[number_ls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c5a49247",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = pd.DataFrame(x_train_scaled, columns= [number_ls])\n",
    "x_test_scaled = pd.DataFrame(x_test_scaled, columns= [number_ls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "49ff2741",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled[['neg','neutral','pos','compound']] = x_train[['neg','neutral','pos','compound']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "79714fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scaled[['neg','neutral','pos','compound']] = x_test[['neg','neutral','pos','compound']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "e054a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = x_train.columns.tolist()[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "fc7ecd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = pd.concat([x_train_scaled, x_train[dummies]],axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "44805f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(review_count,)</th>\n",
       "      <th>(number_of_ratings,)</th>\n",
       "      <th>(length,)</th>\n",
       "      <th>(rating,)</th>\n",
       "      <th>(neg,)</th>\n",
       "      <th>(neutral,)</th>\n",
       "      <th>(pos,)</th>\n",
       "      <th>(compound,)</th>\n",
       "      <th>genre_Business</th>\n",
       "      <th>genre_Chick Lit</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Short Stories</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_Travel</th>\n",
       "      <th>genre_Urban Fantasy</th>\n",
       "      <th>genre_Vampires</th>\n",
       "      <th>genre_Young Adult</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_very negative</th>\n",
       "      <th>sentiment_very positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.411491</td>\n",
       "      <td>-0.284079</td>\n",
       "      <td>0.168132</td>\n",
       "      <td>-0.359763</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.0644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.380954</td>\n",
       "      <td>-0.306387</td>\n",
       "      <td>0.583932</td>\n",
       "      <td>1.975819</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.9918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.362078</td>\n",
       "      <td>-0.284689</td>\n",
       "      <td>1.195403</td>\n",
       "      <td>0.167627</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.9259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.379408</td>\n",
       "      <td>-0.306298</td>\n",
       "      <td>0.119214</td>\n",
       "      <td>0.129956</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.8074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.218285</td>\n",
       "      <td>-0.207416</td>\n",
       "      <td>-0.223210</td>\n",
       "      <td>-0.472775</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>-0.342364</td>\n",
       "      <td>-0.300816</td>\n",
       "      <td>-1.495069</td>\n",
       "      <td>-0.284421</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>5.212623</td>\n",
       "      <td>2.877707</td>\n",
       "      <td>0.510555</td>\n",
       "      <td>2.239513</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.7436</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>0.256904</td>\n",
       "      <td>-0.013444</td>\n",
       "      <td>0.125329</td>\n",
       "      <td>0.582004</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.6124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>-0.370453</td>\n",
       "      <td>-0.270314</td>\n",
       "      <td>0.559473</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>-0.408399</td>\n",
       "      <td>-0.296011</td>\n",
       "      <td>-1.495069</td>\n",
       "      <td>-0.472775</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.4559</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2948 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (review_count,)  (number_of_ratings,)  (length,)  (rating,)  (neg,)  \\\n",
       "0           -0.411491             -0.284079   0.168132  -0.359763   0.147   \n",
       "1           -0.380954             -0.306387   0.583932   1.975819   0.234   \n",
       "2           -0.362078             -0.284689   1.195403   0.167627   0.180   \n",
       "3           -0.379408             -0.306298   0.119214   0.129956   0.126   \n",
       "4           -0.218285             -0.207416  -0.223210  -0.472775   0.185   \n",
       "...               ...                   ...        ...        ...     ...   \n",
       "2943        -0.342364             -0.300816  -1.495069  -0.284421   0.030   \n",
       "2944         5.212623              2.877707   0.510555   2.239513   0.125   \n",
       "2945         0.256904             -0.013444   0.125329   0.582004   0.105   \n",
       "2946        -0.370453             -0.270314   0.559473   0.016944   0.000   \n",
       "2947        -0.408399             -0.296011  -1.495069  -0.472775   0.000   \n",
       "\n",
       "      (neutral,)  (pos,)  (compound,)  genre_Business  genre_Chick Lit  ...  \\\n",
       "0          0.717   0.136      -0.0644               0                0  ...   \n",
       "1          0.702   0.064      -0.9918               0                0  ...   \n",
       "2          0.664   0.156      -0.9259               0                0  ...   \n",
       "3          0.818   0.056      -0.8074               0                0  ...   \n",
       "4          0.591   0.224       0.1531               0                0  ...   \n",
       "...          ...     ...          ...             ...              ...  ...   \n",
       "2943       0.720   0.250       0.9849               0                0  ...   \n",
       "2944       0.788   0.087      -0.7436               0                0  ...   \n",
       "2945       0.796   0.099      -0.6124               0                0  ...   \n",
       "2946       0.901   0.099       0.9153               0                0  ...   \n",
       "2947       0.952   0.048       0.4559               0                0  ...   \n",
       "\n",
       "      genre_Short Stories  genre_Thriller  genre_Travel  genre_Urban Fantasy  \\\n",
       "0                       0               0             0                    0   \n",
       "1                       0               0             0                    0   \n",
       "2                       0               0             0                    0   \n",
       "3                       0               0             0                    0   \n",
       "4                       0               0             0                    0   \n",
       "...                   ...             ...           ...                  ...   \n",
       "2943                    0               0             0                    0   \n",
       "2944                    0               0             0                    0   \n",
       "2945                    0               0             0                    0   \n",
       "2946                    0               0             0                    0   \n",
       "2947                    0               0             0                    0   \n",
       "\n",
       "      genre_Vampires  genre_Young Adult  sentiment_neutral  \\\n",
       "0                  0                  0                  0   \n",
       "1                  0                  0                  0   \n",
       "2                  0                  0                  0   \n",
       "3                  0                  0                  0   \n",
       "4                  0                  0                  0   \n",
       "...              ...                ...                ...   \n",
       "2943               0                  0                  0   \n",
       "2944               0                  0                  0   \n",
       "2945               0                  0                  0   \n",
       "2946               0                  0                  0   \n",
       "2947               0                  0                  0   \n",
       "\n",
       "      sentiment_positive  sentiment_very negative  sentiment_very positive  \n",
       "0                      0                        0                        0  \n",
       "1                      0                        1                        0  \n",
       "2                      0                        1                        0  \n",
       "3                      0                        1                        0  \n",
       "4                      1                        0                        0  \n",
       "...                  ...                      ...                      ...  \n",
       "2943                   0                        0                        1  \n",
       "2944                   0                        1                        0  \n",
       "2945                   0                        1                        0  \n",
       "2946                   0                        0                        1  \n",
       "2947                   1                        0                        0  \n",
       "\n",
       "[2948 rows x 47 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "063c47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scaled = pd.concat([x_test_scaled, x_test[dummies]],axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9169ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "ff5bb192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_count</th>\n",
       "      <th>number_of_ratings</th>\n",
       "      <th>length</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>successful</th>\n",
       "      <th>lemmatized_summary</th>\n",
       "      <th>neg</th>\n",
       "      <th>neutral</th>\n",
       "      <th>pos</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Short Stories</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_Travel</th>\n",
       "      <th>genre_Urban Fantasy</th>\n",
       "      <th>genre_Vampires</th>\n",
       "      <th>genre_Young Adult</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_very negative</th>\n",
       "      <th>sentiment_very positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157</td>\n",
       "      <td>26214</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.34</td>\n",
       "      <td>False</td>\n",
       "      <td>alice adventure wonderland robert sabuda amaze...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.373</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>19212</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Childrens</td>\n",
       "      <td>4.25</td>\n",
       "      <td>False</td>\n",
       "      <td>take bath big job mercer mayer famous little c...</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>531</td>\n",
       "      <td>9155</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Horror</td>\n",
       "      <td>4.01</td>\n",
       "      <td>False</td>\n",
       "      <td>rat wall short lovecraft write augustseptember...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>701</td>\n",
       "      <td>17358</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Picture Books</td>\n",
       "      <td>4.13</td>\n",
       "      <td>False</td>\n",
       "      <td>flock hapless sheep drive country rhyme picture</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>15889</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Childrens</td>\n",
       "      <td>4.00</td>\n",
       "      <td>False</td>\n",
       "      <td>note beverly cleary guide teacher accompany ti...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.191</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>6016</td>\n",
       "      <td>54070</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>4.12</td>\n",
       "      <td>False</td>\n",
       "      <td>latest installment highly acclaim internationa...</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>8425</td>\n",
       "      <td>199251</td>\n",
       "      <td>1443.0</td>\n",
       "      <td>Historical Fiction</td>\n",
       "      <td>4.25</td>\n",
       "      <td>False</td>\n",
       "      <td>year war come jamie frasers wife tell little w...</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.072</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3852</th>\n",
       "      <td>15480</td>\n",
       "      <td>308202</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.15</td>\n",
       "      <td>False</td>\n",
       "      <td>tolstoy epic masterpiece intertwine life priva...</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.132</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3853</th>\n",
       "      <td>179</td>\n",
       "      <td>9045</td>\n",
       "      <td>2904.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.22</td>\n",
       "      <td>False</td>\n",
       "      <td>firmly ground hallmark strength norton antholo...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854</th>\n",
       "      <td>767</td>\n",
       "      <td>11725</td>\n",
       "      <td>4211.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.35</td>\n",
       "      <td>False</td>\n",
       "      <td>surface traditional bildungsroman describe nar...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.058</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3686 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      review_count  number_of_ratings  length               genre  rating  \\\n",
       "0              157              26214    12.0            Classics    4.34   \n",
       "1               62              19212    24.0           Childrens    4.25   \n",
       "2              531               9155    25.0              Horror    4.01   \n",
       "3              701              17358    26.0       Picture Books    4.13   \n",
       "4               50              15889    28.0           Childrens    4.00   \n",
       "...            ...                ...     ...                 ...     ...   \n",
       "3849          6016              54070  1408.0             Mystery    4.12   \n",
       "3851          8425             199251  1443.0  Historical Fiction    4.25   \n",
       "3852         15480             308202  1700.0            Classics    4.15   \n",
       "3853           179               9045  2904.0            Classics    4.22   \n",
       "3854           767              11725  4211.0            Classics    4.35   \n",
       "\n",
       "      successful                                 lemmatized_summary    neg  \\\n",
       "0          False  alice adventure wonderland robert sabuda amaze...  0.000   \n",
       "1          False  take bath big job mercer mayer famous little c...  0.008   \n",
       "2          False  rat wall short lovecraft write augustseptember...  0.015   \n",
       "3          False    flock hapless sheep drive country rhyme picture  0.167   \n",
       "4          False  note beverly cleary guide teacher accompany ti...  0.000   \n",
       "...          ...                                                ...    ...   \n",
       "3849       False  latest installment highly acclaim internationa...  0.143   \n",
       "3851       False  year war come jamie frasers wife tell little w...  0.130   \n",
       "3852       False  tolstoy epic masterpiece intertwine life priva...  0.087   \n",
       "3853       False  firmly ground hallmark strength norton antholo...  0.000   \n",
       "3854       False  surface traditional bildungsroman describe nar...  0.079   \n",
       "\n",
       "      neutral    pos  ...  genre_Short Stories genre_Thriller  genre_Travel  \\\n",
       "0       0.627  0.373  ...                    0              0             0   \n",
       "1       0.781  0.211  ...                    0              0             0   \n",
       "2       0.985  0.000  ...                    0              0             0   \n",
       "3       0.833  0.000  ...                    0              0             0   \n",
       "4       0.809  0.191  ...                    0              0             0   \n",
       "...       ...    ...  ...                  ...            ...           ...   \n",
       "3849    0.806  0.051  ...                    0              0             0   \n",
       "3851    0.798  0.072  ...                    0              0             0   \n",
       "3852    0.781  0.132  ...                    0              0             0   \n",
       "3853    0.874  0.126  ...                    0              0             0   \n",
       "3854    0.863  0.058  ...                    0              0             0   \n",
       "\n",
       "      genre_Urban Fantasy  genre_Vampires  genre_Young Adult  \\\n",
       "0                       0               0                  0   \n",
       "1                       0               0                  0   \n",
       "2                       0               0                  0   \n",
       "3                       0               0                  0   \n",
       "4                       0               0                  0   \n",
       "...                   ...             ...                ...   \n",
       "3849                    0               0                  0   \n",
       "3851                    0               0                  0   \n",
       "3852                    0               0                  0   \n",
       "3853                    0               0                  0   \n",
       "3854                    0               0                  0   \n",
       "\n",
       "      sentiment_neutral  sentiment_positive  sentiment_very negative  \\\n",
       "0                     0                   0                        0   \n",
       "1                     0                   0                        0   \n",
       "2                     0                   0                        0   \n",
       "3                     0                   0                        0   \n",
       "4                     0                   0                        0   \n",
       "...                 ...                 ...                      ...   \n",
       "3849                  0                   0                        1   \n",
       "3851                  0                   0                        1   \n",
       "3852                  0                   0                        0   \n",
       "3853                  0                   0                        0   \n",
       "3854                  0                   0                        1   \n",
       "\n",
       "      sentiment_very positive  \n",
       "0                           1  \n",
       "1                           1  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           1  \n",
       "...                       ...  \n",
       "3849                        0  \n",
       "3851                        0  \n",
       "3852                        1  \n",
       "3853                        1  \n",
       "3854                        0  \n",
       "\n",
       "[3686 rows x 51 columns]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe44b7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb17249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e5cb05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3987a207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be91c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7384cb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce9b271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aee818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "021ceb82",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da701fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import  ConfusionMatrixDisplay\n",
    "from sklearn.metrics import recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df75a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBclf(X_train_scaled, X_test_scaled): \n",
    "    \n",
    "    # create  an instance with predetermined values, using cross validation, grid search and other methods,\n",
    "    # these parameters have been predetermined for the top performance. \n",
    "    xgb_clf = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                                        seed = 42,\n",
    "                                        max_depth = 3,    \n",
    "                                        scale_pos_weight= 7,\n",
    "                                        learning_rate = .1,\n",
    "                                        subsample = .7,\n",
    "                                        colsample_bytree = .7,\n",
    "                                        n_jobs = 10)\n",
    "    \n",
    "    most_imp = [('number_of_ratings',),\n",
    "                'genre_Mystery',\n",
    "                ('review_count',),\n",
    "                 'genre_Nonfiction',\n",
    "                'genre_Horror',\n",
    "                 ('length',),\n",
    "                 'genre_Fiction',\n",
    "                 ('rating',),\n",
    "                 'sentiment_very negative',\n",
    "                 'genre_Young Adult',\n",
    "                 'genre_Fantasy',\n",
    "                 'genre_Romance',\n",
    "                 ('neutral',),\n",
    "                 ('neg',),\n",
    "                 ('pos',),\n",
    "                 ('compound',),\n",
    "                 'sentiment_very positive',\n",
    "                 'genre_Thriller']\n",
    "    \n",
    "    # fit the model with x_train, using the most important features, and y_train\n",
    "    xgb_clf.fit(X_train_scaled[most_imp],y_train)\n",
    "    \n",
    "    # y predictions for test\n",
    "    y_pred = xgb_clf.predict(X_test_scaled[most_imp])\n",
    "    \n",
    "    # assume y_test and y_pred are your test set target variable and predicted labels, respectively\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # plot confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['Unsuccessful', 'Bestseller'])\n",
    "    disp.plot()\n",
    "    disp.ax_.set_title(\"Confusion Matrix for XGB Classifier\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return y_pred\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9dd5437e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/common.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/common.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = XGBclf(X_train_scaled, X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc617973",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d0/5dr5q0n145vcn3_m9dxy1xq80000gn/T/ipykernel_49214/3562620839.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96489bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "68ba7179",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = y_test.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "be17a123",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'baseline'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3629\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'baseline'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d0/5dr5q0n145vcn3_m9dxy1xq80000gn/T/ipykernel_49214/3845216865.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'baseline'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3631\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3632\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3633\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'baseline'"
     ]
    }
   ],
   "source": [
    "y_test['baseline'] == mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "52dd37cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'baseline'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3629\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'baseline'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d0/5dr5q0n145vcn3_m9dxy1xq80000gn/T/ipykernel_49214/1107500179.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'baseline'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3631\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3632\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3633\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'baseline'"
     ]
    }
   ],
   "source": [
    "y_test['baseline'] == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f0552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb5272eb",
   "metadata": {},
   "source": [
    "# XGBOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "645b91a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sklearn.metrics as m\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import  ConfusionMatrixDisplay\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d83429",
   "metadata": {},
   "source": [
    "# import CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a32d02",
   "metadata": {},
   "source": [
    "# best xgb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a06be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.39506172839506176,: recall-score=0.5\n",
    "\n",
    "\n",
    "[[673  33]\n",
    " [ 16  16]]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b0b57004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whatever transformations we apply to X_train need to be applied to X_test\n",
    "# create  an instance with predetermined values \n",
    "xgb_clf = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                                        seed = 42,\n",
    "                                        max_depth = 3,    \n",
    "                                        scale_pos_weight= 7,\n",
    "                                        learning_rate = .1,\n",
    "                                        subsample = .7,\n",
    "                                        colsample_bytree = .7,\n",
    "                                        n_jobs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "eca7efd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/common.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=10, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.fit(x_train_scaled[most_imp],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "d3df6306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/common.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_clf.predict(x_test_scaled[most_imp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "606bea2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[673  33]\n",
      " [ 16  16]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test['successful'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "57eb8bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test['successful'], y_test['baseline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ab305ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1da617ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>successful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>733 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     successful\n",
       "0         False\n",
       "1         False\n",
       "2         False\n",
       "3          True\n",
       "4         False\n",
       "..          ...\n",
       "728       False\n",
       "729       False\n",
       "730       False\n",
       "731       False\n",
       "732       False\n",
       "\n",
       "[733 rows x 1 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "02464622",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_val = y_test['successful'].mode()[0]\n",
    "\n",
    "# Create a new column with the mode value\n",
    "y_test = y_test.assign(baseline=mode_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "90424303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "728    False\n",
       "729    False\n",
       "730    False\n",
       "731    False\n",
       "732    False\n",
       "Name: baseline, Length: 733, dtype: bool"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['baseline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2535b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc(y_test, y_pred):\n",
    "    \n",
    "    \n",
    "    mode_val = y_test['successful'].mode()[0]\n",
    "\n",
    "    # Create a new column with the mode value\n",
    "    y_test = y_test.assign(baseline=mode_val)\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test['successful'], y_pred)\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'XGBClassifer (area = %0.4f)' % auc(fpr, tpr))\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test['successful'], y_test['baseline'])\n",
    "    plt.plot(fpr, tpr, color='red', lw=2, label=f'Baseline (area = %0.4f)' % auc(fpr, tpr))\n",
    "\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate', fontsize=13)\n",
    "    plt.ylabel('True Positive Rate', fontsize=14)\n",
    "    plt.title('XGB Classifier Captured Area', fontsize=17)\n",
    "    plt.legend(loc='lower right', fontsize=13)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17aacb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b2e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# based on the most important feats\n",
    "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.4444444444444445,: recall-score=0.5\n",
    "\n",
    "\n",
    "[[682  24]\n",
    " [ 16  16]]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045e6525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d02811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79810404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbbb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "49aeceec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from tqdm import tqdm\\nfrom sklearn.model_selection import cross_val_score\\nimport xgboost as xgb\\n\\nxgb_clf = xgb.XGBClassifier()\\n\\n# Define the number of folds for cross-validation\\nn_folds = 5\\n\\n# Use tqdm to create a progress bar\\nwith tqdm(total=n_folds) as pbar:\\n    # Pass the progress bar to the cv parameter of cross_val_score\\n    scores = cross_val_score(xgb_clf, x_train_long, y_train, cv=n_folds, verbose=1, n_jobs=-1)\\n    # Update the progress bar with each fold\\n    for i in range(n_folds):\\n        pbar.update(1)\\n\\n# Print the cross-validation scores\\nprint(scores)'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_folds = 5\n",
    "\n",
    "# Use tqdm to create a progress bar\n",
    "with tqdm(total=n_folds) as pbar:\n",
    "    # Pass the progress bar to the cv parameter of cross_val_score\n",
    "    scores = cross_val_score(xgb_clf, x_train_long, y_train, cv=n_folds, verbose=1, n_jobs=-1)\n",
    "    # Update the progress bar with each fold\n",
    "    for i in range(n_folds):\n",
    "        pbar.update(1)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(scores)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8312edc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def th_hyperparam_tuning(x_train, y_train, x_test, y_test, max_depths, scale_pos_weights, learning_rates, subsamples, colsample_bytrees):\n",
    "    for max_depth in max_depths:\n",
    "        for scale_pos_weight in scale_pos_weights:\n",
    "            for learning_rate in learning_rates:\n",
    "                for subsample in subsamples:\n",
    "                    for colsample_bytree in colsample_bytrees:\n",
    "                        # define the XGBClassifier with the current hyperparameters\n",
    "                        xgb_model = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                                                  seed=42,\n",
    "                                                  max_depth=max_depth,\n",
    "                                                  scale_pos_weight=scale_pos_weight,\n",
    "                                                  learning_rate=learning_rate,\n",
    "                                                  subsample=subsample,\n",
    "                                                  colsample_bytree=colsample_bytree,\n",
    "                                                  n_jobs=10)\n",
    "                        # fit the model on the training set\n",
    "                        xgb_model.fit(x_train, y_train)\n",
    "                        # predict on the test set\n",
    "                        y_pred = xgb_model.predict(x_test)\n",
    "                        # print the hyperparameters and the resulting f1-score\n",
    "                        print(f\"max_depth={max_depth}, scale_pos_weight={scale_pos_weight}, learning_rate={learning_rate}, subsample={subsample}, colsample_bytree={colsample_bytree}: f1-score={f1_score(y_test, y_pred)},: recall-score={recall_score(y_test, y_pred)}\")\n",
    "                        print('\\n')\n",
    "                        # print the confusion matrix\n",
    "                        print(confusion_matrix(y_test, y_pred))\n",
    "                        print('\\n')\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7f62fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [3, 5, 7]\n",
    "scale_pos_weights = [3, 5, 7]\n",
    "learning_rates = [0.01, 0.1, 1]\n",
    "subsamples = [0.7, 0.8, 0.9]\n",
    "colsample_bytrees = [0.5, 0.6, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35767cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.3548387096774193,: recall-score=0.34375\n",
    "\n",
    "\n",
    "[[682  19]\n",
    " [ 21  11]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7bebfadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/common.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/common.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.0,: recall-score=0.0\n",
      "\n",
      "\n",
      "[[701   0]\n",
      " [ 32   0]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.11764705882352941,: recall-score=0.0625\n",
      "\n",
      "\n",
      "[[701   0]\n",
      " [ 30   2]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.11428571428571428,: recall-score=0.0625\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 30   2]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.06060606060606061,: recall-score=0.03125\n",
      "\n",
      "\n",
      "[[701   0]\n",
      " [ 31   1]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.11764705882352941,: recall-score=0.0625\n",
      "\n",
      "\n",
      "[[701   0]\n",
      " [ 30   2]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.16666666666666666,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.11764705882352941,: recall-score=0.0625\n",
      "\n",
      "\n",
      "[[701   0]\n",
      " [ 30   2]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.11764705882352941,: recall-score=0.0625\n",
      "\n",
      "\n",
      "[[701   0]\n",
      " [ 30   2]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.16666666666666666,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.2857142857142857,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.2916666666666667,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[692   9]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.2978723404255319,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.31818181818181823,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.2916666666666667,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[692   9]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.2916666666666667,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[692   9]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.30434782608695654,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.2978723404255319,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.28,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[690  11]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.36363636363636365,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[688  13]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.19999999999999998,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[688  13]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.2916666666666667,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[692   9]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.2127659574468085,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.13333333333333333,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.27906976744186046,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.2978723404255319,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.25531914893617025,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[692   9]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.28,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[690  11]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.16666666666666666,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.2631578947368421,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.25,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[698   3]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.16666666666666666,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.16666666666666666,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.29268292682926833,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[698   3]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.16666666666666666,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.3,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[699   2]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.3548387096774193,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[682  19]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.27586206896551724,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[683  18]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.3050847457627119,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[683  18]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.3448275862068966,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[685  16]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.28571428571428575,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[685  16]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.3272727272727273,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[687  14]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.2711864406779661,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[682  19]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.3333333333333333,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[683  18]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.3157894736842105,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[685  16]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.25,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.25925925925925924,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[686  15]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.2962962962962963,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[687  14]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.2916666666666667,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[692   9]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.2545454545454546,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[685  16]\n",
      " [ 25   7]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.3076923076923077,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[689  12]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.3111111111111111,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.3673469387755102,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.2745098039215686,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[689  12]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.3018867924528302,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[688  13]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.2950819672131148,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[681  20]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.273972602739726,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[670  31]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.22641509433962265,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[686  15]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.2222222222222222,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[677  24]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.24657534246575344,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[669  32]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.2711864406779661,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[682  19]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.21875,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[676  25]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.2666666666666667,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[668  33]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.33333333333333337,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[678  23]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.273972602739726,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[670  31]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.2857142857142857,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[667  34]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.29850746268656714,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[676  25]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.27027027027027023,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[669  32]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.2857142857142857,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[673  28]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.3013698630136986,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[671  30]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.273972602739726,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[670  31]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.2571428571428571,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[672  29]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.3137254901960784,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[690  11]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.3103448275862069,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[684  17]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.3396226415094339,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[689  12]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.3333333333333333,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[688  13]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.3018867924528302,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[688  13]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.21428571428571427,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[683  18]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.28,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[690  11]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.2745098039215686,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[689  12]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.19607843137254902,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[687  14]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.2702702702702703,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[701   0]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.2222222222222222,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[701   0]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.2222222222222222,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[701   0]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.2857142857142857,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[697   4]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.2727272727272727,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.3111111111111111,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.2727272727272727,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.29268292682926833,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[698   3]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.3255813953488372,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[697   4]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.3,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[699   2]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.20512820512820512,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[698   3]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.2727272727272727,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.14634146341463417,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 29   3]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.25,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.18181818181818182,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.2857142857142857,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.18604651162790697,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.25531914893617025,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[692   9]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.26666666666666666,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.20833333333333334,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[690  11]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.26666666666666666,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.358974358974359,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[701   0]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.29268292682926833,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[698   3]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.2727272727272727,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.30769230769230765,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.29268292682926833,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[698   3]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.26666666666666666,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.27906976744186046,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.24390243902439024,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[697   4]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.25531914893617025,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[692   9]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.26086956521739124,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.25,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.2978723404255319,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.3111111111111111,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.26666666666666666,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.2857142857142857,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.30434782608695654,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.3111111111111111,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.2857142857142857,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.18181818181818182,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.30434782608695654,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.21739130434782608,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[692   9]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.27906976744186046,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.21739130434782608,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[692   9]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.19230769230769232,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[686  15]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.17391304347826086,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.22222222222222224,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.26666666666666666,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.32,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.3137254901960784,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[690  11]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.22641509433962265,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[686  15]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.32,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.2962962962962963,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[687  14]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.2807017543859649,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[684  17]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.2692307692307692,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[688  13]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.2641509433962264,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[687  14]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.2413793103448276,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[682  19]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.3076923076923077,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[689  12]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.2857142857142857,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.19999999999999998,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[688  13]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.2745098039215686,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[689  12]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.32653061224489793,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[692   9]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.3018867924528302,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[688  13]\n",
      " [ 24   8]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.2692307692307692,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[688  13]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.2978723404255319,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.24000000000000005,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[689  12]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.24000000000000005,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[689  12]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.3076923076923077,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[689  12]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.20408163265306123,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[689  12]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.2692307692307692,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[688  13]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.22727272727272727,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.2127659574468085,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.35555555555555557,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.4313725490196078,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.24390243902439024,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[697   4]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.2222222222222222,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[701   0]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.2631578947368421,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.2222222222222222,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[701   0]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.2631578947368421,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.2222222222222222,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[701   0]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.2631578947368421,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.25,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[698   3]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.2857142857142857,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[697   4]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.23809523809523808,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.25,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[698   3]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.25641025641025644,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[699   2]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.27906976744186046,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.29268292682926833,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[698   3]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.25641025641025644,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[699   2]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.2,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[697   4]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.19607843137254902,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[687  14]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.32,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.25531914893617025,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[692   9]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.14285714285714285,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.13636363636363635,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[692   9]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.2,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[697   4]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.2,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[697   4]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.26666666666666666,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.26086956521739124,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.3157894736842105,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[701   0]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.3,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[699   2]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.2857142857142857,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[697   4]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.30769230769230765,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.25641025641025644,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[699   2]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.23809523809523808,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.30769230769230765,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[700   1]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.25,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[698   3]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.26666666666666666,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.23809523809523808,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.26086956521739124,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 26   6]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.1951219512195122,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.24390243902439024,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[697   4]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.24390243902439024,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[697   4]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.2325581395348837,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.2325581395348837,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.3111111111111111,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.27906976744186046,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.20833333333333334,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[690  11]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.2978723404255319,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.23076923076923075,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[687  14]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.22727272727272727,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.31818181818181823,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.3076923076923077,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[689  12]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.1951219512195122,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.18604651162790697,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.17777777777777778,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[692   9]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.31818181818181823,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.30434782608695654,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.25,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.3111111111111111,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.30434782608695654,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.2745098039215686,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[689  12]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.26086956521739124,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.25,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[691  10]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.23076923076923075,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[687  14]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.3111111111111111,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.22727272727272727,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[694   7]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.2727272727272727,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.23809523809523808,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.27906976744186046,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.2727272727272727,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.23809523809523808,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[696   5]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.26086956521739124,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.2727272727272727,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.23529411764705882,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[688  13]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.2916666666666667,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[692   9]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.20833333333333334,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[690  11]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.16,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[687  14]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.25531914893617025,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[692   9]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.24390243902439024,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[697   4]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.26086956521739124,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[693   8]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.2325581395348837,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[695   6]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.24489795918367344,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[690  11]\n",
      " [ 26   6]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calling function\n",
    "th_hyperparam_tuning(X_train_scaled[most_imp], y_train, X_test_scaled[most_imp], y_test, max_depths, scale_pos_weights, learning_rates, subsamples, colsample_bytrees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11364eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.4313725490196078,: recall-score=0.34375\n",
    "\n",
    "\n",
    "[[693   8]\n",
    " [ 21  11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db56f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.39506172839506176,: recall-score=0.5\n",
    "\n",
    "\n",
    "[[673  33]\n",
    " [ 16  16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.4375,: recall-score=0.4375\n",
    "\n",
    "\n",
    "[[688  18]\n",
    " [ 18  14]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b08a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.4411764705882353,: recall-score=0.46875\n",
    "\n",
    "\n",
    "[[685  21]\n",
    " [ 17  15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf1557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf70a570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bb65c3c",
   "metadata": {},
   "source": [
    "# grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3ccf8dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import make_scorer, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ea33bd5c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 243 candidates, totalling 486 fits\n",
      "[CV 1/2] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, scale_pos_weight=3, subsample=0.7;, score=0.500 total time=  52.4s\n",
      "[CV 2/2] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, scale_pos_weight=3, subsample=0.7;, score=0.500 total time=  51.3s\n",
      "[CV 1/2] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, scale_pos_weight=3, subsample=0.8;, score=0.500 total time=  53.1s\n",
      "[CV 2/2] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, scale_pos_weight=3, subsample=0.8;, score=0.500 total time=  51.8s\n",
      "[CV 1/2] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, scale_pos_weight=3, subsample=0.9;, score=0.500 total time=  51.9s\n",
      "[CV 2/2] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, scale_pos_weight=3, subsample=0.9;, score=0.500 total time=  52.4s\n",
      "[CV 1/2] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, scale_pos_weight=5, subsample=0.7;, score=0.500 total time=  50.2s\n",
      "[CV 2/2] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, scale_pos_weight=5, subsample=0.7;, score=0.500 total time=  49.1s\n",
      "[CV 1/2] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, scale_pos_weight=5, subsample=0.8;, score=0.500 total time=  52.3s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d0/5dr5q0n145vcn3_m9dxy1xq80000gn/T/ipykernel_43771/2846391793.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_long\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Print the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1488\u001b[0m             )\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1491\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"invalid training matrix: {type(dtrain).__name__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_dmatrix_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_dmatrix_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2735\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2736\u001b[0;31m         \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2737\u001b[0m         \u001b[0;31m# Be consistent with versions before 1.7, \"validate\" actually modifies the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2738\u001b[0m         \u001b[0;31m# booster.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mfeature_types\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m                                                     ctypes.byref(sarr)))\n\u001b[0;32m-> 1195\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_cstr_to_pystr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mfrom_cstr_to_pystr\u001b[0;34m(data, length)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'max_depth': [2, 3, 4],\n",
    "          'scale_pos_weight': [3,5,7],\n",
    "          'learning_rate' : [0.01, 0.1, 1],\n",
    "          'subsample' : [0.7, 0.8, 0.9],\n",
    "          'colsample_bytree' : [0.5, 0.6, 0.7]\n",
    "          }\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "scorer = make_scorer(recall_score, average='macro')\n",
    "\n",
    "grid = GridSearchCV(xgb_model, params,cv= 2 , scoring= scorer,  verbose = 3)\n",
    "\n",
    "grid.fit(x_train_long, y_train)\n",
    "\n",
    "# Print the results\n",
    "print('Best params:', grid.best_params_)\n",
    "print('Best recall:', grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b16305c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# create an instance with predetermined values \n",
    "clf_xgb = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                                        seed = 42,\n",
    "                                        max_depth = 3,    \n",
    "                                        scale_pos_weight= 5,\n",
    "                                        learning_rate = .01,\n",
    "                                        subsample = .9,\n",
    "                                        colsample_bytree = .5,\n",
    "                                        n_jobs = 10)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5fd13e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.5, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=10, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_xgb.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2a2b1164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clf_xgb.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b2fe1edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_imp = feat_importances.nlargest(18).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f505319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_imp = [('number_of_ratings',),\n",
    " 'genre_Mystery',\n",
    " ('review_count',),\n",
    " 'genre_Nonfiction',\n",
    " 'genre_Horror',\n",
    " ('length',),\n",
    " 'genre_Fiction',\n",
    " ('rating',),\n",
    " 'sentiment_very negative',\n",
    " 'genre_Young Adult',\n",
    " 'genre_Fantasy',\n",
    " 'genre_Romance',\n",
    " ('neutral',),\n",
    " ('neg',),\n",
    " ('pos',),\n",
    " ('compound',),\n",
    " 'sentiment_very positive',\n",
    " 'genre_Thriller']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "501d5fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(clf_xgb.feature_importances_, index= x_train_scaled.columns)\n",
    "feat_importances.nlargest(18).plot(kind='barh')\n",
    "plt.title(\"Top 18 important features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efcf9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled[important_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283be88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.4225352112676056,: recall-score=0.46875\n",
    "\n",
    "\n",
    "[[682  24]\n",
    " [ 17  15]]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bfaa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.3880597014925374,: recall-score=0.40625\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639f1dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# based on the most important feats\n",
    "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.4444444444444445,: recall-score=0.5\n",
    "\n",
    "\n",
    "[[682  24]\n",
    " [ 16  16]]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe428c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b1f1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a368d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d531c2fc",
   "metadata": {},
   "source": [
    "# create a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb44b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = y.mode()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc42b6c0",
   "metadata": {},
   "source": [
    "# print confusion matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fcab6e",
   "metadata": {},
   "source": [
    "# baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "0ced22ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred), \n",
    "display_labels = ['unsuccessful', 'best seller'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "7afc4446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "02ccd48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_test and y_pred are your test set target variable and predicted labels, respectively\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['Unsuccessful', 'Bestseller'])\n",
    "disp.plot()\n",
    "disp.ax_.set_title(\"Confusion Matrix for XGB Classifier\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bee0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40080302",
   "metadata": {},
   "source": [
    "# create ruc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8bdac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "388be060",
   "metadata": {},
   "source": [
    "# create bar charts, show difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376426ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a264a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d372b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d363bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
