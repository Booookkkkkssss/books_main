{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "641a0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import prepare as pr \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "93ce7413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pr.prep_data('all_books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1331e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "98f8b250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>year_published</th>\n",
       "      <th>author</th>\n",
       "      <th>review_count</th>\n",
       "      <th>number_of_ratings</th>\n",
       "      <th>length</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_summary</th>\n",
       "      <th>successful</th>\n",
       "      <th>lemmatized_summary</th>\n",
       "      <th>neg</th>\n",
       "      <th>neutral</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice's Adventures in Wonderland: A Pop-Up Ada...</td>\n",
       "      <td>Alice's Adventures in Wonderland is Robert Sa...</td>\n",
       "      <td>2003</td>\n",
       "      <td>Robert Sabuda</td>\n",
       "      <td>157</td>\n",
       "      <td>26214</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.34</td>\n",
       "      <td>[]</td>\n",
       "      <td>alice's adventures in wonderland a popup adapt...</td>\n",
       "      <td>alice's adventures in wonderland is robert sa...</td>\n",
       "      <td>False</td>\n",
       "      <td>alice adventure wonderland robert sabuda amaze...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.9718</td>\n",
       "      <td>very positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Alice's Adventures in Wonderland: A Pop-Up Ada...   \n",
       "\n",
       "                                             summary  year_published  \\\n",
       "0   Alice's Adventures in Wonderland is Robert Sa...            2003   \n",
       "\n",
       "          author  review_count  number_of_ratings  length     genre  rating  \\\n",
       "0  Robert Sabuda           157              26214    12.0  Classics    4.34   \n",
       "\n",
       "  reviews                                      cleaned_title  \\\n",
       "0      []  alice's adventures in wonderland a popup adapt...   \n",
       "\n",
       "                                     cleaned_summary  successful  \\\n",
       "0   alice's adventures in wonderland is robert sa...       False   \n",
       "\n",
       "                                  lemmatized_summary  neg  neutral    pos  \\\n",
       "0  alice adventure wonderland robert sabuda amaze...  0.0    0.627  0.373   \n",
       "\n",
       "   compound      sentiment  \n",
       "0    0.9718  very positive  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "23131a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b08ced",
   "metadata": {},
   "source": [
    "# Clean DataFrame for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5f498669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genre'] = df.genre.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7d037db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns= ['title','summary','year_published','author','reviews','cleaned_title','cleaned_summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6abcf4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(df[['genre','sentiment']], dummy_na=False, drop_first=[True, True])\n",
    "col_list = dummy_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "92a009bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, dummy_df],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "53d53067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_count</th>\n",
       "      <th>number_of_ratings</th>\n",
       "      <th>length</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>successful</th>\n",
       "      <th>lemmatized_summary</th>\n",
       "      <th>neg</th>\n",
       "      <th>neutral</th>\n",
       "      <th>pos</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Short Stories</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_Travel</th>\n",
       "      <th>genre_Urban Fantasy</th>\n",
       "      <th>genre_Vampires</th>\n",
       "      <th>genre_Young Adult</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_very negative</th>\n",
       "      <th>sentiment_very positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157</td>\n",
       "      <td>26214</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.34</td>\n",
       "      <td>False</td>\n",
       "      <td>alice adventure wonderland robert sabuda amaze...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.373</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>19212</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Childrens</td>\n",
       "      <td>4.25</td>\n",
       "      <td>False</td>\n",
       "      <td>take bath big job mercer mayer famous little c...</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>531</td>\n",
       "      <td>9155</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Horror</td>\n",
       "      <td>4.01</td>\n",
       "      <td>False</td>\n",
       "      <td>rat wall short lovecraft write augustseptember...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>701</td>\n",
       "      <td>17358</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Picture Books</td>\n",
       "      <td>4.13</td>\n",
       "      <td>False</td>\n",
       "      <td>flock hapless sheep drive country rhyme picture</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>15889</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Childrens</td>\n",
       "      <td>4.00</td>\n",
       "      <td>False</td>\n",
       "      <td>note beverly cleary guide teacher accompany ti...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.191</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>6016</td>\n",
       "      <td>54070</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>4.12</td>\n",
       "      <td>False</td>\n",
       "      <td>latest installment highly acclaim internationa...</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>8425</td>\n",
       "      <td>199251</td>\n",
       "      <td>1443.0</td>\n",
       "      <td>Historical Fiction</td>\n",
       "      <td>4.25</td>\n",
       "      <td>False</td>\n",
       "      <td>year war come jamie frasers wife tell little w...</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.072</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3852</th>\n",
       "      <td>15480</td>\n",
       "      <td>308202</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.15</td>\n",
       "      <td>False</td>\n",
       "      <td>tolstoy epic masterpiece intertwine life priva...</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.132</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3853</th>\n",
       "      <td>179</td>\n",
       "      <td>9045</td>\n",
       "      <td>2904.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.22</td>\n",
       "      <td>False</td>\n",
       "      <td>firmly ground hallmark strength norton antholo...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854</th>\n",
       "      <td>767</td>\n",
       "      <td>11725</td>\n",
       "      <td>4211.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.35</td>\n",
       "      <td>False</td>\n",
       "      <td>surface traditional bildungsroman describe nar...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.058</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3686 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      review_count  number_of_ratings  length               genre  rating  \\\n",
       "0              157              26214    12.0            Classics    4.34   \n",
       "1               62              19212    24.0           Childrens    4.25   \n",
       "2              531               9155    25.0              Horror    4.01   \n",
       "3              701              17358    26.0       Picture Books    4.13   \n",
       "4               50              15889    28.0           Childrens    4.00   \n",
       "...            ...                ...     ...                 ...     ...   \n",
       "3849          6016              54070  1408.0             Mystery    4.12   \n",
       "3851          8425             199251  1443.0  Historical Fiction    4.25   \n",
       "3852         15480             308202  1700.0            Classics    4.15   \n",
       "3853           179               9045  2904.0            Classics    4.22   \n",
       "3854           767              11725  4211.0            Classics    4.35   \n",
       "\n",
       "      successful                                 lemmatized_summary    neg  \\\n",
       "0          False  alice adventure wonderland robert sabuda amaze...  0.000   \n",
       "1          False  take bath big job mercer mayer famous little c...  0.008   \n",
       "2          False  rat wall short lovecraft write augustseptember...  0.015   \n",
       "3          False    flock hapless sheep drive country rhyme picture  0.167   \n",
       "4          False  note beverly cleary guide teacher accompany ti...  0.000   \n",
       "...          ...                                                ...    ...   \n",
       "3849       False  latest installment highly acclaim internationa...  0.143   \n",
       "3851       False  year war come jamie frasers wife tell little w...  0.130   \n",
       "3852       False  tolstoy epic masterpiece intertwine life priva...  0.087   \n",
       "3853       False  firmly ground hallmark strength norton antholo...  0.000   \n",
       "3854       False  surface traditional bildungsroman describe nar...  0.079   \n",
       "\n",
       "      neutral    pos  ...  genre_Short Stories genre_Thriller  genre_Travel  \\\n",
       "0       0.627  0.373  ...                    0              0             0   \n",
       "1       0.781  0.211  ...                    0              0             0   \n",
       "2       0.985  0.000  ...                    0              0             0   \n",
       "3       0.833  0.000  ...                    0              0             0   \n",
       "4       0.809  0.191  ...                    0              0             0   \n",
       "...       ...    ...  ...                  ...            ...           ...   \n",
       "3849    0.806  0.051  ...                    0              0             0   \n",
       "3851    0.798  0.072  ...                    0              0             0   \n",
       "3852    0.781  0.132  ...                    0              0             0   \n",
       "3853    0.874  0.126  ...                    0              0             0   \n",
       "3854    0.863  0.058  ...                    0              0             0   \n",
       "\n",
       "      genre_Urban Fantasy  genre_Vampires  genre_Young Adult  \\\n",
       "0                       0               0                  0   \n",
       "1                       0               0                  0   \n",
       "2                       0               0                  0   \n",
       "3                       0               0                  0   \n",
       "4                       0               0                  0   \n",
       "...                   ...             ...                ...   \n",
       "3849                    0               0                  0   \n",
       "3851                    0               0                  0   \n",
       "3852                    0               0                  0   \n",
       "3853                    0               0                  0   \n",
       "3854                    0               0                  0   \n",
       "\n",
       "      sentiment_neutral  sentiment_positive  sentiment_very negative  \\\n",
       "0                     0                   0                        0   \n",
       "1                     0                   0                        0   \n",
       "2                     0                   0                        0   \n",
       "3                     0                   0                        0   \n",
       "4                     0                   0                        0   \n",
       "...                 ...                 ...                      ...   \n",
       "3849                  0                   0                        1   \n",
       "3851                  0                   0                        1   \n",
       "3852                  0                   0                        0   \n",
       "3853                  0                   0                        0   \n",
       "3854                  0                   0                        1   \n",
       "\n",
       "      sentiment_very positive  \n",
       "0                           1  \n",
       "1                           1  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           1  \n",
       "...                       ...  \n",
       "3849                        0  \n",
       "3851                        0  \n",
       "3852                        1  \n",
       "3853                        1  \n",
       "3854                        0  \n",
       "\n",
       "[3686 rows x 51 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "75385853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_count</th>\n",
       "      <th>number_of_ratings</th>\n",
       "      <th>length</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>successful</th>\n",
       "      <th>lemmatized_summary</th>\n",
       "      <th>neg</th>\n",
       "      <th>neutral</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157</td>\n",
       "      <td>26214</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.34</td>\n",
       "      <td>False</td>\n",
       "      <td>alice adventure wonderland robert sabuda amaze...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.9718</td>\n",
       "      <td>very positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>19212</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Childrens</td>\n",
       "      <td>4.25</td>\n",
       "      <td>False</td>\n",
       "      <td>take bath big job mercer mayer famous little c...</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>very positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>531</td>\n",
       "      <td>9155</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Horror</td>\n",
       "      <td>4.01</td>\n",
       "      <td>False</td>\n",
       "      <td>rat wall short lovecraft write augustseptember...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.1779</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>701</td>\n",
       "      <td>17358</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Picture Books</td>\n",
       "      <td>4.13</td>\n",
       "      <td>False</td>\n",
       "      <td>flock hapless sheep drive country rhyme picture</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>15889</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Childrens</td>\n",
       "      <td>4.00</td>\n",
       "      <td>False</td>\n",
       "      <td>note beverly cleary guide teacher accompany ti...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>very positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>6016</td>\n",
       "      <td>54070</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>4.12</td>\n",
       "      <td>False</td>\n",
       "      <td>latest installment highly acclaim internationa...</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.9437</td>\n",
       "      <td>very negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>8425</td>\n",
       "      <td>199251</td>\n",
       "      <td>1443.0</td>\n",
       "      <td>Historical Fiction</td>\n",
       "      <td>4.25</td>\n",
       "      <td>False</td>\n",
       "      <td>year war come jamie frasers wife tell little w...</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.7239</td>\n",
       "      <td>very negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3852</th>\n",
       "      <td>15480</td>\n",
       "      <td>308202</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.15</td>\n",
       "      <td>False</td>\n",
       "      <td>tolstoy epic masterpiece intertwine life priva...</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>very positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3853</th>\n",
       "      <td>179</td>\n",
       "      <td>9045</td>\n",
       "      <td>2904.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.22</td>\n",
       "      <td>False</td>\n",
       "      <td>firmly ground hallmark strength norton antholo...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.8176</td>\n",
       "      <td>very positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854</th>\n",
       "      <td>767</td>\n",
       "      <td>11725</td>\n",
       "      <td>4211.0</td>\n",
       "      <td>Classics</td>\n",
       "      <td>4.35</td>\n",
       "      <td>False</td>\n",
       "      <td>surface traditional bildungsroman describe nar...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.8145</td>\n",
       "      <td>very negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3686 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      review_count  number_of_ratings  length               genre  rating  \\\n",
       "0              157              26214    12.0            Classics    4.34   \n",
       "1               62              19212    24.0           Childrens    4.25   \n",
       "2              531               9155    25.0              Horror    4.01   \n",
       "3              701              17358    26.0       Picture Books    4.13   \n",
       "4               50              15889    28.0           Childrens    4.00   \n",
       "...            ...                ...     ...                 ...     ...   \n",
       "3849          6016              54070  1408.0             Mystery    4.12   \n",
       "3851          8425             199251  1443.0  Historical Fiction    4.25   \n",
       "3852         15480             308202  1700.0            Classics    4.15   \n",
       "3853           179               9045  2904.0            Classics    4.22   \n",
       "3854           767              11725  4211.0            Classics    4.35   \n",
       "\n",
       "      successful                                 lemmatized_summary    neg  \\\n",
       "0          False  alice adventure wonderland robert sabuda amaze...  0.000   \n",
       "1          False  take bath big job mercer mayer famous little c...  0.008   \n",
       "2          False  rat wall short lovecraft write augustseptember...  0.015   \n",
       "3          False    flock hapless sheep drive country rhyme picture  0.167   \n",
       "4          False  note beverly cleary guide teacher accompany ti...  0.000   \n",
       "...          ...                                                ...    ...   \n",
       "3849       False  latest installment highly acclaim internationa...  0.143   \n",
       "3851       False  year war come jamie frasers wife tell little w...  0.130   \n",
       "3852       False  tolstoy epic masterpiece intertwine life priva...  0.087   \n",
       "3853       False  firmly ground hallmark strength norton antholo...  0.000   \n",
       "3854       False  surface traditional bildungsroman describe nar...  0.079   \n",
       "\n",
       "      neutral    pos  compound      sentiment  \n",
       "0       0.627  0.373    0.9718  very positive  \n",
       "1       0.781  0.211    0.9811  very positive  \n",
       "2       0.985  0.000   -0.1779       negative  \n",
       "3       0.833  0.000   -0.3400       negative  \n",
       "4       0.809  0.191    0.8570  very positive  \n",
       "...       ...    ...       ...            ...  \n",
       "3849    0.806  0.051   -0.9437  very negative  \n",
       "3851    0.798  0.072   -0.7239  very negative  \n",
       "3852    0.781  0.132    0.7430  very positive  \n",
       "3853    0.874  0.126    0.8176  very positive  \n",
       "3854    0.863  0.058   -0.8145  very negative  \n",
       "\n",
       "[3686 rows x 12 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95731dd7",
   "metadata": {},
   "source": [
    "# split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bde3f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1af74763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, target):\n",
    "    train, test = train_test_split(df, test_size=.2, random_state=42, stratify=df[target])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5a917c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split(df,'successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "376764de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train =  train.drop(columns= \"successful\")\n",
    "y_train = train['successful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d074faeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.drop(columns= \"successful\")\n",
    "y_test = test['successful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "692b3793",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reset_index(drop= True)\n",
    "y_train = y_train.reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "bc1f5cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_test = x_test.reset_index(drop= True)\n",
    "y_test = y_test.reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3453eca",
   "metadata": {},
   "source": [
    "# creating a min max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c74e28f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainnum = x_train.select_dtypes(exclude= ['string','object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0158ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainnum = xtrainnum.drop(columns = ['neg','pos','neutral','compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d52a6bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_count</th>\n",
       "      <th>number_of_ratings</th>\n",
       "      <th>length</th>\n",
       "      <th>rating</th>\n",
       "      <th>genre_Business</th>\n",
       "      <th>genre_Chick Lit</th>\n",
       "      <th>genre_Childrens</th>\n",
       "      <th>genre_Christian</th>\n",
       "      <th>genre_Classics</th>\n",
       "      <th>genre_Comics</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Short Stories</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_Travel</th>\n",
       "      <th>genre_Urban Fantasy</th>\n",
       "      <th>genre_Vampires</th>\n",
       "      <th>genre_Young Adult</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_very negative</th>\n",
       "      <th>sentiment_very positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12558</td>\n",
       "      <td>116363</td>\n",
       "      <td>310.0</td>\n",
       "      <td>3.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3371</td>\n",
       "      <td>153866</td>\n",
       "      <td>323.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2680</td>\n",
       "      <td>63466</td>\n",
       "      <td>293.0</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>79</td>\n",
       "      <td>130.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>2052</td>\n",
       "      <td>28572</td>\n",
       "      <td>353.0</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>26711</td>\n",
       "      <td>511652</td>\n",
       "      <td>229.0</td>\n",
       "      <td>3.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>1002</td>\n",
       "      <td>18369</td>\n",
       "      <td>280.0</td>\n",
       "      <td>4.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>31042</td>\n",
       "      <td>922768</td>\n",
       "      <td>320.0</td>\n",
       "      <td>4.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>738 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     review_count  number_of_ratings  length  rating  genre_Business  \\\n",
       "0           12558             116363   310.0    3.71               0   \n",
       "1               9                 38    32.0    3.82               0   \n",
       "2            3371             153866   323.0    3.96               0   \n",
       "3            2680              63466   293.0    3.86               0   \n",
       "4              11                 79   130.0    4.47               0   \n",
       "..            ...                ...     ...     ...             ...   \n",
       "733          2052              28572   353.0    4.16               0   \n",
       "734         26711             511652   229.0    3.53               0   \n",
       "735          1002              18369   280.0    4.27               0   \n",
       "736         31042             922768   320.0    4.36               0   \n",
       "737             3                 21    41.0    3.86               0   \n",
       "\n",
       "     genre_Chick Lit  genre_Childrens  genre_Christian  genre_Classics  \\\n",
       "0                  0                0                0               0   \n",
       "1                  0                0                0               0   \n",
       "2                  0                0                0               0   \n",
       "3                  0                0                0               0   \n",
       "4                  0                0                0               0   \n",
       "..               ...              ...              ...             ...   \n",
       "733                0                0                0               0   \n",
       "734                0                0                0               0   \n",
       "735                0                0                0               0   \n",
       "736                0                0                0               0   \n",
       "737                0                0                0               0   \n",
       "\n",
       "     genre_Comics  ...  genre_Short Stories  genre_Thriller  genre_Travel  \\\n",
       "0               0  ...                    0               0             0   \n",
       "1               0  ...                    0               0             0   \n",
       "2               0  ...                    0               0             0   \n",
       "3               0  ...                    0               0             0   \n",
       "4               0  ...                    0               0             0   \n",
       "..            ...  ...                  ...             ...           ...   \n",
       "733             0  ...                    0               0             0   \n",
       "734             0  ...                    0               0             0   \n",
       "735             0  ...                    0               0             0   \n",
       "736             0  ...                    0               0             0   \n",
       "737             0  ...                    0               0             0   \n",
       "\n",
       "     genre_Urban Fantasy  genre_Vampires  genre_Young Adult  \\\n",
       "0                      0               0                  0   \n",
       "1                      0               0                  0   \n",
       "2                      0               0                  1   \n",
       "3                      0               0                  0   \n",
       "4                      0               0                  0   \n",
       "..                   ...             ...                ...   \n",
       "733                    0               0                  1   \n",
       "734                    0               0                  1   \n",
       "735                    0               0                  0   \n",
       "736                    0               0                  0   \n",
       "737                    0               0                  0   \n",
       "\n",
       "     sentiment_neutral  sentiment_positive  sentiment_very negative  \\\n",
       "0                    0                   0                        0   \n",
       "1                    0                   0                        0   \n",
       "2                    0                   0                        0   \n",
       "3                    0                   0                        1   \n",
       "4                    0                   0                        0   \n",
       "..                 ...                 ...                      ...   \n",
       "733                  0                   0                        0   \n",
       "734                  0                   0                        0   \n",
       "735                  0                   0                        0   \n",
       "736                  0                   0                        0   \n",
       "737                  0                   0                        1   \n",
       "\n",
       "     sentiment_very positive  \n",
       "0                          1  \n",
       "1                          1  \n",
       "2                          1  \n",
       "3                          0  \n",
       "4                          1  \n",
       "..                       ...  \n",
       "733                        1  \n",
       "734                        1  \n",
       "735                        1  \n",
       "736                        0  \n",
       "737                        0  \n",
       "\n",
       "[738 rows x 43 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrainnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0af9af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainnum = xtrainnum[['review_count','number_of_ratings','length','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "95487a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "04dc8604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "# Note that we only call .fit with the training data,\n",
    "# but we use .transform to apply the scaling to all the data splits.\n",
    "scaler.fit(xtrainnum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "6671c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_ls = xtrainnum.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a58cdb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['review_count', 'number_of_ratings', 'length', 'rating']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7ab35744",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = scaler.transform(x_train[number_ls])\n",
    "x_test_scaled = scaler.transform(x_test[number_ls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "0497e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = pd.DataFrame(x_train_scaled, columns= [number_ls])\n",
    "x_test_scaled = pd.DataFrame(x_test_scaled, columns= [number_ls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "74e8d462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neutral</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.147</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.0644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.234</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.9918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.180</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.9259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.126</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.8074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.185</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>0.030</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.9849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.7436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>0.105</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.9153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.4559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2948 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        neg  neutral    pos  compound\n",
       "0     0.147    0.717  0.136   -0.0644\n",
       "1     0.234    0.702  0.064   -0.9918\n",
       "2     0.180    0.664  0.156   -0.9259\n",
       "3     0.126    0.818  0.056   -0.8074\n",
       "4     0.185    0.591  0.224    0.1531\n",
       "...     ...      ...    ...       ...\n",
       "2943  0.030    0.720  0.250    0.9849\n",
       "2944  0.125    0.788  0.087   -0.7436\n",
       "2945  0.105    0.796  0.099   -0.6124\n",
       "2946  0.000    0.901  0.099    0.9153\n",
       "2947  0.000    0.952  0.048    0.4559\n",
       "\n",
       "[2948 rows x 4 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[['neg','neutral','pos','compound']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "5639f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled[['neg','neutral','pos','compound']] = x_train[['neg','neutral','pos','compound']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "58b06408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(review_count,)</th>\n",
       "      <th>(number_of_ratings,)</th>\n",
       "      <th>(length,)</th>\n",
       "      <th>(rating,)</th>\n",
       "      <th>(neg,)</th>\n",
       "      <th>(neutral,)</th>\n",
       "      <th>(pos,)</th>\n",
       "      <th>(compound,)</th>\n",
       "      <th>genre_Business</th>\n",
       "      <th>genre_Chick Lit</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Short Stories</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_Travel</th>\n",
       "      <th>genre_Urban Fantasy</th>\n",
       "      <th>genre_Vampires</th>\n",
       "      <th>genre_Young Adult</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_very negative</th>\n",
       "      <th>sentiment_very positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.472791</td>\n",
       "      <td>-0.322874</td>\n",
       "      <td>0.039140</td>\n",
       "      <td>-0.393078</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.0644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.436369</td>\n",
       "      <td>-0.347805</td>\n",
       "      <td>0.352410</td>\n",
       "      <td>1.961993</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.9918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.413854</td>\n",
       "      <td>-0.323556</td>\n",
       "      <td>0.813101</td>\n",
       "      <td>0.138712</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.9259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.434524</td>\n",
       "      <td>-0.347706</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.100727</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.8074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.242344</td>\n",
       "      <td>-0.237197</td>\n",
       "      <td>-0.255702</td>\n",
       "      <td>-0.507033</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-0.341579</td>\n",
       "      <td>-1.213940</td>\n",
       "      <td>-0.317108</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>6.235392</td>\n",
       "      <td>3.210703</td>\n",
       "      <td>0.297127</td>\n",
       "      <td>2.227888</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.7436</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>0.324439</td>\n",
       "      <td>-0.020416</td>\n",
       "      <td>0.006892</td>\n",
       "      <td>0.556547</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.6124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>-0.423843</td>\n",
       "      <td>-0.307491</td>\n",
       "      <td>0.333982</td>\n",
       "      <td>-0.013228</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>-0.469103</td>\n",
       "      <td>-0.336210</td>\n",
       "      <td>-1.213940</td>\n",
       "      <td>-0.507033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.4559</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2948 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (review_count,)  (number_of_ratings,)  (length,)  (rating,)  (neg,)  \\\n",
       "0           -0.472791             -0.322874   0.039140  -0.393078   0.147   \n",
       "1           -0.436369             -0.347805   0.352410   1.961993   0.234   \n",
       "2           -0.413854             -0.323556   0.813101   0.138712   0.180   \n",
       "3           -0.434524             -0.347706   0.002285   0.100727   0.126   \n",
       "4           -0.242344             -0.237197  -0.255702  -0.507033   0.185   \n",
       "...               ...                   ...        ...        ...     ...   \n",
       "2943        -0.390341             -0.341579  -1.213940  -0.317108   0.030   \n",
       "2944         6.235392              3.210703   0.297127   2.227888   0.125   \n",
       "2945         0.324439             -0.020416   0.006892   0.556547   0.105   \n",
       "2946        -0.423843             -0.307491   0.333982  -0.013228   0.000   \n",
       "2947        -0.469103             -0.336210  -1.213940  -0.507033   0.000   \n",
       "\n",
       "      (neutral,)  (pos,)  (compound,)  genre_Business  genre_Chick Lit  ...  \\\n",
       "0          0.717   0.136      -0.0644               0                0  ...   \n",
       "1          0.702   0.064      -0.9918               0                0  ...   \n",
       "2          0.664   0.156      -0.9259               0                0  ...   \n",
       "3          0.818   0.056      -0.8074               0                0  ...   \n",
       "4          0.591   0.224       0.1531               0                0  ...   \n",
       "...          ...     ...          ...             ...              ...  ...   \n",
       "2943       0.720   0.250       0.9849               0                0  ...   \n",
       "2944       0.788   0.087      -0.7436               0                0  ...   \n",
       "2945       0.796   0.099      -0.6124               0                0  ...   \n",
       "2946       0.901   0.099       0.9153               0                0  ...   \n",
       "2947       0.952   0.048       0.4559               0                0  ...   \n",
       "\n",
       "      genre_Short Stories  genre_Thriller  genre_Travel  genre_Urban Fantasy  \\\n",
       "0                       0               0             0                    0   \n",
       "1                       0               0             0                    0   \n",
       "2                       0               0             0                    0   \n",
       "3                       0               0             0                    0   \n",
       "4                       0               0             0                    0   \n",
       "...                   ...             ...           ...                  ...   \n",
       "2943                    0               0             0                    0   \n",
       "2944                    0               0             0                    0   \n",
       "2945                    0               0             0                    0   \n",
       "2946                    0               0             0                    0   \n",
       "2947                    0               0             0                    0   \n",
       "\n",
       "      genre_Vampires  genre_Young Adult  sentiment_neutral  \\\n",
       "0                  0                  0                  0   \n",
       "1                  0                  0                  0   \n",
       "2                  0                  0                  0   \n",
       "3                  0                  0                  0   \n",
       "4                  0                  0                  0   \n",
       "...              ...                ...                ...   \n",
       "2943               0                  0                  0   \n",
       "2944               0                  0                  0   \n",
       "2945               0                  0                  0   \n",
       "2946               0                  0                  0   \n",
       "2947               0                  0                  0   \n",
       "\n",
       "      sentiment_positive  sentiment_very negative  sentiment_very positive  \n",
       "0                      0                        0                        0  \n",
       "1                      0                        1                        0  \n",
       "2                      0                        1                        0  \n",
       "3                      0                        1                        0  \n",
       "4                      1                        0                        0  \n",
       "...                  ...                      ...                      ...  \n",
       "2943                   0                        0                        1  \n",
       "2944                   0                        1                        0  \n",
       "2945                   0                        1                        0  \n",
       "2946                   0                        0                        1  \n",
       "2947                   1                        0                        0  \n",
       "\n",
       "[2948 rows x 47 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "8e1a12e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scaled[['neg','neutral','pos','compound']] = x_test[['neg','neutral','pos','compound']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1fed2ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = train[comb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b143ab39",
   "metadata": {},
   "source": [
    "# create dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5ed97315",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = pd.concat([x_train_scaled, x_train[comb]],axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "983d9a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scaled = pd.concat([x_test_scaled, x_test[comb]],axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "b5fea0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(review_count,)</th>\n",
       "      <th>(number_of_ratings,)</th>\n",
       "      <th>(length,)</th>\n",
       "      <th>(rating,)</th>\n",
       "      <th>(neg,)</th>\n",
       "      <th>(neutral,)</th>\n",
       "      <th>(pos,)</th>\n",
       "      <th>(compound,)</th>\n",
       "      <th>genre_Business</th>\n",
       "      <th>genre_Chick Lit</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Short Stories</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_Travel</th>\n",
       "      <th>genre_Urban Fantasy</th>\n",
       "      <th>genre_Vampires</th>\n",
       "      <th>genre_Young Adult</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_very negative</th>\n",
       "      <th>sentiment_very positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.472791</td>\n",
       "      <td>-0.322874</td>\n",
       "      <td>0.03914</td>\n",
       "      <td>-0.393078</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.0644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (review_count,)  (number_of_ratings,)  (length,)  (rating,)  (neg,)  \\\n",
       "0        -0.472791             -0.322874    0.03914  -0.393078   0.147   \n",
       "\n",
       "   (neutral,)  (pos,)  (compound,)  genre_Business  genre_Chick Lit  ...  \\\n",
       "0       0.717   0.136      -0.0644               0                0  ...   \n",
       "\n",
       "   genre_Short Stories  genre_Thriller  genre_Travel  genre_Urban Fantasy  \\\n",
       "0                    0               0             0                    0   \n",
       "\n",
       "   genre_Vampires  genre_Young Adult  sentiment_neutral  sentiment_positive  \\\n",
       "0               0                  0                  0                   0   \n",
       "\n",
       "   sentiment_very negative  sentiment_very positive  \n",
       "0                        0                        0  \n",
       "\n",
       "[1 rows x 47 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled.head(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "9e8a929a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(review_count,)</th>\n",
       "      <th>(number_of_ratings,)</th>\n",
       "      <th>(length,)</th>\n",
       "      <th>(rating,)</th>\n",
       "      <th>(neg,)</th>\n",
       "      <th>(neutral,)</th>\n",
       "      <th>(pos,)</th>\n",
       "      <th>(compound,)</th>\n",
       "      <th>genre_Business</th>\n",
       "      <th>genre_Chick Lit</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Short Stories</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_Travel</th>\n",
       "      <th>genre_Urban Fantasy</th>\n",
       "      <th>genre_Vampires</th>\n",
       "      <th>genre_Young Adult</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_very negative</th>\n",
       "      <th>sentiment_very positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.456529</td>\n",
       "      <td>0.007394</td>\n",
       "      <td>-0.301771</td>\n",
       "      <td>-1.152778</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (review_count,)  (number_of_ratings,)  (length,)  (rating,)  (neg,)  \\\n",
       "0         0.456529              0.007394  -0.301771  -1.152778   0.031   \n",
       "\n",
       "   (neutral,)  (pos,)  (compound,)  genre_Business  genre_Chick Lit  ...  \\\n",
       "0       0.797   0.172       0.9647               0                0  ...   \n",
       "\n",
       "   genre_Short Stories  genre_Thriller  genre_Travel  genre_Urban Fantasy  \\\n",
       "0                    0               0             0                    0   \n",
       "\n",
       "   genre_Vampires  genre_Young Adult  sentiment_neutral  sentiment_positive  \\\n",
       "0               0                  0                  0                   0   \n",
       "\n",
       "   sentiment_very negative  sentiment_very positive  \n",
       "0                        0                        1  \n",
       "\n",
       "[1 rows x 47 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "bd615c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/common.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(review_count,)</th>\n",
       "      <th>(number_of_ratings,)</th>\n",
       "      <th>(length,)</th>\n",
       "      <th>(rating,)</th>\n",
       "      <th>(neg,)</th>\n",
       "      <th>(neutral,)</th>\n",
       "      <th>(pos,)</th>\n",
       "      <th>(compound,)</th>\n",
       "      <th>genre_Business</th>\n",
       "      <th>genre_Chick Lit</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Short Stories</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_Travel</th>\n",
       "      <th>genre_Urban Fantasy</th>\n",
       "      <th>genre_Vampires</th>\n",
       "      <th>genre_Young Adult</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_very negative</th>\n",
       "      <th>sentiment_very positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.472791</td>\n",
       "      <td>-0.322874</td>\n",
       "      <td>0.039140</td>\n",
       "      <td>-0.393078</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.0644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.436369</td>\n",
       "      <td>-0.347805</td>\n",
       "      <td>0.352410</td>\n",
       "      <td>1.961993</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.9918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.413854</td>\n",
       "      <td>-0.323556</td>\n",
       "      <td>0.813101</td>\n",
       "      <td>0.138712</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.9259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.434524</td>\n",
       "      <td>-0.347706</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.100727</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.8074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.242344</td>\n",
       "      <td>-0.237197</td>\n",
       "      <td>-0.255702</td>\n",
       "      <td>-0.507033</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-0.341579</td>\n",
       "      <td>-1.213940</td>\n",
       "      <td>-0.317108</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>6.235392</td>\n",
       "      <td>3.210703</td>\n",
       "      <td>0.297127</td>\n",
       "      <td>2.227888</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.7436</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>0.324439</td>\n",
       "      <td>-0.020416</td>\n",
       "      <td>0.006892</td>\n",
       "      <td>0.556547</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.6124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>-0.423843</td>\n",
       "      <td>-0.307491</td>\n",
       "      <td>0.333982</td>\n",
       "      <td>-0.013228</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>-0.469103</td>\n",
       "      <td>-0.336210</td>\n",
       "      <td>-1.213940</td>\n",
       "      <td>-0.507033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.4559</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2948 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (review_count,)  (number_of_ratings,)  (length,)  (rating,)  (neg,)  \\\n",
       "0           -0.472791             -0.322874   0.039140  -0.393078   0.147   \n",
       "1           -0.436369             -0.347805   0.352410   1.961993   0.234   \n",
       "2           -0.413854             -0.323556   0.813101   0.138712   0.180   \n",
       "3           -0.434524             -0.347706   0.002285   0.100727   0.126   \n",
       "4           -0.242344             -0.237197  -0.255702  -0.507033   0.185   \n",
       "...               ...                   ...        ...        ...     ...   \n",
       "2943        -0.390341             -0.341579  -1.213940  -0.317108   0.030   \n",
       "2944         6.235392              3.210703   0.297127   2.227888   0.125   \n",
       "2945         0.324439             -0.020416   0.006892   0.556547   0.105   \n",
       "2946        -0.423843             -0.307491   0.333982  -0.013228   0.000   \n",
       "2947        -0.469103             -0.336210  -1.213940  -0.507033   0.000   \n",
       "\n",
       "      (neutral,)  (pos,)  (compound,)  genre_Business  genre_Chick Lit  ...  \\\n",
       "0          0.717   0.136      -0.0644               0                0  ...   \n",
       "1          0.702   0.064      -0.9918               0                0  ...   \n",
       "2          0.664   0.156      -0.9259               0                0  ...   \n",
       "3          0.818   0.056      -0.8074               0                0  ...   \n",
       "4          0.591   0.224       0.1531               0                0  ...   \n",
       "...          ...     ...          ...             ...              ...  ...   \n",
       "2943       0.720   0.250       0.9849               0                0  ...   \n",
       "2944       0.788   0.087      -0.7436               0                0  ...   \n",
       "2945       0.796   0.099      -0.6124               0                0  ...   \n",
       "2946       0.901   0.099       0.9153               0                0  ...   \n",
       "2947       0.952   0.048       0.4559               0                0  ...   \n",
       "\n",
       "      genre_Short Stories  genre_Thriller  genre_Travel  genre_Urban Fantasy  \\\n",
       "0                       0               0             0                    0   \n",
       "1                       0               0             0                    0   \n",
       "2                       0               0             0                    0   \n",
       "3                       0               0             0                    0   \n",
       "4                       0               0             0                    0   \n",
       "...                   ...             ...           ...                  ...   \n",
       "2943                    0               0             0                    0   \n",
       "2944                    0               0             0                    0   \n",
       "2945                    0               0             0                    0   \n",
       "2946                    0               0             0                    0   \n",
       "2947                    0               0             0                    0   \n",
       "\n",
       "      genre_Vampires  genre_Young Adult  sentiment_neutral  \\\n",
       "0                  0                  0                  0   \n",
       "1                  0                  0                  0   \n",
       "2                  0                  0                  0   \n",
       "3                  0                  0                  0   \n",
       "4                  0                  0                  0   \n",
       "...              ...                ...                ...   \n",
       "2943               0                  0                  0   \n",
       "2944               0                  0                  0   \n",
       "2945               0                  0                  0   \n",
       "2946               0                  0                  0   \n",
       "2947               0                  0                  0   \n",
       "\n",
       "      sentiment_positive  sentiment_very negative  sentiment_very positive  \n",
       "0                      0                        0                        0  \n",
       "1                      0                        1                        0  \n",
       "2                      0                        1                        0  \n",
       "3                      0                        1                        0  \n",
       "4                      1                        0                        0  \n",
       "...                  ...                      ...                      ...  \n",
       "2943                   0                        0                        1  \n",
       "2944                   0                        1                        0  \n",
       "2945                   0                        1                        0  \n",
       "2946                   0                        0                        1  \n",
       "2947                   1                        0                        0  \n",
       "\n",
       "[2948 rows x 47 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled[important_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f86d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21aee482",
   "metadata": {},
   "source": [
    "# XGBOOST "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cbda2c",
   "metadata": {},
   "source": [
    "# import CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "252501b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sklearn.metrics as m\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "2c23fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whatever transformations we apply to X_train need to be applied to X_test\n",
    "# create an instance with predetermined values \n",
    "xgb_clf = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                                        seed = 42,\n",
    "                                        max_depth = 3,    \n",
    "                                        scale_pos_weight= 5,\n",
    "                                        learning_rate = .01,\n",
    "                                        subsample = .9,\n",
    "                                        colsample_bytree = .5,\n",
    "                                        n_jobs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "4eaa3d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96101695, 0.96271186, 0.95762712, 0.95585739, 0.95585739])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(xgb_clf, x_train_scaled, y_train, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "18cc4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def th_hyperparam_tuning(x_train, y_train, x_test, y_test, max_depths, scale_pos_weights, learning_rates, subsamples, colsample_bytrees):\n",
    "    for max_depth in max_depths:\n",
    "        for scale_pos_weight in scale_pos_weights:\n",
    "            for learning_rate in learning_rates:\n",
    "                for subsample in subsamples:\n",
    "                    for colsample_bytree in colsample_bytrees:\n",
    "                        # define the XGBClassifier with the current hyperparameters\n",
    "                        xgb_model = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                                                  seed=42,\n",
    "                                                  max_depth=max_depth,\n",
    "                                                  scale_pos_weight=scale_pos_weight,\n",
    "                                                  learning_rate=learning_rate,\n",
    "                                                  subsample=subsample,\n",
    "                                                  colsample_bytree=colsample_bytree,\n",
    "                                                  n_jobs=10)\n",
    "                        # fit the model on the training set\n",
    "                        xgb_model.fit(x_train, y_train)\n",
    "                        # predict on the test set\n",
    "                        y_pred = xgb_model.predict(x_test)\n",
    "                        # print the hyperparameters and the resulting f1-score\n",
    "                        print(f\"max_depth={max_depth}, scale_pos_weight={scale_pos_weight}, learning_rate={learning_rate}, subsample={subsample}, colsample_bytree={colsample_bytree}: f1-score={f1_score(y_test, y_pred)},: recall-score={recall_score(y_test, y_pred)}\")\n",
    "                        print('\\n')\n",
    "                        # print the confusion matrix\n",
    "                        print(confusion_matrix(y_test, y_pred))\n",
    "                        print('\\n')\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "28f83836",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [3, 5, 7]\n",
    "scale_pos_weights = [3, 5, 7]\n",
    "learning_rates = [0.01, 0.1, 1]\n",
    "subsamples = [0.7, 0.8, 0.9]\n",
    "colsample_bytrees = [0.5, 0.6, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666d43f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.3880597014925374,: recall-score=0.40625\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc1bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.4225352112676056,: recall-score=0.46875\n",
    "\n",
    "\n",
    "[[682  24]\n",
    " [ 17  15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "b7a382ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/common.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/common.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.0,: recall-score=0.0\n",
      "\n",
      "\n",
      "[[706   0]\n",
      " [ 32   0]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.11764705882352941,: recall-score=0.0625\n",
      "\n",
      "\n",
      "[[706   0]\n",
      " [ 30   2]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.16666666666666666,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.0,: recall-score=0.0\n",
      "\n",
      "\n",
      "[[706   0]\n",
      " [ 32   0]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.16666666666666666,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.16666666666666666,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.0,: recall-score=0.0\n",
      "\n",
      "\n",
      "[[706   0]\n",
      " [ 32   0]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.16666666666666666,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.16666666666666666,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.375,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[699   7]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.34615384615384615,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[695  11]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.34615384615384615,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[695  11]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.3404255319148936,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[699   7]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.36,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.3703703703703703,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.3333333333333333,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[698   8]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.32653061224489793,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.3673469387755102,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[698   8]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.28,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[695  11]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.25531914893617025,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.2545454545454546,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[690  16]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.23076923076923075,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[692  14]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.3076923076923077,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.1702127659574468,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[695  11]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.3103448275862069,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[689  17]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.2909090909090909,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[691  15]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.3396226415094339,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.29268292682926833,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[703   3]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.29268292682926833,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[703   3]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.3,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[704   2]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.34146341463414637,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[704   2]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.29268292682926833,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[703   3]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.2631578947368421,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.3,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[704   2]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.3333333333333333,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[703   3]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.3880597014925374,: recall-score=0.40625\n",
      "\n",
      "\n",
      "[[684  22]\n",
      " [ 19  13]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.3636363636363636,: recall-score=0.375\n",
      "\n",
      "\n",
      "[[684  22]\n",
      " [ 20  12]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.3278688524590164,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[687  19]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.375,: recall-score=0.375\n",
      "\n",
      "\n",
      "[[686  20]\n",
      " [ 20  12]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.4225352112676056,: recall-score=0.46875\n",
      "\n",
      "\n",
      "[[682  24]\n",
      " [ 17  15]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.41791044776119407,: recall-score=0.4375\n",
      "\n",
      "\n",
      "[[685  21]\n",
      " [ 18  14]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.3880597014925374,: recall-score=0.40625\n",
      "\n",
      "\n",
      "[[684  22]\n",
      " [ 19  13]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.3636363636363636,: recall-score=0.375\n",
      "\n",
      "\n",
      "[[684  22]\n",
      " [ 20  12]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.41791044776119407,: recall-score=0.4375\n",
      "\n",
      "\n",
      "[[685  21]\n",
      " [ 18  14]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.2413793103448276,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[687  19]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.2545454545454546,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[690  16]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.25925925925925924,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[691  15]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.34615384615384615,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[695  11]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.3050847457627119,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[688  18]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.35714285714285715,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[692  14]\n",
      " [ 22  10]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.3137254901960784,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[695  11]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.2641509433962264,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[692  14]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.25925925925925924,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[691  15]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.3333333333333333,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[698   8]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.4262295081967213,: recall-score=0.40625\n",
      "\n",
      "\n",
      "[[690  16]\n",
      " [ 19  13]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.4615384615384615,: recall-score=0.46875\n",
      "\n",
      "\n",
      "[[688  18]\n",
      " [ 17  15]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.39215686274509803,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.39999999999999997,: recall-score=0.375\n",
      "\n",
      "\n",
      "[[690  16]\n",
      " [ 20  12]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.39999999999999997,: recall-score=0.4375\n",
      "\n",
      "\n",
      "[[682  24]\n",
      " [ 18  14]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.4166666666666667,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[700   6]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.36065573770491804,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[688  18]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.4444444444444445,: recall-score=0.5\n",
      "\n",
      "\n",
      "[[682  24]\n",
      " [ 16  16]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.379746835443038,: recall-score=0.46875\n",
      "\n",
      "\n",
      "[[674  32]\n",
      " [ 17  15]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.325,: recall-score=0.40625\n",
      "\n",
      "\n",
      "[[671  35]\n",
      " [ 19  13]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.3636363636363637,: recall-score=0.4375\n",
      "\n",
      "\n",
      "[[675  31]\n",
      " [ 18  14]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.375,: recall-score=0.46875\n",
      "\n",
      "\n",
      "[[673  33]\n",
      " [ 17  15]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.325,: recall-score=0.40625\n",
      "\n",
      "\n",
      "[[671  35]\n",
      " [ 19  13]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.3703703703703704,: recall-score=0.46875\n",
      "\n",
      "\n",
      "[[672  34]\n",
      " [ 17  15]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.36585365853658536,: recall-score=0.46875\n",
      "\n",
      "\n",
      "[[671  35]\n",
      " [ 17  15]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.35000000000000003,: recall-score=0.4375\n",
      "\n",
      "\n",
      "[[672  34]\n",
      " [ 18  14]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.36585365853658536,: recall-score=0.46875\n",
      "\n",
      "\n",
      "[[671  35]\n",
      " [ 17  15]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.2692307692307692,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[693  13]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.36,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.3380281690140845,: recall-score=0.375\n",
      "\n",
      "\n",
      "[[679  27]\n",
      " [ 20  12]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.27586206896551724,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[688  18]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.23076923076923075,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[692  14]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.37735849056603776,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[695  11]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.21818181818181817,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[689  17]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.2745098039215686,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=3, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.2745098039215686,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.11764705882352941,: recall-score=0.0625\n",
      "\n",
      "\n",
      "[[706   0]\n",
      " [ 30   2]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.2631578947368421,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.11428571428571428,: recall-score=0.0625\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 30   2]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.30769230769230765,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.17142857142857143,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[706   0]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.2631578947368421,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.30769230769230765,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.35555555555555557,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[701   5]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.40816326530612246,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[699   7]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.34782608695652173,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[700   6]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.4166666666666667,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[700   6]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.3404255319148936,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[699   7]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.3673469387755102,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[698   8]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.425531914893617,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[701   5]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.2978723404255319,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[698   8]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.375,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[699   7]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.13636363636363635,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.34615384615384615,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[695  11]\n",
      " [ 23   9]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.19999999999999998,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[693  13]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.19047619047619047,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[700   6]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.21739130434782608,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.2978723404255319,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[698   8]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.2641509433962264,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[692  14]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.34615384615384615,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[695  11]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.26086956521739124,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[698   8]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.3255813953488372,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[702   4]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.3255813953488372,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[702   4]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.3,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[704   2]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.3333333333333333,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[703   3]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.3111111111111111,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[700   6]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.30769230769230765,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.30769230769230765,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.26086956521739124,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[698   8]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.39215686274509803,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.3396226415094339,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.34615384615384615,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[695  11]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.4150943396226415,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[696  10]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.3333333333333333,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[693  13]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.39285714285714285,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[693  13]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.39215686274509803,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.3396226415094339,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.42857142857142855,: recall-score=0.375\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 20  12]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.30434782608695654,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[699   7]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.2916666666666667,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.2857142857142857,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[696  10]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.17777777777777778,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.26086956521739124,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[698   8]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.2745098039215686,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.2727272727272727,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[700   6]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.2127659574468085,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[696  10]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.3404255319148936,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[699   7]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.43478260869565216,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[702   4]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.45614035087719296,: recall-score=0.40625\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 19  13]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.375,: recall-score=0.375\n",
      "\n",
      "\n",
      "[[686  20]\n",
      " [ 20  12]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.47058823529411764,: recall-score=0.375\n",
      "\n",
      "\n",
      "[[699   7]\n",
      " [ 20  12]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.4827586206896552,: recall-score=0.4375\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 18  14]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.3934426229508197,: recall-score=0.375\n",
      "\n",
      "\n",
      "[[689  17]\n",
      " [ 20  12]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.34782608695652173,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[700   6]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.3666666666666667,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[689  17]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.3880597014925374,: recall-score=0.40625\n",
      "\n",
      "\n",
      "[[684  22]\n",
      " [ 19  13]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.45614035087719296,: recall-score=0.40625\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 19  13]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.39285714285714285,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[693  13]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.4,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.3793103448275862,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[691  15]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.3934426229508197,: recall-score=0.375\n",
      "\n",
      "\n",
      "[[689  17]\n",
      " [ 20  12]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.3278688524590164,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[687  19]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.38709677419354843,: recall-score=0.375\n",
      "\n",
      "\n",
      "[[688  18]\n",
      " [ 20  12]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.39999999999999997,: recall-score=0.375\n",
      "\n",
      "\n",
      "[[690  16]\n",
      " [ 20  12]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.37288135593220334,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[690  16]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.24489795918367344,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[695  11]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.3157894736842105,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[690  16]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.3076923076923077,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.3396226415094339,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.25925925925925924,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[691  15]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.3076923076923077,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.21739130434782608,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.2962962962962963,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[692  14]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=5, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.19607843137254902,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[692  14]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.17142857142857143,: recall-score=0.09375\n",
      "\n",
      "\n",
      "[[706   0]\n",
      " [ 29   3]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.2631578947368421,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.11428571428571428,: recall-score=0.0625\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 30   2]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.30769230769230765,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.2222222222222222,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[706   0]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.25641025641025644,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[704   2]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.29268292682926833,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[703   3]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.3,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[704   2]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.23809523809523808,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[701   5]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.3404255319148936,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[699   7]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.34146341463414637,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[704   2]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.4166666666666667,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[700   6]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.4,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[702   4]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.3255813953488372,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[702   4]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.4444444444444445,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[703   3]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.3255813953488372,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[702   4]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.32653061224489793,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.2127659574468085,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[696  10]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.21739130434782608,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.24000000000000005,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.32653061224489793,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.32653061224489793,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.25,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[696  10]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.26666666666666666,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[699   7]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=3, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.31818181818181823,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[701   5]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.21621621621621623,: recall-score=0.125\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 28   4]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.35,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.29268292682926833,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[703   3]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.2631578947368421,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.29268292682926833,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[703   3]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.3111111111111111,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[700   6]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.2631578947368421,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[705   1]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.3,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[704   2]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.27906976744186046,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[701   5]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.36363636363636365,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[702   4]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.3111111111111111,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[700   6]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.35555555555555557,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[701   5]\n",
      " [ 24   8]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.35555555555555557,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[701   5]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.44000000000000006,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[699   7]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.375,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[699   7]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.391304347826087,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[701   5]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.3333333333333333,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[698   8]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.4489795918367347,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[700   6]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.2127659574468085,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[696  10]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.39215686274509803,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.3076923076923077,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.2962962962962963,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[692  14]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.3703703703703703,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.25,: recall-score=0.1875\n",
      "\n",
      "\n",
      "[[696  10]\n",
      " [ 26   6]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.39999999999999997,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[698   8]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.4150943396226415,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[696  10]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=5, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.32,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[696  10]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.5: f1-score=0.3255813953488372,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[702   4]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.6: f1-score=0.3673469387755102,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[698   8]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.7, colsample_bytree=0.7: f1-score=0.4150943396226415,: recall-score=0.34375\n",
      "\n",
      "\n",
      "[[696  10]\n",
      " [ 21  11]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.5: f1-score=0.36363636363636365,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[702   4]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.6: f1-score=0.34782608695652173,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[700   6]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.8, colsample_bytree=0.7: f1-score=0.38461538461538464,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[696  10]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.5: f1-score=0.391304347826087,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[701   5]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.6: f1-score=0.35294117647058826,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[696  10]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.2692307692307692,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[693  13]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.5: f1-score=0.34782608695652173,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[700   6]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.6: f1-score=0.2978723404255319,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[698   8]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7: f1-score=0.3333333333333333,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[698   8]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.5: f1-score=0.40816326530612246,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[699   7]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.6: f1-score=0.39999999999999997,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[698   8]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.8, colsample_bytree=0.7: f1-score=0.36,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.5: f1-score=0.391304347826087,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[701   5]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.6: f1-score=0.4166666666666667,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[700   6]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=0.1, subsample=0.9, colsample_bytree=0.7: f1-score=0.4166666666666667,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[700   6]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.5: f1-score=0.34615384615384615,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[695  11]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.6: f1-score=0.2127659574468085,: recall-score=0.15625\n",
      "\n",
      "\n",
      "[[696  10]\n",
      " [ 27   5]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.7, colsample_bytree=0.7: f1-score=0.30434782608695654,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[699   7]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.5: f1-score=0.3076923076923077,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[694  12]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.6: f1-score=0.37735849056603776,: recall-score=0.3125\n",
      "\n",
      "\n",
      "[[695  11]\n",
      " [ 22  10]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.8, colsample_bytree=0.7: f1-score=0.2857142857142857,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[696  10]\n",
      " [ 25   7]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.5: f1-score=0.2807017543859649,: recall-score=0.25\n",
      "\n",
      "\n",
      "[[689  17]\n",
      " [ 24   8]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.6: f1-score=0.36,: recall-score=0.28125\n",
      "\n",
      "\n",
      "[[697   9]\n",
      " [ 23   9]]\n",
      "\n",
      "\n",
      "max_depth=7, scale_pos_weight=7, learning_rate=1, subsample=0.9, colsample_bytree=0.7: f1-score=0.30434782608695654,: recall-score=0.21875\n",
      "\n",
      "\n",
      "[[699   7]\n",
      " [ 25   7]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "th_hyperparam_tuning(x_train_scaled[important_feats], y_train, x_test_scaled[important_feats], y_test, max_depths, scale_pos_weights, learning_rates, subsamples, colsample_bytrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the most important feats\n",
    "max_depth=3, scale_pos_weight=7, learning_rate=0.01, subsample=0.9, colsample_bytree=0.7: f1-score=0.4444444444444445,: recall-score=0.5\n",
    "\n",
    "\n",
    "[[682  24]\n",
    " [ 16  16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "d0f25a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance with predetermined values \n",
    "clf_xgb = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                                        seed = 42,\n",
    "                                        max_depth = 3,    \n",
    "                                        scale_pos_weight= 5,\n",
    "                                        learning_rate = .01,\n",
    "                                        subsample = .9,\n",
    "                                        colsample_bytree = .5,\n",
    "                                        n_jobs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "5844095b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.5, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=10, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_xgb.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "c2901c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10706209, 0.14391436, 0.0563195 , 0.05070722, 0.03722677,\n",
       "       0.0383594 , 0.03182706, 0.0266741 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.04669446,\n",
       "       0.0527713 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.05773534, 0.        , 0.        , 0.        ,\n",
       "       0.13585968, 0.07239079, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03914009, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00232934, 0.        ,\n",
       "       0.        , 0.        , 0.046776  , 0.        , 0.        ,\n",
       "       0.04739108, 0.00682146], dtype=float32)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_xgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "a39b2546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(clf_xgb.feature_importances_, index= x_train_scaled.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')\n",
    "plt.title(\"Top 15 important features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "ae45d953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/common.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(review_count,)</th>\n",
       "      <th>(number_of_ratings,)</th>\n",
       "      <th>(length,)</th>\n",
       "      <th>(rating,)</th>\n",
       "      <th>(neg,)</th>\n",
       "      <th>(neutral,)</th>\n",
       "      <th>(pos,)</th>\n",
       "      <th>(compound,)</th>\n",
       "      <th>genre_Business</th>\n",
       "      <th>genre_Chick Lit</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Short Stories</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_Travel</th>\n",
       "      <th>genre_Urban Fantasy</th>\n",
       "      <th>genre_Vampires</th>\n",
       "      <th>genre_Young Adult</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_very negative</th>\n",
       "      <th>sentiment_very positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.472791</td>\n",
       "      <td>-0.322874</td>\n",
       "      <td>0.039140</td>\n",
       "      <td>-0.393078</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.0644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.436369</td>\n",
       "      <td>-0.347805</td>\n",
       "      <td>0.352410</td>\n",
       "      <td>1.961993</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.9918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.413854</td>\n",
       "      <td>-0.323556</td>\n",
       "      <td>0.813101</td>\n",
       "      <td>0.138712</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.9259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.434524</td>\n",
       "      <td>-0.347706</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.100727</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.8074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.242344</td>\n",
       "      <td>-0.237197</td>\n",
       "      <td>-0.255702</td>\n",
       "      <td>-0.507033</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-0.341579</td>\n",
       "      <td>-1.213940</td>\n",
       "      <td>-0.317108</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>6.235392</td>\n",
       "      <td>3.210703</td>\n",
       "      <td>0.297127</td>\n",
       "      <td>2.227888</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.7436</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>0.324439</td>\n",
       "      <td>-0.020416</td>\n",
       "      <td>0.006892</td>\n",
       "      <td>0.556547</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.6124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>-0.423843</td>\n",
       "      <td>-0.307491</td>\n",
       "      <td>0.333982</td>\n",
       "      <td>-0.013228</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>-0.469103</td>\n",
       "      <td>-0.336210</td>\n",
       "      <td>-1.213940</td>\n",
       "      <td>-0.507033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.4559</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2948 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (review_count,)  (number_of_ratings,)  (length,)  (rating,)  (neg,)  \\\n",
       "0           -0.472791             -0.322874   0.039140  -0.393078   0.147   \n",
       "1           -0.436369             -0.347805   0.352410   1.961993   0.234   \n",
       "2           -0.413854             -0.323556   0.813101   0.138712   0.180   \n",
       "3           -0.434524             -0.347706   0.002285   0.100727   0.126   \n",
       "4           -0.242344             -0.237197  -0.255702  -0.507033   0.185   \n",
       "...               ...                   ...        ...        ...     ...   \n",
       "2943        -0.390341             -0.341579  -1.213940  -0.317108   0.030   \n",
       "2944         6.235392              3.210703   0.297127   2.227888   0.125   \n",
       "2945         0.324439             -0.020416   0.006892   0.556547   0.105   \n",
       "2946        -0.423843             -0.307491   0.333982  -0.013228   0.000   \n",
       "2947        -0.469103             -0.336210  -1.213940  -0.507033   0.000   \n",
       "\n",
       "      (neutral,)  (pos,)  (compound,)  genre_Business  genre_Chick Lit  ...  \\\n",
       "0          0.717   0.136      -0.0644               0                0  ...   \n",
       "1          0.702   0.064      -0.9918               0                0  ...   \n",
       "2          0.664   0.156      -0.9259               0                0  ...   \n",
       "3          0.818   0.056      -0.8074               0                0  ...   \n",
       "4          0.591   0.224       0.1531               0                0  ...   \n",
       "...          ...     ...          ...             ...              ...  ...   \n",
       "2943       0.720   0.250       0.9849               0                0  ...   \n",
       "2944       0.788   0.087      -0.7436               0                0  ...   \n",
       "2945       0.796   0.099      -0.6124               0                0  ...   \n",
       "2946       0.901   0.099       0.9153               0                0  ...   \n",
       "2947       0.952   0.048       0.4559               0                0  ...   \n",
       "\n",
       "      genre_Short Stories  genre_Thriller  genre_Travel  genre_Urban Fantasy  \\\n",
       "0                       0               0             0                    0   \n",
       "1                       0               0             0                    0   \n",
       "2                       0               0             0                    0   \n",
       "3                       0               0             0                    0   \n",
       "4                       0               0             0                    0   \n",
       "...                   ...             ...           ...                  ...   \n",
       "2943                    0               0             0                    0   \n",
       "2944                    0               0             0                    0   \n",
       "2945                    0               0             0                    0   \n",
       "2946                    0               0             0                    0   \n",
       "2947                    0               0             0                    0   \n",
       "\n",
       "      genre_Vampires  genre_Young Adult  sentiment_neutral  \\\n",
       "0                  0                  0                  0   \n",
       "1                  0                  0                  0   \n",
       "2                  0                  0                  0   \n",
       "3                  0                  0                  0   \n",
       "4                  0                  0                  0   \n",
       "...              ...                ...                ...   \n",
       "2943               0                  0                  0   \n",
       "2944               0                  0                  0   \n",
       "2945               0                  0                  0   \n",
       "2946               0                  0                  0   \n",
       "2947               0                  0                  0   \n",
       "\n",
       "      sentiment_positive  sentiment_very negative  sentiment_very positive  \n",
       "0                      0                        0                        0  \n",
       "1                      0                        1                        0  \n",
       "2                      0                        1                        0  \n",
       "3                      0                        1                        0  \n",
       "4                      1                        0                        0  \n",
       "...                  ...                      ...                      ...  \n",
       "2943                   0                        0                        1  \n",
       "2944                   0                        1                        0  \n",
       "2945                   0                        1                        0  \n",
       "2946                   0                        0                        1  \n",
       "2947                   1                        0                        0  \n",
       "\n",
       "[2948 rows x 47 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled[important_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "3f278320",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feats = feat_importances.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97bb34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feat_importances\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba7b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d6a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1de7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c869665d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8275f1d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6793e5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f78f952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc447db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4c6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fac3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650447c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033e665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b9505b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e0ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5fedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aed622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d8b0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16903e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be3098a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a836704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14418d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccce2254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df26de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5059f3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee2565d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "789c42a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "dbd7a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3852ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pr.prep_data('all_books.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a026cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8f10f2",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f4600",
   "metadata": {},
   "source": [
    "# fit train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302899e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082353c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "a8c8f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import  ConfusionMatrixDisplay\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd95c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree.predict(x_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e37f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the recall score\n",
    "recall = recall_score(y_train, y_pred, pos_label='best seller')\n",
    "print(\"Recall score for 'best seller' class:\", recall)\n",
    "# print(\"Recall score on training data:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f81556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import  ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff092c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(\n",
    "confusion_matrix = confusion_matrix(y_train, y_pred), \n",
    "display_labels = ['unsuccessful', 'best seller'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c704a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assume y_train and y_train_pred are your target variable and predicted labels, respectively\n",
    "# and y_test and y_pred are your test set target variable and predicted labels, respectively\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].set_title(\"train\")\n",
    "ax[1].set_title(\"test\")\n",
    "\n",
    "# plot confusion matrix for training data\n",
    "ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train, y_pred),\n",
    "                       display_labels=['unsuccessful', 'best seller']).plot(ax=ax[0])\n",
    "\n",
    "# plot confusion matrix for test data\n",
    "ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train, y_pred),\n",
    "                       display_labels=['unsuccessful', 'best seller']).plot(ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98364666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume y_test and y_pred are your test set target variable and predicted labels, respectively\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "# plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['best', 'unsuccessful'])\n",
    "disp.plot()\n",
    "disp.ax_.set_title(\"Confusion Matrix for Test Data\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance with predetermined values \n",
    "clf_xgb = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                                        seed = 42,\n",
    "                                        max_depth = 3,    \n",
    "                                        scale_pos_weight= 5,\n",
    "                                        learning_rate = .01,\n",
    "                                        subsample = .9,\n",
    "                                        colsample_bytree = .5,\n",
    "                                        n_jobs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9616012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e613d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "x_bow_train = vectorizer.fit_transform(x_train)\n",
    "x_bow_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77cd96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance with predetermined values \n",
    "xgb = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                                        seed = 42,\n",
    "                                        max_depth = 3,    \n",
    "                                        scale_pos_weight= 5,\n",
    "                                        learning_rate = .01,\n",
    "                                        subsample = .9,\n",
    "                                        colsample_bytree = .5,\n",
    "                                        n_jobs = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a493bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(x_bow_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a554c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test set\n",
    "y_pred = xgb.predict(x_bow_train)\n",
    "\n",
    "# evaluate classifier performance\n",
    "accuracy = xgb.score(x_bow_train, y_train)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceecf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume y_test and y_pred are your test set target variable and predicted labels, respectively\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "# plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['best', 'unsuccessful'])\n",
    "disp.plot()\n",
    "disp.ax_.set_title(\"Confusion Matrix for Test Data\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeef96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b8c38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eb7247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2cd070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0942f533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca5f198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c9aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cd508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def th_hyperparam_tuning(x_train, y_train, x_test, y_test, max_depths, scale_pos_weights, learning_rates, subsamples, colsample_bytrees):\n",
    "    for max_depth in max_depths:\n",
    "        for scale_pos_weight in scale_pos_weights:\n",
    "            for learning_rate in learning_rates:\n",
    "                for subsample in subsamples:\n",
    "                    for colsample_bytree in colsample_bytrees:\n",
    "                        # define the XGBClassifier with the current hyperparameters\n",
    "                        xgb_model = XGBClassifier(objective ='binary:logistic', \n",
    "                                                  seed=42,\n",
    "                                                  max_depth=max_depth,\n",
    "                                                  scale_pos_weight=scale_pos_weight,\n",
    "                                                  learning_rate=learning_rate,\n",
    "                                                  subsample=subsample,\n",
    "                                                  colsample_bytree=colsample_bytree,\n",
    "                                                  n_jobs=10)\n",
    "                        # fit the model on the training set\n",
    "                        xgb_model.fit(x_train, y_train)\n",
    "                        # predict on the test set\n",
    "                        y_pred = xgb_model.predict(x_test)\n",
    "                        # print the hyperparameters and the resulting f1-score\n",
    "                        print(f\"max_depth={max_depth}, scale_pos_weight={scale_pos_weight}, learning_rate={learning_rate}, subsample={subsample}, colsample_bytree={colsample_bytree}: f1-score={f1_score(y_test, y_pred)},: recall-score={recall_score(y_test, y_pred)}\")\n",
    "                        print('\\n')\n",
    "                        # print the confusion matrix\n",
    "                        print(confusion_matrix(y_test, y_pred))\n",
    "                        print('\\n')\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e24252",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [3, 5, 7]\n",
    "scale_pos_weights = [3, 5, 7]\n",
    "learning_rates = [0.01, 0.1, 1]\n",
    "subsamples = [0.7, 0.8, 0.9]\n",
    "colsample_bytrees = [0.5, 0.6, 0.7]\n",
    "\n",
    "th_hyperparam_tuning(x_bow_train, y_train, x_bow_test, y_test, max_depths, scale_pos_weights, learning_rates, subsamples, colsample_bytrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3d5163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff75fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
