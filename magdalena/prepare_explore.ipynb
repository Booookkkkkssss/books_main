{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c87f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import prepare as prep\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.model_selection\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, binom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63654336",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f036ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original df\n",
    "\n",
    "f = pd.read_csv('all_books.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9abef52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>year_published</th>\n",
       "      <th>author</th>\n",
       "      <th>review_count</th>\n",
       "      <th>number_of_ratings</th>\n",
       "      <th>length</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>book_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Missing in Death</td>\n",
       "      <td>Aboard the Staten Island ferry, a tourist come...</td>\n",
       "      <td>2009</td>\n",
       "      <td>J.D. Robb</td>\n",
       "      <td>334</td>\n",
       "      <td>9875</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>4.24</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>The Last Boyfriend</td>\n",
       "      <td>Owen is the organizer of the Montgomery clan, ...</td>\n",
       "      <td>2012</td>\n",
       "      <td>Nora Roberts</td>\n",
       "      <td>2545</td>\n",
       "      <td>47392</td>\n",
       "      <td>436.0</td>\n",
       "      <td>Romance</td>\n",
       "      <td>4.09</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Just Me in the Tub</td>\n",
       "      <td>Taking a bath is a big job. Mercer Mayer's fam...</td>\n",
       "      <td>1994</td>\n",
       "      <td>Gina Mayer</td>\n",
       "      <td>62</td>\n",
       "      <td>19212</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Childrens</td>\n",
       "      <td>4.25</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Lucy in the Sky</td>\n",
       "      <td>Settling down for a 24-hour flight to Australi...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Paige Toon</td>\n",
       "      <td>628</td>\n",
       "      <td>9524</td>\n",
       "      <td>390.0</td>\n",
       "      <td>Chick Lit</td>\n",
       "      <td>3.95</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>The Rats in the Walls</td>\n",
       "      <td>\"The Rats in the Walls\" is a short story by H....</td>\n",
       "      <td>1924</td>\n",
       "      <td>H.P. Lovecraft</td>\n",
       "      <td>531</td>\n",
       "      <td>9155</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Horror</td>\n",
       "      <td>4.01</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                                            summary  \\\n",
       "48        Missing in Death  Aboard the Staten Island ferry, a tourist come...   \n",
       "53      The Last Boyfriend  Owen is the organizer of the Montgomery clan, ...   \n",
       "205     Just Me in the Tub  Taking a bath is a big job. Mercer Mayer's fam...   \n",
       "104        Lucy in the Sky  Settling down for a 24-hour flight to Australi...   \n",
       "334  The Rats in the Walls  \"The Rats in the Walls\" is a short story by H....   \n",
       "\n",
       "    year_published          author  review_count  number_of_ratings  length  \\\n",
       "48            2009       J.D. Robb           334               9875    77.0   \n",
       "53            2012    Nora Roberts          2545              47392   436.0   \n",
       "205           1994      Gina Mayer            62              19212    24.0   \n",
       "104           2007      Paige Toon           628               9524   390.0   \n",
       "334           1924  H.P. Lovecraft           531               9155    25.0   \n",
       "\n",
       "         genre  rating reviews  book_tag  \n",
       "48     Mystery    4.24      []       NaN  \n",
       "53     Romance    4.09      []       NaN  \n",
       "205  Childrens    4.25      []       NaN  \n",
       "104  Chick Lit    3.95      []       NaN  \n",
       "334     Horror    4.01      []       NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46b4f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nytbs df\n",
    "\n",
    "b = pd.read_csv('books_feat_on_NYBS').drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b117fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1045, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77728cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date        0\n",
       "Book        0\n",
       "Author      0\n",
       "Month     968\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at best sellers\n",
    "\n",
    "b.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac6857c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataframe of the books\n",
    "\n",
    "df = prep.prep_data('all_books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbb1305f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>year_published</th>\n",
       "      <th>author</th>\n",
       "      <th>review_count</th>\n",
       "      <th>number_of_ratings</th>\n",
       "      <th>length</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_summary</th>\n",
       "      <th>successful</th>\n",
       "      <th>lemmatized_summary</th>\n",
       "      <th>neg</th>\n",
       "      <th>neutral</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Thing Explainer: Complicated Stuff in Simple W...</td>\n",
       "      <td>In Thing Explainer: Complicated Stuff in Simpl...</td>\n",
       "      <td>2015</td>\n",
       "      <td>Randall Munroe</td>\n",
       "      <td>939</td>\n",
       "      <td>10777</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Science</td>\n",
       "      <td>4.14</td>\n",
       "      <td>[]</td>\n",
       "      <td>thing explainer complicated stuff in simple words</td>\n",
       "      <td>in thing explainer complicated stuff in simple...</td>\n",
       "      <td>False</td>\n",
       "      <td>thing explainer complicate stuff simple word t...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>First Impressions</td>\n",
       "      <td>The first biography of Monet written especiall...</td>\n",
       "      <td>1991</td>\n",
       "      <td>Ann Waldron</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>3.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>first impressions</td>\n",
       "      <td>the first biography of monet written especiall...</td>\n",
       "      <td>False</td>\n",
       "      <td>first biography monet write especially young r...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Nejma</td>\n",
       "      <td>all of the unsleeping. gold sweeping. poems. i...</td>\n",
       "      <td>2014</td>\n",
       "      <td>Nayyirah Waheed</td>\n",
       "      <td>533</td>\n",
       "      <td>5881</td>\n",
       "      <td>172.0</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>4.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nejma</td>\n",
       "      <td>all of the unsleeping. gold sweeping. poems. i...</td>\n",
       "      <td>False</td>\n",
       "      <td>unsleeping gold sweeping poem hand</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Redhead by the Side of the Road</td>\n",
       "      <td>Micah Mortimer is a creature of habit. A self-...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Anne Tyler</td>\n",
       "      <td>5334</td>\n",
       "      <td>41838</td>\n",
       "      <td>178.0</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>3.62</td>\n",
       "      <td>[]</td>\n",
       "      <td>redhead by the side of the road</td>\n",
       "      <td>micah mortimer is a creature of habit. a selfe...</td>\n",
       "      <td>False</td>\n",
       "      <td>micah mortimer creature habit selfemployed tec...</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>King Arthur</td>\n",
       "      <td>A ruler said¬†to be the model of goodness over ...</td>\n",
       "      <td>1918</td>\n",
       "      <td>Andrew Lang</td>\n",
       "      <td>62</td>\n",
       "      <td>598</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>3.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>king arthur</td>\n",
       "      <td>a ruler said to be the model of goodness over ...</td>\n",
       "      <td>False</td>\n",
       "      <td>ruler say model goodness evil formidable comra...</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>The Present</td>\n",
       "      <td>Old Version</td>\n",
       "      <td>Inc.</td>\n",
       "      <td>Kenneth   Thomas</td>\n",
       "      <td>79</td>\n",
       "      <td>2383</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Science Fiction</td>\n",
       "      <td>3.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the present</td>\n",
       "      <td>old version</td>\n",
       "      <td>False</td>\n",
       "      <td>old version</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>The Mermaid's Voice Returns in This One</td>\n",
       "      <td>Goodreads Choice Award-winning poet and USA TO...</td>\n",
       "      <td>2019</td>\n",
       "      <td>Amanda Lovelace</td>\n",
       "      <td>2185</td>\n",
       "      <td>16801</td>\n",
       "      <td>210.0</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>3.68</td>\n",
       "      <td>[]</td>\n",
       "      <td>the mermaid's voice returns in this one</td>\n",
       "      <td>goodreads choice awardwinning poet and usa tod...</td>\n",
       "      <td>False</td>\n",
       "      <td>goodreads choice awardwinning poet usa today b...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>You Learn by Living: Eleven Keys for a More Fu...</td>\n",
       "      <td>Mrs. Roosevelt expresses her philosophy of lif...</td>\n",
       "      <td>1960</td>\n",
       "      <td>Eleanor Roosevelt</td>\n",
       "      <td>566</td>\n",
       "      <td>4084</td>\n",
       "      <td>211.0</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>3.98</td>\n",
       "      <td>[]</td>\n",
       "      <td>you learn by living eleven keys for a more ful...</td>\n",
       "      <td>mrs. roosevelt expresses her philosophy of lif...</td>\n",
       "      <td>False</td>\n",
       "      <td>roosevelt express philosophy life relate exper...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Burning in Water, Drowning in Flame</td>\n",
       "      <td>Burning in Water, Drowning in Flame is poetry ...</td>\n",
       "      <td>1974</td>\n",
       "      <td>Charles Bukowski</td>\n",
       "      <td>482</td>\n",
       "      <td>8041</td>\n",
       "      <td>232.0</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>4.08</td>\n",
       "      <td>[]</td>\n",
       "      <td>burning in water, drowning in flame</td>\n",
       "      <td>burning in water, drowning in flame is poetry ...</td>\n",
       "      <td>False</td>\n",
       "      <td>burn water drown flame poetry full gamble drin...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>H is for Hawk</td>\n",
       "      <td>As a child, Helen Macdonald was determined to ...</td>\n",
       "      <td>2014</td>\n",
       "      <td>Helen Macdonald</td>\n",
       "      <td>9407</td>\n",
       "      <td>70020</td>\n",
       "      <td>300.0</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>3.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>h is for hawk</td>\n",
       "      <td>as a child, helen macdonald was determined to ...</td>\n",
       "      <td>False</td>\n",
       "      <td>child helen macdonald determine become falcone...</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.113</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>Kerri's War</td>\n",
       "      <td>Librarian Note: Alternate Cover Edition for AS...</td>\n",
       "      <td>2011</td>\n",
       "      <td>Stephen Douglass</td>\n",
       "      <td>16</td>\n",
       "      <td>1527</td>\n",
       "      <td>315.0</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>3.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kerri's war</td>\n",
       "      <td>librarian note alternate cover edition for asi...</td>\n",
       "      <td>False</td>\n",
       "      <td>librarian note alternate cover</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>Seven Years in Tibet</td>\n",
       "      <td>Recounts how the author, an Austrian, escaped ...</td>\n",
       "      <td>1953</td>\n",
       "      <td>Heinrich Harrer</td>\n",
       "      <td>1299</td>\n",
       "      <td>23045</td>\n",
       "      <td>330.0</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>4.09</td>\n",
       "      <td>['‚ÄùNow the Living Buddha was approaching. He p...</td>\n",
       "      <td>seven years in tibet</td>\n",
       "      <td>recounts how the author, an austrian, escaped ...</td>\n",
       "      <td>False</td>\n",
       "      <td>recount author austrian escape english internm...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>Remarkable Creatures</td>\n",
       "      <td>In 1810, a sister and brother uncover the foss...</td>\n",
       "      <td>2009</td>\n",
       "      <td>Tracy Chevalier</td>\n",
       "      <td>5220</td>\n",
       "      <td>48963</td>\n",
       "      <td>352.0</td>\n",
       "      <td>Historical Fiction</td>\n",
       "      <td>3.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>remarkable creatures</td>\n",
       "      <td>in 1810, a sister and brother uncover the foss...</td>\n",
       "      <td>False</td>\n",
       "      <td>sister brother uncover fossilize skull unknown...</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>Winterhorn</td>\n",
       "      <td>ùñÇùñäùñëùñàùñîùñíùñä ùñôùñî ùñÜ ùñíùñÜùñåùñéùñàùñÜùñë ùñúùñîùñóùñëùñâ ùñîùñã ùñâùñóùñÜùñåùñîùñìùñò, ùñîùñóùñàùñò, ùñé...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Baiculescu Ovidiu Nicolae</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>371.0</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>4.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>winterhorn</td>\n",
       "      <td>welcome to a magical world of dragons, orcs, i...</td>\n",
       "      <td>False</td>\n",
       "      <td>welcome magical world dragon orcs imp wizard w...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>Smarter Faster Better: The Secrets of Being Pr...</td>\n",
       "      <td>A new book that explores the science of produc...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Charles Duhigg</td>\n",
       "      <td>2410</td>\n",
       "      <td>32071</td>\n",
       "      <td>400.0</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>3.90</td>\n",
       "      <td>[]</td>\n",
       "      <td>smarter faster better the secrets of being pro...</td>\n",
       "      <td>a new book that explores the science of produc...</td>\n",
       "      <td>False</td>\n",
       "      <td>new explores science productivity today world ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>The Raw Shark Texts</td>\n",
       "      <td>Eric Sanderson wakes up in a house one day wit...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Steven  Hall</td>\n",
       "      <td>2014</td>\n",
       "      <td>19923</td>\n",
       "      <td>427.0</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>3.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the raw shark texts</td>\n",
       "      <td>eric sanderson wakes up in a house one day wit...</td>\n",
       "      <td>False</td>\n",
       "      <td>eric sanderson wake house one day idea note in...</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>One Day</td>\n",
       "      <td>15th July 1988: Emma and Dexter meet for the f...</td>\n",
       "      <td>2009</td>\n",
       "      <td>David Nicholls</td>\n",
       "      <td>18888</td>\n",
       "      <td>313843</td>\n",
       "      <td>435.0</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>3.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>one day</td>\n",
       "      <td>15th july 1988 emma and dexter meet for the fi...</td>\n",
       "      <td>False</td>\n",
       "      <td>july emma dexter meet first time night graduat...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>Fear: Trump in the White House</td>\n",
       "      <td>With authoritative reporting honed through eig...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Bob Woodward</td>\n",
       "      <td>7075</td>\n",
       "      <td>61316</td>\n",
       "      <td>448.0</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>3.87</td>\n",
       "      <td>[]</td>\n",
       "      <td>fear trump in the white house</td>\n",
       "      <td>with authoritative reporting honed through eig...</td>\n",
       "      <td>False</td>\n",
       "      <td>authoritative reporting hone eight presidency ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3479</th>\n",
       "      <td>Tolkien's World From A To Z</td>\n",
       "      <td>For the millions who have already ventured to ...</td>\n",
       "      <td>1974</td>\n",
       "      <td>Robert   Foster</td>\n",
       "      <td>102</td>\n",
       "      <td>11527</td>\n",
       "      <td>569.0</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>4.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tolkien's world from a to z</td>\n",
       "      <td>for the millions who have already ventured to ...</td>\n",
       "      <td>False</td>\n",
       "      <td>million already venture middleearth countless ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3694</th>\n",
       "      <td>The Luminaries</td>\n",
       "      <td>It is 1866, and young Walter Moody has come to...</td>\n",
       "      <td>2013</td>\n",
       "      <td>Eleanor Catton</td>\n",
       "      <td>8894</td>\n",
       "      <td>76365</td>\n",
       "      <td>848.0</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>3.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the luminaries</td>\n",
       "      <td>it is 1866, and young walter moody has come to...</td>\n",
       "      <td>False</td>\n",
       "      <td>young walter moody come make fortune upon new ...</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>The Dark Tower</td>\n",
       "      <td>The seventh and final installment of Stephen K...</td>\n",
       "      <td>2004</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>6943</td>\n",
       "      <td>163628</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>4.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the dark tower</td>\n",
       "      <td>the seventh and final installment of stephen k...</td>\n",
       "      <td>True</td>\n",
       "      <td>seventh final installment stephen king dark to...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "64    Thing Explainer: Complicated Stuff in Simple W...   \n",
       "96                                    First Impressions   \n",
       "284                                               Nejma   \n",
       "320                     Redhead by the Side of the Road   \n",
       "374                                         King Arthur   \n",
       "420                                         The Present   \n",
       "487             The Mermaid's Voice Returns in This One   \n",
       "490   You Learn by Living: Eleven Keys for a More Fu...   \n",
       "619                 Burning in Water, Drowning in Flame   \n",
       "1318                                      H is for Hawk   \n",
       "1530                                        Kerri's War   \n",
       "1772                               Seven Years in Tibet   \n",
       "2075                               Remarkable Creatures   \n",
       "2324                                         Winterhorn   \n",
       "2679  Smarter Faster Better: The Secrets of Being Pr...   \n",
       "2888                                The Raw Shark Texts   \n",
       "2959                                            One Day   \n",
       "3033                     Fear: Trump in the White House   \n",
       "3479                        Tolkien's World From A To Z   \n",
       "3694                                     The Luminaries   \n",
       "3741                                     The Dark Tower   \n",
       "\n",
       "                                                summary year_published  \\\n",
       "64    In Thing Explainer: Complicated Stuff in Simpl...           2015   \n",
       "96    The first biography of Monet written especiall...           1991   \n",
       "284   all of the unsleeping. gold sweeping. poems. i...           2014   \n",
       "320   Micah Mortimer is a creature of habit. A self-...           2020   \n",
       "374   A ruler said¬†to be the model of goodness over ...           1918   \n",
       "420                                         Old Version           Inc.   \n",
       "487   Goodreads Choice Award-winning poet and USA TO...           2019   \n",
       "490   Mrs. Roosevelt expresses her philosophy of lif...           1960   \n",
       "619   Burning in Water, Drowning in Flame is poetry ...           1974   \n",
       "1318  As a child, Helen Macdonald was determined to ...           2014   \n",
       "1530  Librarian Note: Alternate Cover Edition for AS...           2011   \n",
       "1772  Recounts how the author, an Austrian, escaped ...           1953   \n",
       "2075  In 1810, a sister and brother uncover the foss...           2009   \n",
       "2324  ùñÇùñäùñëùñàùñîùñíùñä ùñôùñî ùñÜ ùñíùñÜùñåùñéùñàùñÜùñë ùñúùñîùñóùñëùñâ ùñîùñã ùñâùñóùñÜùñåùñîùñìùñò, ùñîùñóùñàùñò, ùñé...           2020   \n",
       "2679  A new book that explores the science of produc...           2016   \n",
       "2888  Eric Sanderson wakes up in a house one day wit...           2007   \n",
       "2959  15th July 1988: Emma and Dexter meet for the f...           2009   \n",
       "3033  With authoritative reporting honed through eig...           2018   \n",
       "3479  For the millions who have already ventured to ...           1974   \n",
       "3694  It is 1866, and young Walter Moody has come to...           2013   \n",
       "3741  The seventh and final installment of Stephen K...           2004   \n",
       "\n",
       "                         author  review_count  number_of_ratings  length  \\\n",
       "64               Randall Munroe           939              10777    64.0   \n",
       "96                  Ann Waldron             2                 23    92.0   \n",
       "284             Nayyirah Waheed           533               5881   172.0   \n",
       "320                  Anne Tyler          5334              41838   178.0   \n",
       "374                 Andrew Lang            62                598   192.0   \n",
       "420            Kenneth   Thomas            79               2383   200.0   \n",
       "487             Amanda Lovelace          2185              16801   210.0   \n",
       "490           Eleanor Roosevelt           566               4084   211.0   \n",
       "619            Charles Bukowski           482               8041   232.0   \n",
       "1318            Helen Macdonald          9407              70020   300.0   \n",
       "1530           Stephen Douglass            16               1527   315.0   \n",
       "1772            Heinrich Harrer          1299              23045   330.0   \n",
       "2075            Tracy Chevalier          5220              48963   352.0   \n",
       "2324  Baiculescu Ovidiu Nicolae            12                 36   371.0   \n",
       "2679             Charles Duhigg          2410              32071   400.0   \n",
       "2888               Steven  Hall          2014              19923   427.0   \n",
       "2959             David Nicholls         18888             313843   435.0   \n",
       "3033               Bob Woodward          7075              61316   448.0   \n",
       "3479            Robert   Foster           102              11527   569.0   \n",
       "3694             Eleanor Catton          8894              76365   848.0   \n",
       "3741               Stephen King          6943             163628  1050.0   \n",
       "\n",
       "                   genre  rating  \\\n",
       "64               Science    4.14   \n",
       "96            Nonfiction    3.57   \n",
       "284               Poetry    4.02   \n",
       "320              Fiction    3.62   \n",
       "374              Fantasy    3.50   \n",
       "420      Science Fiction    3.59   \n",
       "487               Poetry    3.68   \n",
       "490           Nonfiction    3.98   \n",
       "619               Poetry    4.08   \n",
       "1318          Nonfiction    3.74   \n",
       "1530            Thriller    3.83   \n",
       "1772          Nonfiction    4.09   \n",
       "2075  Historical Fiction    3.87   \n",
       "2324             Fantasy    4.44   \n",
       "2679          Nonfiction    3.90   \n",
       "2888             Fiction    3.82   \n",
       "2959             Fiction    3.81   \n",
       "3033          Nonfiction    3.87   \n",
       "3479             Fantasy    4.18   \n",
       "3694             Fiction    3.73   \n",
       "3741             Fantasy    4.27   \n",
       "\n",
       "                                                reviews  \\\n",
       "64                                                   []   \n",
       "96                                                  NaN   \n",
       "284                                                 NaN   \n",
       "320                                                  []   \n",
       "374                                                 NaN   \n",
       "420                                                 NaN   \n",
       "487                                                  []   \n",
       "490                                                  []   \n",
       "619                                                  []   \n",
       "1318                                                NaN   \n",
       "1530                                                NaN   \n",
       "1772  ['‚ÄùNow the Living Buddha was approaching. He p...   \n",
       "2075                                                NaN   \n",
       "2324                                                NaN   \n",
       "2679                                                 []   \n",
       "2888                                                NaN   \n",
       "2959                                                NaN   \n",
       "3033                                                 []   \n",
       "3479                                                NaN   \n",
       "3694                                                NaN   \n",
       "3741                                                NaN   \n",
       "\n",
       "                                          cleaned_title  \\\n",
       "64    thing explainer complicated stuff in simple words   \n",
       "96                                    first impressions   \n",
       "284                                               nejma   \n",
       "320                     redhead by the side of the road   \n",
       "374                                         king arthur   \n",
       "420                                         the present   \n",
       "487             the mermaid's voice returns in this one   \n",
       "490   you learn by living eleven keys for a more ful...   \n",
       "619                 burning in water, drowning in flame   \n",
       "1318                                      h is for hawk   \n",
       "1530                                        kerri's war   \n",
       "1772                               seven years in tibet   \n",
       "2075                               remarkable creatures   \n",
       "2324                                         winterhorn   \n",
       "2679  smarter faster better the secrets of being pro...   \n",
       "2888                                the raw shark texts   \n",
       "2959                                            one day   \n",
       "3033                      fear trump in the white house   \n",
       "3479                        tolkien's world from a to z   \n",
       "3694                                     the luminaries   \n",
       "3741                                     the dark tower   \n",
       "\n",
       "                                        cleaned_summary  successful  \\\n",
       "64    in thing explainer complicated stuff in simple...       False   \n",
       "96    the first biography of monet written especiall...       False   \n",
       "284   all of the unsleeping. gold sweeping. poems. i...       False   \n",
       "320   micah mortimer is a creature of habit. a selfe...       False   \n",
       "374   a ruler said to be the model of goodness over ...       False   \n",
       "420                                         old version       False   \n",
       "487   goodreads choice awardwinning poet and usa tod...       False   \n",
       "490   mrs. roosevelt expresses her philosophy of lif...       False   \n",
       "619   burning in water, drowning in flame is poetry ...       False   \n",
       "1318  as a child, helen macdonald was determined to ...       False   \n",
       "1530  librarian note alternate cover edition for asi...       False   \n",
       "1772  recounts how the author, an austrian, escaped ...       False   \n",
       "2075  in 1810, a sister and brother uncover the foss...       False   \n",
       "2324  welcome to a magical world of dragons, orcs, i...       False   \n",
       "2679  a new book that explores the science of produc...       False   \n",
       "2888  eric sanderson wakes up in a house one day wit...       False   \n",
       "2959  15th july 1988 emma and dexter meet for the fi...       False   \n",
       "3033  with authoritative reporting honed through eig...       False   \n",
       "3479  for the millions who have already ventured to ...       False   \n",
       "3694  it is 1866, and young walter moody has come to...       False   \n",
       "3741  the seventh and final installment of stephen k...        True   \n",
       "\n",
       "                                     lemmatized_summary    neg  neutral  \\\n",
       "64    thing explainer complicate stuff simple word t...  0.000    1.000   \n",
       "96    first biography monet write especially young r...  0.000    1.000   \n",
       "284                  unsleeping gold sweeping poem hand  0.000    1.000   \n",
       "320   micah mortimer creature habit selfemployed tec...  0.088    0.823   \n",
       "374   ruler say model goodness evil formidable comra...  0.084    0.832   \n",
       "420                                         old version  0.000    1.000   \n",
       "487   goodreads choice awardwinning poet usa today b...  0.000    1.000   \n",
       "490   roosevelt express philosophy life relate exper...  0.000    1.000   \n",
       "619   burn water drown flame poetry full gamble drin...  0.000    1.000   \n",
       "1318  child helen macdonald determine become falcone...  0.127    0.760   \n",
       "1530                     librarian note alternate cover  0.000    1.000   \n",
       "1772  recount author austrian escape english internm...  0.000    1.000   \n",
       "2075  sister brother uncover fossilize skull unknown...  0.117    0.761   \n",
       "2324  welcome magical world dragon orcs imp wizard w...  0.000    1.000   \n",
       "2679  new explores science productivity today world ...  0.000    1.000   \n",
       "2888  eric sanderson wake house one day idea note in...  0.141    0.727   \n",
       "2959  july emma dexter meet first time night graduat...  0.000    1.000   \n",
       "3033  authoritative reporting hone eight presidency ...  0.000    1.000   \n",
       "3479  million already venture middleearth countless ...  0.000    1.000   \n",
       "3694  young walter moody come make fortune upon new ...  0.108    0.800   \n",
       "3741  seventh final installment stephen king dark to...  0.000    1.000   \n",
       "\n",
       "        pos  compound sentiment  \n",
       "64    0.000       0.0   neutral  \n",
       "96    0.000       0.0   neutral  \n",
       "284   0.000       0.0   neutral  \n",
       "320   0.088       0.0   neutral  \n",
       "374   0.084      -0.0   neutral  \n",
       "420   0.000       0.0   neutral  \n",
       "487   0.000       0.0   neutral  \n",
       "490   0.000       0.0   neutral  \n",
       "619   0.000       0.0   neutral  \n",
       "1318  0.113      -0.0   neutral  \n",
       "1530  0.000       0.0   neutral  \n",
       "1772  0.000       0.0   neutral  \n",
       "2075  0.122      -0.0   neutral  \n",
       "2324  0.000       0.0   neutral  \n",
       "2679  0.000       0.0   neutral  \n",
       "2888  0.132       0.0   neutral  \n",
       "2959  0.000       0.0   neutral  \n",
       "3033  0.000       0.0   neutral  \n",
       "3479  0.000       0.0   neutral  \n",
       "3694  0.093       0.0   neutral  \n",
       "3741  0.000       0.0   neutral  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping 'Picture Books'\n",
    "\n",
    "df = df[df['genre'] != 'Picture Books']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a40de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting year to int\n",
    "\n",
    "df.year_published = df.year_published.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd3025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding rows with non-years\n",
    "\n",
    "[re.findall(r\"[^0-9]\", str(x)) for x in df.year_published]\n",
    "\n",
    "# setting to a series and DF of non-years\n",
    "empty = pd.DataFrame(pd.Series([re.findall(r\"[^0-9]\", str(x)) for x in df.year_published]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c23a6d",
   "metadata": {},
   "source": [
    "## cleaning, exploring`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f0dcb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                    0\n",
       "summary                  0\n",
       "year_published           0\n",
       "author                   0\n",
       "review_count             0\n",
       "number_of_ratings        0\n",
       "length                   0\n",
       "genre                    0\n",
       "rating                   0\n",
       "reviews               1976\n",
       "cleaned_title            0\n",
       "cleaned_summary          0\n",
       "successful               0\n",
       "lemmatized_summary       0\n",
       "neg                      0\n",
       "neutral                  0\n",
       "pos                      0\n",
       "compound                 0\n",
       "sentiment                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many nan\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391d0705",
   "metadata": {},
   "source": [
    "**No NaNs appear in important columns.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e3d0ea",
   "metadata": {},
   "source": [
    "## train‚Äîtest split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1e708bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    train, test = train_test_split(df, test_size = .2, random_state = 42, stratify = df.succesful)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9c0374",
   "metadata": {},
   "source": [
    "**1 / True = successful (bestseller), 0 / False = not a bestseller**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3b94e50",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train, test \u001b[38;5;241m=\u001b[39m \u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m train\u001b[38;5;241m.\u001b[39mshape, test\u001b[38;5;241m.\u001b[39mshape\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(df):\n\u001b[0;32m----> 2\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m train_test_split(df, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.2\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m, stratify \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train, test\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'target'"
     ]
    }
   ],
   "source": [
    "train, test = split(df)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5729bafc",
   "metadata": {},
   "source": [
    "#### We'll be doing k-folds, so no need to have a validate portion here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b542e9",
   "metadata": {},
   "source": [
    "### Does the length of a book have a relationship to its success ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0652a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c235bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# successful books\n",
    "\n",
    "besties = train[train['target'] == 'best seller']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b26f52",
   "metadata": {},
   "source": [
    "**127 bestseller books in train. Assigning to a variable in order to explore page length.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc15bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean length of pages\n",
    "\n",
    "besties['length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aacbc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# median length of pages\n",
    "\n",
    "besties['length'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec8e810",
   "metadata": {},
   "source": [
    "**The mean length of best sellers is 477 pages, the median is 400 pages.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2200b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation\n",
    "\n",
    "besties['length'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27de9ac",
   "metadata": {},
   "source": [
    "**Standard deviation of about 205 pages. So, 68% of NYT bestsellers have a length of 272 to 682 pages.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967cb926",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_books = besties[besties['length'] > 682]\n",
    "long_books.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a31440",
   "metadata": {},
   "source": [
    "**19 books have more than 682 pages.** Now to compare with generalised / random books list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3df6906",
   "metadata": {},
   "source": [
    "### Non-bestsellers\n",
    "\n",
    "**18 books have more than 677 pages.** Now to compare with generalised / random books list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e27610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolating unsuccessful books \n",
    "\n",
    "sadness = train[train['target'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92647b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sadness['length'].max(), sadness['length'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c5a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sadness['length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe1b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation of non-bestsellers\n",
    "\n",
    "sadness['length'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a8392",
   "metadata": {},
   "source": [
    "**Standard deviation of about 175 pages. So, 68% of non-bestsellers have a length between 180 and 530 pages.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c12a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e594b56f",
   "metadata": {},
   "source": [
    "### Exploring length and year published\n",
    "\n",
    "H_O : There is no relationship between the length of a book and the year that it was published.\n",
    "\n",
    "H_a : There is a relationship between the length of a book and the year that it was published."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab830dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.title('Non-Bestseller Lengths, By Year Published')\n",
    "sns.barplot(y = sadness['length'], x = sadness['year_published'])\n",
    "\n",
    "plt.xticks(rotation = 45)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "\n",
    "plt.title('Bestseller Lengths, By Year Published')\n",
    "\n",
    "sns.barplot(y = besties['length'], x = besties['year_published'])\n",
    "\n",
    "plt.xticks(rotation = 45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdbe991",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "\n",
    "plt.title('All Books Lengths, By Year')\n",
    "\n",
    "sns.barplot(y = train['length'], x = train['year_published'])\n",
    "\n",
    "plt.xticks(rotation = 45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90e07c8",
   "metadata": {},
   "source": [
    "**The distribution for all there dataframes is relatively uniform; a chi-square test is appropriate here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172eb4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi-square function\n",
    "\n",
    "def chi_sq(a, b):\n",
    "    '''\n",
    "    This function will take in two arguments in the form of two discrete variables \n",
    "    and runs a chi^2 test to determine if the the two variables are independent of \n",
    "    each other and prints the results based on the findings.\n",
    "    '''\n",
    "    alpha = 0.05\n",
    "    \n",
    "    result = pd.crosstab(a, b)\n",
    "\n",
    "    chi2, p, degf, expected = stats.chi2_contingency(result)\n",
    "\n",
    "    print(f'Chi-square  : {chi2:.4f}') \n",
    "    print(\"\")\n",
    "    print(f'P-value : {p:.4f}')\n",
    "    print(\"\")\n",
    "    if p / 2 > alpha:\n",
    "        print(\"We fail to reject the null hypothesis.\")\n",
    "    else:\n",
    "        print(f'We reject the null hypothesis ; there is a relationship between the target variable and the feature examined.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi-square on train for length and year published\n",
    "\n",
    "a = train['length']\n",
    "b = train['year_published']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84389401",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sq(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdeca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi-square on besties  for length and year published\n",
    "\n",
    "v = besties['length']\n",
    "w = besties['year_published']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sq(v, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d15c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi-square on sadness for length and year published\n",
    "\n",
    "t = sadness['length']\n",
    "u = sadness['year_published']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71bbc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sq(t, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167028e1",
   "metadata": {},
   "source": [
    "**TAKEAWAYS: There is a relationship between the length of the book (positive correlation) and the year that it was published, particularly for books not on the NYT Best Seller list, and for the train dataset. The length of the book and the year that it was published did not have a relationship for NYT Best Sellers.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9882650e",
   "metadata": {},
   "source": [
    "## Exploring length and successs\n",
    "\n",
    "H_O : There is no relationship between the length of a book and its landing on the NYT Best Seller list.\n",
    "\n",
    "H_a : There is a relationship between the length of a book and its landing on the NYT Best Seller list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8996a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting all books\n",
    "\n",
    "def book_len_success():\n",
    "    \n",
    "    '''\n",
    "    this function uses the training dataset to plot \n",
    "    the target ('successful') against the length in \n",
    "    pages of each book. it puts out a barplot.\n",
    "    '''\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    plt.title('Success Of Book Based On Average Page Length')\n",
    "\n",
    "    graphed = sns.barplot(x = train['successful'], y = train['length'], palette = 'CMRmap')\n",
    "\n",
    "    # set xtick labels and properties\n",
    "    plt.xticks([0, 1], \n",
    "               [ 'Not On List', 'Bestseller'],\n",
    "               rotation = 25)\n",
    "\n",
    "    # plt.legend([],[]) --this line unnecessary here\n",
    "    plt.yticks(np.arange(0, 600, 100))\n",
    "\n",
    "    # display y axis grids\n",
    "    # graphed.yaxis.grid(True)\n",
    "\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Appearance On NYT Best Seller List')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b2de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_len_success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa6cc0",
   "metadata": {},
   "source": [
    "**It appears that bestsellers have, on average, a longer average page count than books that are not NYT Best Sellers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50caefc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi-square on train for length and success\n",
    "\n",
    "r = train['length']\n",
    "s = train['successful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da0e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sq(r, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e57089",
   "metadata": {},
   "source": [
    "**TAKEAWAYS: It appears, both from the bar plot and from the chi-square test, that there is a significant relationship between book length and its appearing on the NYT Best Seller list. Bestsellers, on average, have a longer page length than non-bestsellers. This discovery is also supported by the cumulative density function results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a48b442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8b75af4",
   "metadata": {},
   "source": [
    "### Using .cdf on bestsellers and non-bestsellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d9836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestsellers\n",
    "\n",
    "# mean\n",
    "m = 477\n",
    "\n",
    "# standard deviation\n",
    "s = 205\n",
    "\n",
    "# Define the normal distribution\n",
    "bestseller_len = stats.norm(m, s)\n",
    "\n",
    "## Find the value where 95% of the values / variables are less than unknown-value-X : Use PPF.\n",
    "best_cdf = bestseller_len.cdf(191)\n",
    "best_cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291ef18",
   "metadata": {},
   "source": [
    "**8pc chance of a successful book having a length of 191 pages or less.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71bb765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of unsuccessful books\n",
    "m = 355\n",
    "\n",
    "# standard deviation\n",
    "s = 175\n",
    "\n",
    "nonbest_length = stats.norm(m, s)\n",
    "\n",
    "nonbest_cdf = nonbest_length.cdf(191)\n",
    "nonbest_cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685d4de7",
   "metadata": {},
   "source": [
    "**17.4pc chance of an unsuccessful book having 200 or less pages.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3e0eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee58bdf1",
   "metadata": {},
   "source": [
    "### What about sentiment score distribution ?¬∂\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff000a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting bestseller books : length vs sentiment score\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.title('Sentiment Score Of Book Summary Based On Page Length : Bestsellers')\n",
    "\n",
    "sns.barplot(x = besties['sentiment'], y = besties['length'])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6b5384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting unsuccessful books : length vs sentiment score\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.title('Sentiment Score Of Book Summary Based On Page Length : Non-Bestsellers')\n",
    "\n",
    "sns.barplot(x = sadness['sentiment'], y = sadness['length'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360690f7",
   "metadata": {},
   "source": [
    "**TAKEAWAYS: Length of book does not seem to have much relationship to the book-summary sentiment score. There was one bestseller with a neutral score, which led to it not being able to have an average page length calculation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fafe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = besties[besties['sentiment'] == 'very negative']\n",
    "a['title'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47447b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = besties[besties['sentiment'] == 'negative']\n",
    "b['title'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d9071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = besties[besties['sentiment'] == 'neutral']\n",
    "e['title'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56de13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = besties[besties['sentiment'] == 'positive']\n",
    "d['title'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b1fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = besties[besties['sentiment'] == 'very positive']\n",
    "c['title'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0fdb35",
   "metadata": {},
   "source": [
    "**Of the bestseller sentiment scores, 65 have very negative scores, 7 have negative, 1 has neutral, 11 have positive and 43 have very positive.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adbc36b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ffce6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
