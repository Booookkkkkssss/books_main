{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15dbe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7263e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links():\n",
    "    df = pd.read_csv('2000_book_ids.txt', header= None, names = ['book_tag'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31002539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'https://www.goodreads.com/book/show/'\n",
    "collect = pd.DataFrame(columns = ['title','summary','year_published','author','review_count',\n",
    "                                  'number_of_ratings','length','genre','rating','reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07798df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_soup():\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')  \n",
    "    print(f'URL:              {url}')\n",
    "    print(f'Request Response: {response.status_code}')\n",
    "    print(f'Request Number:   {counter+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(tag_list):\n",
    "    # 1st half of link \n",
    "    base = 'https://www.goodreads.com/book/show/'\n",
    "    for i, item in enumerate(tag_list):\n",
    "        # concatenate 1st half of link with booktag\n",
    "        url = base + item\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(\"The request has timed out.\")\n",
    "        \n",
    "        # make soup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44143d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape(df['book_tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb9fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for i, item in enumerate(df['book_tag']):\n",
    "    if i < 195:\n",
    "        continue\n",
    "    url = base + item\n",
    "    # create initial web request\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"The request has timed out.\")\n",
    "    make_soup()\n",
    "    \n",
    "    #--------title-------------------------------------------\n",
    "    \n",
    "     # save to Variable\n",
    "    title_tag = soup.find('h1', attrs={'class': 'Text Text__title1'})\n",
    "    # looking at the h1 tag aria.\n",
    "    title = title_tag['aria-label'].split(': ')[1]\n",
    "    print(f'Book Title:       {title}')\n",
    "    \n",
    "    #----author-----------------------------------------------\n",
    "    \n",
    "    # find where author is stored\n",
    "    soup.find('span', class_ = \"ContributorLink__name\")\n",
    "    # save the text to a variable\n",
    "    auth = soup.find('span', class_ = \"ContributorLink__name\").text\n",
    "    print(f'Book Author: {auth}')\n",
    "    \n",
    "    #----rating-----------------------------------------------\n",
    "    \n",
    "    rating = soup.find_all('div', class_= 'RatingStatistics__rating')[0].text\n",
    "    print(f'Overall Rating: {rating}')\n",
    "    \n",
    "    #----genre------------------------------------------------\n",
    "    \n",
    "    genre = soup.find('a', {'class': 'Button Button--tag-inline Button--small'}).get_text()\n",
    "    print(f'Genre: {genre}')\n",
    "    \n",
    "    #----rating and review counts------------------------------\n",
    "    \n",
    "    stats = soup.find_all('div', class_ = \"RatingStatistics__meta\")\n",
    "    \n",
    "    rating_span = soup.find('span', {'data-testid': 'ratingsCount'})\n",
    "    review_span = soup.find('span', {'data-testid': 'reviewsCount'})\n",
    "    \n",
    "    rating_text = rating_span.text.strip()\n",
    "    review_text = review_span.text.strip()\n",
    "    \n",
    "    rating_text = re.sub('[^0-9]', '', rating_text)\n",
    "    review_text = re.sub('[^0-9]', '', review_text)\n",
    "    print(f'Number of Ratings: {rating_text}')\n",
    "    print(f'Number of Reviews: {review_text}')\n",
    "         \n",
    "    #----summary------------------------------\n",
    "    \n",
    "    summary = soup.find_all('span', class_ = \"Formatted\")[0].text\n",
    "           \n",
    "    #----# of pages------------------------------\n",
    "    \n",
    "    page = soup.find('p').text\n",
    "    page = re.sub('[^0-9]', '', page)\n",
    "    print(f'Number of Pages: {page}')\n",
    "          \n",
    "    #--------year--------------------------\n",
    "    \n",
    "    year = (soup.find_all('p')[1].text)\n",
    "    year = year[-4:]\n",
    "    print(f'Year Published: {year}')\n",
    "    \n",
    "    #--------reviews--------------------------\n",
    "        \n",
    "    reviews = soup.find_all('section',class_ = \"ReviewText__content\")\n",
    "          \n",
    "    ls_reviews = []\n",
    "    for i in range (0,len (reviews)):\n",
    "        rev = soup.find_all('section',class_ = \"ReviewText__content\")[i].text\n",
    "        ls_reviews.append(rev)\n",
    "    \n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    collect.loc[counter, ['title','summary','year_published','author','review_count','number_of_ratings',\n",
    "                          'length','genre','rating','reviews']] = title, summary, year, auth, review_text, rating_text, page, genre, rating, ls_reviews  \n",
    "    counter = counter + 1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
