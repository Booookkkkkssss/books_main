{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46dc895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "    \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "#from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException, ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2889c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_file_to_dataframe(filename):\n",
    "    # Check if the text file exists\n",
    "    if os.path.exists(filename):\n",
    "        \n",
    "        # Read the text file and create a list of lines\n",
    "        with open(filename, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            content = [line.strip() for line in lines]\n",
    "\n",
    "        # Create a DataFrame from the list\n",
    "        df = pd.DataFrame(content, columns=['links'])\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        print(f\"{filename} does not exist.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3b80df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save settings to file\n",
    "def save_settings(settings, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(settings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f645c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load settings from file\n",
    "def load_settings(filename):\n",
    "    # Define default settings\n",
    "    DEFAULT_SETTINGS = {\n",
    "        \"synopsis_and_review_wait_amount\": 4,\n",
    "        \"find_button_wait\": 2,\n",
    "        \"publisher_click_wait_amount\": 2,\n",
    "        \"button_element_WebDriverWait_amount\": 20,\n",
    "        \"title_element_WebDriverWait_amount\": 20,\n",
    "        \"synopsis_and_review_list_WebDriverWait_amount\": 20,\n",
    "        \"publisher_element_WebDriverWait_amount\": 20,\n",
    "    }\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            return json.load(f)\n",
    "        \n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        return DEFAULT_SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f40e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_details_and_editions_button_click(find_button_wait,button_element_WebDriverWait_amount,publisher_click_wait_amount):\n",
    "    print(f\"- [[Hard Wait]] of {find_button_wait} seconds for button to load...\")\n",
    "    time.sleep(find_button_wait)\n",
    "    print(f\"- Waiting up to {button_element_WebDriverWait_amount} seconds for presence of Button element\")\n",
    "    button = WebDriverWait(driver, button_element_WebDriverWait_amount).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'button[aria-label=\"Book details and editions\"]')))\n",
    "        \n",
    "    find_button_test = \"Pass\"\n",
    "    print(\"- Found Button\")\n",
    "    #button = driver.find_element_by_css_selector('button[aria-label=\"Book details and editions\"]')\n",
    "    \n",
    "    print(\"- Trying Click\")\n",
    "    button.click()\n",
    "    \n",
    "    print(\"- Clicked Button:\")\n",
    "    \n",
    "    # if no exception from click() then assign \"Pass\"\n",
    "    clicked_button_test = \"Pass\"\n",
    "    \n",
    "    # waiting for elements to load after clicking button\n",
    "    time.sleep(publisher_click_wait_amount)\n",
    "    print(f\"- [[Hard Wait]] of {publisher_click_wait_amount} seconds after clicking button\")\n",
    "\n",
    "    return clicked_button_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658d1199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publisher_text(publisher_element_WebDriverWait_amount):\n",
    "    try:\n",
    "        print(\"- Looking for Publisher - Parent Element\")\n",
    "        # Find the element with the EditionDetails class\n",
    "        edition_details_element = WebDriverWait(driver, publisher_element_WebDriverWait_amount).until(EC.presence_of_element_located((By.CLASS_NAME, 'EditionDetails')))\n",
    "        print(\"- Found Parent Element\")\n",
    "        print(\"- Looking for Publisher - Child Element\")\n",
    "        # Find the nested element with the data-testid attribute\n",
    "        publisher_element = edition_details_element.find_elements_by_css_selector('div[data-testid=\"contentContainer\"]')\n",
    "        print(\"- Found Child Element\")\n",
    "        \n",
    "        return publisher_element[1].text\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        print(\"Element: EditionDetails element after click fail\")\n",
    "        return \"\"\n",
    "    \n",
    "    except TimeoutException:\n",
    "        print(\"Timeout: EditionDetails element not found within the specified time\")\n",
    "        return \"\"\n",
    "    \n",
    "    except IndexError:\n",
    "        print(\"IndexError: The publisher_element list does not have enough elements\")\n",
    "        return \"\"\n",
    "    \n",
    "    except ElementClickInterceptedException:\n",
    "        print(\"N O   P U B L I S H E R\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_file_check(filename):\n",
    "    # boolean value, test if file exists\n",
    "    index_file_exists = os.path.isfile(filename)\n",
    "    \n",
    "    # checking last value of index in order to continue from last position\n",
    "    if index_file_exists:\n",
    "        with open(filename, \"r\") as index_file:\n",
    "            last_index = int(index_file.read())\n",
    "    else:\n",
    "        last_index = 0\n",
    "\n",
    "    print(f\"Output of last_index: {last_index}\")\n",
    "\n",
    "    return index_file_exists, last_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper_logger(index,current_link,section)\n",
    "    \n",
    "    if section == \"title\":\n",
    "        print(\"===============================================================\")\n",
    "        print(f\"            N E W   B O O K  S T A R T I N G:   #{index+1}\")\n",
    "        print(\"===============================================================\")\n",
    "        print(\"                      L I N K\")\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "        print(current_link)\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "        print(\"                   A C T I O N    L O G\")\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "    else if section == \"\":\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18025fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def publisher_test(publisher):\n",
    "    publisher_test = 'Fail' if publisher == '' else 'Pass'\n",
    "    \n",
    "    return publisher_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046bc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_test(synopsis_length):\n",
    "    review_5_test = 'Pass' if synopsis_length >= 8 else 'Fail'\n",
    "    \n",
    "    return review_5_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bed318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(df, settings_dict, last_index):\n",
    "    # time settings\n",
    "    synopsis_and_review_wait_amount = settings_dict[\"synopsis_and_review_wait_amount\"]\n",
    "    find_button_wait = settings_dict[\"find_button_wait\"]\n",
    "    publisher_click_wait_amount = settings_dict[\"publisher_click_wait_amount\"]\n",
    "    \n",
    "    button_element_WebDriverWait_amount = settings_dict[\"button_element_WebDriverWait_amount\"]\n",
    "    title_element_WebDriverWait_amount = settings_dict[\"title_element_WebDriverWait_amount\"]\n",
    "    synopsis_and_review_list_WebDriverWait_amount = settings_dict[\"synopsis_and_review_list_WebDriverWait_amount\"]\n",
    "    publisher_element_WebDriverWait_amount = settings_dict[\"publisher_element_WebDriverWait_amount\"]\n",
    "    \n",
    "    last_index = last_index\n",
    "    \n",
    "    # iterate over the dataframe\n",
    "    for index, row in df.iloc[last_index:].iterrows():\n",
    "        #============================================================================================================\n",
    "        # L O A D    P A G E    O N    S C R A P I N G    B R O W S E R\n",
    "        #============================================================================================================\n",
    "        driver.get(row['links'])\n",
    "        current_link = row['links']\n",
    "        \n",
    "        #============================================================================================================\n",
    "        # L O G G I N G   B E G I N S\n",
    "        #============================================================================================================\n",
    "        scraper_logger(index,current_link,section=\"title\")\n",
    "\n",
    "        #============================================================================================================\n",
    "        # S Y N O P S I S   &   R E V I E W S    -    M E A T   A N D   P O T A T O E S\n",
    "        #============================================================================================================\n",
    "        try:\n",
    "            print(f\"- [[Hard Wait]] of {synopsis_and_review_wait_amount} seconds for Synopsis and Reviews to load....\")\n",
    "            time.sleep(synopsis_and_review_wait_amount)\n",
    "            print(f\"- Waiting up to {synopsis_and_review_list_WebDriverWait_amount} for presence of Synopsis and Reviews element\")\n",
    "            synopsis_and_review_list = WebDriverWait(driver, synopsis_and_review_list_WebDriverWait_amount).until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'Formatted')))\n",
    "            synopsis = synopsis_and_review_list[0].text\n",
    "            synopsis_length = len(synopsis_and_review_list)\n",
    "        except TimeoutException:\n",
    "            print(f\"!!!Timed out while waiting for synopsis and review list for book {title}, moving on to next book!!!\")\n",
    "            continue\n",
    "            \n",
    "        #============================================================================================================\n",
    "        # T I T L E\n",
    "        #============================================================================================================\n",
    "        try:\n",
    "            print(f\"- Waiting up to {title_element_WebDriverWait_amount} for presence of Title element\")\n",
    "            title_element = WebDriverWait(driver, title_element_WebDriverWait_amount).until(EC.presence_of_element_located((By.CLASS_NAME, 'BookPageTitleSection__title')))\n",
    "            title = title_element.text\n",
    "        except TimeoutException:\n",
    "            print(f\"!!! Timed out while waiting for title for book {current_link}, moving on to next book !!!\")\n",
    "            continue\n",
    "\n",
    "        #============================================================================================================\n",
    "        # P U B L I S H E R\n",
    "        #============================================================================================================\n",
    "        # First, try to find and click the button\n",
    "        try:\n",
    "            clicked_button_test = book_details_and_editions_button_click(find_button_wait,button_element_WebDriverWait_amount,publisher_click_wait_amount)\n",
    "\n",
    "            # run the get_publisher_text function for 1st time\n",
    "            print(\"- Looking for publisher...\")\n",
    "            publisher = get_publisher_text(publisher_element_WebDriverWait_amount)\n",
    "\n",
    "        except (NoSuchElementException):\n",
    "            find_button_test = \"Fail\"\n",
    "            clicked_button_test = \"Fail\"\n",
    "            print(\"!!! Button not found !!!\")\n",
    "            try:\n",
    "                print(\"- Trying to click one last time\")\n",
    "                clicked_button_test = book_details_and_editions_button_click(find_button_wait,button_element_WebDriverWait_amount,publisher_click_wait_amount)\n",
    "                print(\"- Trying to get publisher one last time\")\n",
    "                publisher = get_publisher_text(publisher_element_WebDriverWait_amount)\n",
    "                find_button_test = \"Pass\"\n",
    "            except:\n",
    "                print(\"- Didn't Find Element\")\n",
    "                publisher=\"\"\n",
    "                find_button_test = \"Fail\"\n",
    "                clicked_button_test = \"Fail\"\n",
    "        except (ElementNotInteractableException, ElementClickInterceptedException):\n",
    "            print(\"!!! Button Not Clickable or Overlay is in the way !!!\")\n",
    "            find_button_test = \"Pass\"\n",
    "            clicked_button_test = \"Fail\"\n",
    "            try:\n",
    "                print(\"- Trying to click one last time\")\n",
    "                clicked_button_test = book_details_and_editions_button_click(find_button_wait,button_element_WebDriverWait_amount,publisher_click_wait_amount)\n",
    "                print(\"- Trying to get publisher one last time\")\n",
    "                publisher = get_publisher_text(publisher_element_WebDriverWait_amount)\n",
    "                find_button_test = \"Pass\"\n",
    "            except(ElementNotInteractableException, ElementClickInterceptedException):\n",
    "                print(\"!!! Button STILL Not Clickable or Overlay is in the way !!!\")\n",
    "                publisher=\"\"\n",
    "                find_button_test = \"Fail\"\n",
    "                clicked_button_test = \"Fail\"\n",
    "            except:\n",
    "                publisher=\"\"\n",
    "                find_button_test = \"Fail\"\n",
    "                clicked_button_test = \"Fail\"\n",
    "    #============================================================================================================\n",
    "    # B A S I C   M E T A D A T A   S E C T I O N\n",
    "    #============================================================================================================\n",
    "    try:\n",
    "        page_count_element = driver.find_element_by_css_selector('p[data-testid=\"pagesFormat\"]')\n",
    "        page_count = page_count_element.text\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        page_count = \"\"\n",
    "    \n",
    "    try:\n",
    "        year_element = driver.find_element_by_css_selector('p[data-testid=\"publicationInfo\"]')\n",
    "        year = year_element.text\n",
    "    except NoSuchElementException:\n",
    "        year = \"\"\n",
    "    \n",
    "    try:\n",
    "        review_count_element = driver.find_element_by_css_selector('span[data-testid=\"reviewsCount\"]')\n",
    "        review_count = review_count_element.text\n",
    "        \n",
    "        # converting string to interger with RegEx\n",
    "        review_count_match = re.search(r'\\d+', review_count)\n",
    "        if review_count_match:\n",
    "            review_count = int(review_count_match.group())\n",
    "        else:\n",
    "            review_count = 0\n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        review_count = 0\n",
    "\n",
    "    try:\n",
    "        rating_count_element = driver.find_element_by_css_selector('span[data-testid=\"ratingsCount\"]')\n",
    "        rating_count = rating_count_element.text\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        rating_count = \"\"\n",
    "    \n",
    "    try:\n",
    "        rating_element = driver.find_element_by_class_name('RatingStatistics__rating')    \n",
    "        rating = rating_element.text\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        rating = \"\"\n",
    "    \n",
    "    try:\n",
    "        genre_class_element = driver.find_element_by_class_name('BookPageMetadataSection__genres')\n",
    "        genres_text_element = genre_class_element.find_elements_by_css_selector('.BookPageMetadataSection__genreButton .Button__labelItem')\n",
    "        genre = genres_text_element[0].text\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        genre = \"\"\n",
    "    \n",
    "    try:\n",
    "        author_element = driver.find_element_by_class_name('ContributorLink__name')\n",
    "        author = author_element.text\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        author = \"\"\n",
    "        \n",
    "    # create a list to hold current row with book metadata\n",
    "    \n",
    "    book_reviews = [title, synopsis, page_count, year, review_count, rating, rating_count, genre, author, publisher]\n",
    "\n",
    "    #============================================================================================================\n",
    "    # D A T A F R A M E   S E C T I O N\n",
    "    #============================================================================================================\n",
    "    # current row in DataFrame. create these columns\n",
    "    # and add book information to current dataframe row\n",
    "    df.at[index, 'title'] = title\n",
    "    df.at[index, 'synopsis'] = synopsis\n",
    "    df.at[index, 'page_count'] = page_count\n",
    "    df.at[index, 'year'] = year\n",
    "    df.at[index, 'review_count'] = review_count\n",
    "    df.at[index, 'rating'] = rating\n",
    "    df.at[index, 'rating_count'] = rating_count\n",
    "    df.at[index, 'genre'] = genre\n",
    "    df.at[index, 'author'] = author\n",
    "    df.at[index, 'publisher'] = publisher\n",
    "\n",
    "    # ==================================================================\n",
    "    # R E V I E W S\n",
    "    # ==================================================================\n",
    "    # iterating 5 times for reviews offset by 3 \n",
    "    # list of elements \"synopsis_and_review_list\" has synopsis\n",
    "    # and reviews\n",
    "    \n",
    "    # set this to the maximum number of reviews you want to capture\n",
    "    max_reviews = 5  \n",
    "    \n",
    "    # index 0 has synopsis, index 1 & 2 are blank, 3-7 contain reviews\n",
    "    review_index = 3 \n",
    "    \n",
    "    for i in range(max_reviews):\n",
    "        if review_index < synopsis_length:\n",
    "            # saving current review to temporary list\n",
    "            book_reviews.append(synopsis_and_review_list[review_index].text)\n",
    "            review_index += 1\n",
    "        else:\n",
    "            book_reviews.append(\"no_review\")\n",
    "    # ==================================================================\n",
    "    # T I M E   S T A M P\n",
    "    # ==================================================================\n",
    "    \n",
    "    # assign the current datetime for each row in the loop\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    \n",
    "    # ==================================================================\n",
    "    # L O G G G I N G   C O N T I N U E S\n",
    "    # ==================================================================\n",
    "    \n",
    "    # T E S T   D E F I N I T I O N S\n",
    "    # ------------------------------------------------------------------\n",
    "    publisher_test = \n",
    "    review_5_test = \n",
    "    \n",
    "    #============================================================================================================\n",
    "    # L O G G I N G   C O N T I N U E S\n",
    "    #============================================================================================================\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(\"                      T I T L E\")\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(f\"{title}\")\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(f\"5 Review Test:{review_5_test}\")\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(f\"Clicked Button Test:{clicked_button_test}\")\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(f\"Publisher Found Test:{publisher_test}\")\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(f\"TIME STAMP:{current_datetime}\")\n",
    "    print(\"---------------------------------------------------------------\\n\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # ==================================================================\n",
    "    # F I N A L  O U T P U T   D A T A F R A M E   C O L U M N S\n",
    "    # ==================================================================\n",
    "    df.at[index, 'link'] = current_link\n",
    "    df.at[index, 'scraped_at'] = current_datetime\n",
    "    \n",
    "    # ==================================================================\n",
    "    # F I N A L   C S V   O U T P U T   F I L E  A P P E N D\n",
    "    # ==================================================================\n",
    "    book_reviews.append(current_link)\n",
    "    book_reviews.append(current_datetime)\n",
    "    \n",
    "    # ==================================================================\n",
    "    # S A V I N G   D A T A   A F T E R   E A C H   I T E R A T I O N\n",
    "    # ==================================================================\n",
    "    with open(output_filename, \"a\", newline='', encoding='utf-8') as reviews_file:\n",
    "        csv_writer = csv.writer(reviews_file)\n",
    "        \n",
    "        if not reviews_file_exists:\n",
    "            csv_writer.writerow(['Book Name','Synopsis', 'page_count', 'year', 'review_count', 'rating', 'rating_count', 'genre', 'author', 'publisher', 'Review 1', 'Review 2', 'Review 3', 'Review 4', 'Review 5','Link','scraped_at'])\n",
    "            reviews_file_exists = True\n",
    "            \n",
    "        # Actual Saving of the data to csv\n",
    "        csv_writer.writerow(book_reviews)\n",
    "\n",
    "    # ==================================================================\n",
    "    # S A V I N G   P L A C E   A F T E R   E A C H   I T E R A T I O N\n",
    "    # ==================================================================\n",
    "    \n",
    "    # save place of index to file for resuming later\n",
    "    with open(\"index.txt\", \"w\") as index_file:\n",
    "        index_file.write(str(index + 1))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "154b637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_goodreads_book_dataset(df, output_filename, settings_dict, index_filename = \"index.txt\"):\n",
    "    # Starting scraper browser.\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    # Tests to check if file names exist.\n",
    "    reviews_file_exists = os.path.isfile(output_filename)\n",
    "    index_file_exits, last_index = index_file_check(index_filename)\n",
    "     \n",
    "    # Running scraper loop function.\n",
    "    df = scraper(df,\n",
    "                 output_filename,\n",
    "                 settings_dict,\n",
    "                 last_index\n",
    "                )\n",
    "    \n",
    "    # Wrapping up!\n",
    "    # -----------\n",
    "    \n",
    "    # Scraper has finished iterating DataFrame. Closing scraper browser.\n",
    "    driver.quit()\n",
    "\n",
    "    # Closing files in use.\n",
    "    if not reviews_file_exists:\n",
    "        open(output_filename, \"a\", newline='', encoding='utf-8').close()\n",
    "\n",
    "    # Closing files in use.\n",
    "    if not index_file_exists:\n",
    "        open(\"index.txt\", \"a\").close()\n",
    "\n",
    "    # In case scraper runs correctly then there is no need for index file to resume.\n",
    "    if os.path.isfile(\"index.txt\"):\n",
    "        os.remove(\"index.txt\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b7fbe",
   "metadata": {},
   "source": [
    "# Run GoodReads Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1efe31",
   "metadata": {},
   "source": [
    "#### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc45cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name input & output files\n",
    "input_filename = \"final_links.txt\"\n",
    "output_filename = \"weekend_dataset.csv\"\n",
    "settings_filename = \"settings.json\"\n",
    "\n",
    "# Load settings from file\n",
    "time_settings_dict = load_settings(settings_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f9240c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update settings\n",
    "# ---------------\n",
    "\n",
    "# hard waits\n",
    "time_settings_dict[\"synopsis_and_review_wait_amount\"] = 4\n",
    "# next 2 settings could double, if failure occurs\n",
    "time_settings_dict[\"find_button_wait\"] = 2\n",
    "time_settings_dict[\"publisher_click_wait_amount\"] = 2\n",
    "\n",
    "# soft waits\n",
    "time_settings_dict[\"button_element_WebDriverWait_amount\"] = 20\n",
    "time_settings_dict[\"title_element_WebDriverWait_amount\"] = 20\n",
    "time_settings_dict[\"synopsis_and_review_list_WebDriverWait_amount\"] = 20\n",
    "time_settings_dict[\"publisher_element_WebDriverWait_amount\"] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99287570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save settings to file\n",
    "save_settings(time_settings_dict, settings_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85bed59",
   "metadata": {},
   "source": [
    "### Actual Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce8770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire links to scrape\n",
    "df = text_file_to_dataframe(input_filename)\n",
    "\n",
    "# run goodreads scraper function\n",
    "df = get_goodreads_book_dataset(df, output_filename, settings_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
