{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe50ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import codecs\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "    \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aca2a595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_file_to_dataframe(filename):\n",
    "    # Check if the text file exists\n",
    "    if os.path.exists(filename):\n",
    "        \n",
    "        # Read the text file and create a list of lines\n",
    "        with open(filename, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            content = [line.strip() for line in lines]\n",
    "\n",
    "        # Create a DataFrame from the list\n",
    "        df = pd.DataFrame(content, columns=['links'])\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        print(f\"{filename} does not exist.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80e93db",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = \"links.txt\"\n",
    "df = text_file_to_dataframe(input_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dde02d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.goodreads.com/book/show/13771831-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.goodreads.com/book/show/28111953-j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.goodreads.com/book/show/24612758-m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               links\n",
       "0  https://www.goodreads.com/book/show/13771831-b...\n",
       "1  https://www.goodreads.com/book/show/28111953-j...\n",
       "2  https://www.goodreads.com/book/show/24612758-m..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2625f63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "# S C R A P I N G   B R O W S E R\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.goodreads.com/book/show/13771831-breaking-news?from_search=true&from_srp=true&qid=mipV5pB2vA&rank=1')\n",
    "\n",
    "try:\n",
    "    synopsis_and_review_list = WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'Formatted')))\n",
    "    print(len(synopsis_and_review_list))\n",
    "except TimeoutException:\n",
    "    print(f\"Timed out while waiting for synopsis and review list for book {title}, moving on to next book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2cedd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(synopsis_and_review_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ba38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Printing synopsis_and_review_list elements:\")\n",
    "for elem in synopsis_and_review_list:\n",
    "    print(elem.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd33eb0",
   "metadata": {},
   "source": [
    "    The purpose of the code: This should be a brief description of what the code does. For example: \"This code uses Selenium to extract book metadata from Goodreads webpages and appends it to a CSV file. If there are more than 5 reviews for a book, it also appends each review to the CSV file as a separate column.\"\n",
    "\n",
    "    Input parameters: If the code takes any input parameters, these should be documented in the docstring. For example: \"This function takes a Pandas DataFrame as input, where each row contains a link to a Goodreads book page.\"\n",
    "\n",
    "    Output: If the code produces any output or modifies any files, this should be documented in the docstring. For example: \"This function writes book metadata to a CSV file called 'reviews.csv' and creates an index file called 'index.txt' to keep track of which rows have already been processed.\"\n",
    "\n",
    "    Exceptions: If the code raises any exceptions, these should be documented in the docstring along with an explanation of what causes them. For example: \"This function may raise a NoSuchElementException if it is unable to find a required element on a Goodreads book page.\"\n",
    "\n",
    "    Dependencies: If the code depends on any external libraries or packages, these should be documented in the docstring. For example: \"This code uses the Selenium WebDriver library to scrape data from Goodreads webpages.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a460bf88",
   "metadata": {},
   "source": [
    "```python\n",
    "\"\"\"\n",
    "This function uses the Selenium WebDriver library to scrape book metadata from Goodreads webpages and appends it to a CSV file. If there are more than 5 reviews for a book, it also appends each review to the CSV file as a separate column.\n",
    "\n",
    "Input:\n",
    "- df: Pandas DataFrame containing book metadata, including a link to each book's Goodreads page.\n",
    "\n",
    "Output:\n",
    "- None\n",
    "\n",
    "Exceptions:\n",
    "- This function may raise a NoSuchElementException if it is unable to find a required element on a Goodreads book page.\n",
    "\n",
    "Dependencies:\n",
    "- Selenium WebDriver library\n",
    "- ChromeDriver executable (version X.XX) corresponding to the installed version of the Google Chrome web browser.\n",
    "\n",
    "Usage:\n",
    "- Before running this function, ensure that the ChromeDriver executable is in the system PATH and that the Google Chrome web browser is installed.\n",
    "- To run the function, pass a Pandas DataFrame containing book metadata as the input parameter, like this:\n",
    "  scrape_goodreads_data(df)\n",
    "\n",
    "This function loads each Goodreads book page using the ChromeDriver web browser and extracts metadata elements such as page count, publication year, number of reviews, average rating, rating count, genre, and author name. It then writes this metadata to a CSV file called \"reviews.csv\" and creates an index file called \"index.txt\" to keep track of which rows have already been processed. If there are more than 5 reviews for a book, it also extracts each review and appends it to the CSV file as a separate column.\n",
    "\n",
    "Note that the function requires the ChromeDriver executable to be installed and added to the system PATH. The version of the ChromeDriver executable should correspond to the installed version of the Google Chrome web browser. This function may raise a NoSuchElementException if it is unable to find a required element on a Goodreads book page.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8db3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selenium_book_scraper():\n",
    "    '''\n",
    "    This function iterates through a list of links in each row of a dataframe. \n",
    "    It uses the link to use Selenium to extract elements in a Goodreads webpage \n",
    "    containing book metadata, which represents each row. It will append all \n",
    "    metadata to a list that is written to a csv, creates a column in the current \n",
    "    row and adds the value from each metadata variable, and prints each variable.  \n",
    "    If more than or equal to 5 reviews exists for for the book it will iterate 5 \n",
    "    times and append each review as a column. It will iterate through a list of \n",
    "    elements in the webpage called 'synopsis_and_review_list'. It skips the first \n",
    "    3 items in the list, because index 0 contains the synopsis, and index  1 & 2 \n",
    "    are blank.  Index 3 to 7 contain reviews 1 through 5.\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    This function iterates through a list of links in each row of a dataframe, \n",
    "    uses the link to extract elements in a Goodreads webpage \n",
    "    containing book metadata, and appends all metadata to a \n",
    "    list that is written to a CSV. It also creates a column in \n",
    "    the current row and adds the value from each metadata \n",
    "    variable, and prints each variable.\n",
    "\n",
    "    If there are more than or equal to 5 reviews for the book, \n",
    "    the code iterates 5 times and appends each review as a column. \n",
    "    It iterates through a list of elements in the webpage called \n",
    "    synopsis_and_review_list, skips the first 3 items in the list \n",
    "    (because index 0 contains the synopsis, and index 1 & 2 are blank), \n",
    "    and appends each review to book_reviews.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "187eb718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8852b91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of last_index\n",
      "0\n",
      "Ouput of index\n",
      "0\n",
      "Ouput of row\n",
      "links    https://www.goodreads.com/book/show/13771831-b...\n",
      "Name: 0, dtype: object\n",
      "Ouput of title\n",
      "The Godmothers #5\n",
      "Breaking News\n",
      "Assigning synopsis_and_review_list\n",
      "The variable length of book 1 = \n",
      "3\n",
      "Output of synopsis_length\n",
      "3\n",
      "Ouput of page_count\n",
      "272 pages, Paperback\n",
      "Ouput of year\n",
      "First published January 1, 2012\n",
      "Ouput of review_count\n",
      "131 reviews\n",
      "Ouput of RegEx: review_count\n",
      "131\n",
      "Ouput of rating_count\n",
      "1,649 ratings\n",
      "Ouput of rating\n",
      "4.17\n",
      "Ouput of genre\n",
      "Romance\n",
      "Ouput of author\n",
      "Fern Michaels\n",
      "Book 0:\n",
      "The Godmothers #5\n",
      "Breaking News\n",
      "==============\n",
      "272 pages, Paperback\n",
      "\n",
      "\n",
      "==============\n",
      "First published January 1, 2012\n",
      "\n",
      "\n",
      "==============\n",
      "Total Reviews: \n",
      "131\n",
      "\n",
      "\n",
      "==============\n",
      "4.17\n",
      "\n",
      "\n",
      "==============\n",
      "1,649 ratings\n",
      "\n",
      "\n",
      "==============\n",
      "Romance\n",
      "\n",
      "\n",
      "==============\n",
      "Fern Michaels\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# S C R A P I N G   B R O W S E R\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the files for writing\n",
    "reviews_file = open(\"reviews.csv\", \"a\", newline='', encoding='utf-8')\n",
    "csv_writer = csv.writer(reviews_file)\n",
    "\n",
    "if not reviews_file_exists:\n",
    "    csv_writer.writerow(['Book Name','page_count','year','review_count','rating','rating_count','genre','author','Review 1', 'Review 2', 'Review 3', 'Review 4', 'Review 5'])\n",
    "\n",
    "if index_file_exists:\n",
    "    index_file = open(\"index.txt\", \"r\")\n",
    "    last_index = int(index_file.read())\n",
    "    index_file.close()\n",
    "else:\n",
    "    last_index = 0\n",
    "\n",
    "print(\"Output of last_index\")\n",
    "print(last_index)\n",
    "\n",
    "# Iterate over the dataframe\n",
    "for index, row in df.iloc[last_index:].iterrows():\n",
    "    print(\"Ouput of index\")\n",
    "    print(index)\n",
    "    \n",
    "    print(\"Ouput of row\")\n",
    "    print(row)\n",
    "\n",
    "    #============================================================================================================\n",
    "    # L O A D    P A G E    O N    S C R A P I N G    B R O W S E R\n",
    "    #============================================================================================================\n",
    "    driver.get(row['links'])\n",
    "    title_element = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CLASS_NAME, 'BookPageTitleSection__title')))\n",
    "    title = title_element.text\n",
    "    \n",
    "    print(\"Ouput of title\")\n",
    "    print(title)\n",
    "    #============================================================================================================\n",
    "    # D E F I N I T I O N    S E C T I O N\n",
    "    #============================================================================================================\n",
    "    try:\n",
    "        print(\"Assigning synopsis_and_review_list\")\n",
    "        synopsis_and_review_list = WebDriverWait(driver, 30).until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'Formatted')))\n",
    "        \n",
    "        print(f\"The variable length of book {index+1} = \")\n",
    "        print(len(synopsis_and_review_list))\n",
    "        synopsis_length = len(synopsis_and_review_list)\n",
    "        print(\"Output of synopsis_length\")\n",
    "        print(synopsis_length)\n",
    "    except TimeoutException:\n",
    "        print(f\"Timed out while waiting for synopsis and review list for book {title}, moving on to next book\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        page_count_element = driver.find_element_by_css_selector('p[data-testid=\"pagesFormat\"]')\n",
    "        page_count = page_count_element.text\n",
    "        \n",
    "        print(\"Ouput of page_count\")\n",
    "        print(page_count)\n",
    "    except NoSuchElementException:\n",
    "        page_count = \"\"\n",
    "    \n",
    "    try:\n",
    "        year_element = driver.find_element_by_css_selector('p[data-testid=\"publicationInfo\"]')\n",
    "        year = year_element.text\n",
    "        \n",
    "        print(\"Ouput of year\")\n",
    "        print(year)\n",
    "    except NoSuchElementException:\n",
    "        year = \"\"\n",
    "    \n",
    "    try:\n",
    "        review_count_element = driver.find_element_by_css_selector('span[data-testid=\"reviewsCount\"]')\n",
    "        review_count = review_count_element.text\n",
    "        \n",
    "        print(\"Ouput of review_count\")\n",
    "        print(review_count)\n",
    "        \n",
    "        # converting string to interger with RegEx\n",
    "        review_count_match = re.search(r'\\d+', review_count)\n",
    "        if review_count_match:\n",
    "            review_count = int(review_count_match.group())\n",
    "            print(\"Ouput of RegEx: review_count\")\n",
    "            print(review_count)\n",
    "        else:\n",
    "            review_count = 0\n",
    "            print(\"Ouput of No_RegEx: review_count\")\n",
    "            print(review_count)\n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        review_count = 0\n",
    "        print(\"Ouput of No_Count: review_count\")\n",
    "        print(review_count)\n",
    "    \n",
    "    try:\n",
    "        rating_count_element = driver.find_element_by_css_selector('span[data-testid=\"ratingsCount\"]')\n",
    "        rating_count = rating_count_element.text\n",
    "        print(\"Ouput of rating_count\")\n",
    "        print(rating_count)\n",
    "    except NoSuchElementException:\n",
    "        rating_count = \"\"\n",
    "    \n",
    "    try:\n",
    "        rating_element = driver.find_element_by_class_name('RatingStatistics__rating')    \n",
    "        rating = rating_element.text\n",
    "        print(\"Ouput of rating\")\n",
    "        print(rating)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        rating = \"\"\n",
    "    \n",
    "    try:\n",
    "        genre_class_element = driver.find_element_by_class_name('BookPageMetadataSection__genres')\n",
    "        genres_text_element = genre_class_element.find_elements_by_css_selector('.BookPageMetadataSection__genreButton .Button__labelItem')\n",
    "        genre = genres_text_element[0].text\n",
    "        print(\"Ouput of genre\")\n",
    "        print(genre)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        genre = \"\"\n",
    "    \n",
    "    try:\n",
    "        author_element = driver.find_element_by_class_name('ContributorLink__name')\n",
    "        author = author_element.text\n",
    "        print(\"Ouput of author\")\n",
    "        print(author)\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        author = \"\"\n",
    "        \n",
    "    book_reviews = [title]\n",
    "    \n",
    "    book_reviews.append(page_count)\n",
    "    book_reviews.append(year)\n",
    "    book_reviews.append(review_count)\n",
    "    book_reviews.append(rating)\n",
    "    book_reviews.append(rating_count)\n",
    "    book_reviews.append(genre)\n",
    "    book_reviews.append(author)\n",
    "\n",
    "    # Write the reviews to the CSV file\n",
    "    csv_writer.writerow(book_reviews)\n",
    "    \n",
    "    # current row in DataFrame. create these columns\n",
    "    # and add book information to current dataframe row\n",
    "    row['page_count'] = page_count\n",
    "    row['year'] = year\n",
    "    row['review_count'] = review_count\n",
    "    row['rating'] = rating\n",
    "    row['rating_count'] = rating_count\n",
    "    row['genre'] = genre\n",
    "    row['author'] = author\n",
    "    \n",
    "    # =====================\n",
    "    # T E S T   P R I N T\n",
    "    # =====================\n",
    "    print(f\"Book {index}:\")\n",
    "    print(title)\n",
    "    print(\"==============\")\n",
    "    print(page_count)\n",
    "    print(\"\\n\")\n",
    "    print(\"==============\")\n",
    "    print(year)\n",
    "    print(\"\\n\")\n",
    "    print(\"==============\")\n",
    "    print(\"Total Reviews: \")\n",
    "    print(review_count)\n",
    "    print(\"\\n\")\n",
    "    print(\"==============\")\n",
    "    print(rating)\n",
    "    print(\"\\n\")\n",
    "    print(\"==============\")\n",
    "    print(rating_count)\n",
    "    print(\"\\n\")\n",
    "    print(\"==============\")\n",
    "    print(genre)\n",
    "    print(\"\\n\")\n",
    "    print(\"==============\")\n",
    "    print(author)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    if synopsis_length >= 8:\n",
    "        for i in range(5):\n",
    "            \n",
    "            print(f\"Review {i+1}\")\n",
    "            print(\"==============\")\n",
    "            print(synopsis_and_review_list[i+3].text)\n",
    "            \n",
    "            # backup text file\n",
    "            book_reviews.append(synopsis_and_review_list[i+3].text)\n",
    "            \n",
    "        # Write the reviews to the CSV file\n",
    "        csv_writer.writerow(book_reviews)\n",
    "        \n",
    "        # Write the index to the file\n",
    "        with open(\"index.txt\", \"w\") as index_file:\n",
    "            index_file.write(str(index+1))\n",
    "\n",
    "# Close the files\n",
    "reviews_file.close()\n",
    "\n",
    "# Write the index to the file after the loop has completed\n",
    "with open(\"index.txt\", \"w\") as index_file:\n",
    "    index_file.write(str(index))\n",
    "\n",
    "# Create the files if they didn't exist\n",
    "if not reviews_file_exists:\n",
    "    open(\"reviews.csv\", \"a\", newline='', encoding='utf-8').close()\n",
    "\n",
    "if not index_file_exists:\n",
    "    open(\"index.txt\", \"a\").close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0148b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
