{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "182142d6-a650-4646-8c05-65c993a9f248",
   "metadata": {},
   "source": [
    "# Finding the Next Bestseller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77619ae-9700-418c-9fe2-3b09b44225d0",
   "metadata": {},
   "source": [
    "## Project Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15381bbd-f106-4cec-b01b-b731878b296c",
   "metadata": {},
   "source": [
    "Using publicly available data fom Goodreads, Wikipedia, and Amazon, this project aims to acquire, explore, and analyze information about books - their popularity via online reviews and ratings, as well as keywords, author name, publisher, and more - to programmatically determine which factors lead to a book landing on the New York Times Bestseller list. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b820db-e363-4342-b7f3-9093ee45dbca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Project Creators:\n",
    "\n",
    "- [Brandon Navarrete](https://github.com/brandontnavarrete)\n",
    "- [Magdalena Rahn](https://github.com/MagdalenaRahn)\n",
    "- [Manuel Parra](https://github.com/manuelparra1)\n",
    "- [Shawn Brown](https://github.com/shawn-brown12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce4c9a9-4454-46cf-b36f-d7eef74b68cb",
   "metadata": {},
   "source": [
    "## Setting up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f2b23cd-8785-4311-b8e6-6ae4b1179d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from xgboost import XGBClassifier as xgb\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import prepare as prep\n",
    "import explore as ex\n",
    "import model as m\n",
    "\n",
    "seed = 42\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799400e-8d97-43f2-838c-6d7b4acd61ce",
   "metadata": {},
   "source": [
    "## Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653ed402-8bf2-4224-b37e-68642e992e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function sequentially runs each function from within the prepare.py file \n",
    "# in order to gather and clean the data, as well as creating our target variable and getting\n",
    "# the sentiment analysis of the book summaries\n",
    "df = prep.prep_data('all_books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c7ad53-19d7-4966-9deb-0b64146fb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick peak at our dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace63519-6fe9-46c0-991b-2b7b570c20ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the above df into a new csv file, so that we don't have to run it through again unless we add to our dataset.\n",
    "df.to_csv('final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b819e7a-db84-45dd-a8fc-dc40234b214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling the data from the csv saved above\n",
    "df = pd.read_csv('final_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab206ef-b9e9-4c33-a641-46a4b8510330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a peak to compare the dataframe above and confirm they are the same\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa089e0-42a8-4a3a-bd0b-5cc4307e01a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed5323f-a643-4c3c-a86f-1d41de5b2f02",
   "metadata": {},
   "source": [
    "### Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334d0dab-8791-4585-8797-17d37604dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9954ae2c-38da-43cf-b20d-a02540297385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic information about our data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85a271-0550-425d-a625-4e03408c600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a look at what genres we have\n",
    "df['genre'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e6781-bcee-453e-b9eb-304e8cdaca62",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5aa1a-9e64-4353-8c91-378f3cc38ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting our data into train and test subsets\n",
    "train, test = ex.split(df, 'successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d7e73c-a7d4-4a72-b10b-c913a94bd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the size of our subsets\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f9cac7-79cd-4876-82c2-df70379ceae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace717fb-0db9-44a4-bdec-64156cc5b902",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Acquisition and Preparation Takeaways</b>\n",
    "    \n",
    "- Initially, we had over 4000 books in our book list, as well at the dataset of NYT bestsellers comprising of over 1000 books. This included 11 features of each of those books. From the actual gathered data, we had around 3800 books, around 160 of which were bestsellers.\n",
    "    \n",
    "- For any null values in our data, we either imputed or dropped them, depending on what feature was null. We ended up dropping a number of rows where the summary was empty, while we manually imputed missing book titles, lengths, and publishing years, as those encompassed multiple of our bestsellers.\n",
    "    \n",
    "- We dropped any books not in English, as well as any duplicated books. We also used the Goodreads data on the first available hardcover edition, where possible.\n",
    "    \n",
    "- During our cleaning phase, we engineered a number of columns to our dataframe, including our target column, cleaned and lemmatized version, of the summary, and several values created during our dsentiment analysis of the summary.\n",
    "    \n",
    "- Our final dataframe had the following columns:\n",
    "    - `title`, `summary`, `year_published`, `author`, `review_count`, `number_of_ratings`, `length`, `genre`, `rating`, `reviews`, `cleaned_title`, `cleaned_summary`, `target`, `lemmatized_summary`, `neg`, `neutral`, `pos`, `compound`, `sentiment`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2f0636-945a-454f-86a1-2c9db5c88be8",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c630b80c-6267-4ac1-a101-48b293ab115f",
   "metadata": {},
   "source": [
    "### Which words/ngrams appear more often in summaries with a positive sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f77a7-e7ac-4379-be8e-a235e75e2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to most common single words\n",
    "best_words = ex.uni_id_best_seller(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab668c0c-0a81-49af-97d5-94b45523a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show most common bigrams in bestsellers\n",
    "ex.best_bigrams(best_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de40ccd-f935-4eb7-837a-7ae7ad5b40c3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Takeaways:</b> \n",
    "        \n",
    "Looking at bi grams, we see:\n",
    "\n",
    "----------------------------------------    \n",
    "\n",
    "- 'bestselling author': Either the summary referencing a past bestseller or the fact that the book *is* a bestseller.\n",
    "    \n",
    "- 'bouny hunter': Perhaps books with bounty hunter characters are popular?\n",
    "\n",
    "- There were a lot of character names, like: (eve, dallas(in death series)) or (armand, gamache(still life)(location three pine))  \n",
    "\n",
    "- Sûreté du Québec is the provincial police service for the province of Quebec, in Canada.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc5b67-d803-4981-95d8-6e5850521975",
   "metadata": {},
   "source": [
    "### Which words/ngrams appear more often in summaries with a negative sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63aafda-dda0-4a13-a77c-5cd06b4c2142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check the frequency of top words, bigrams, and trigrams in summaries with negative sentiment\n",
    "ex.explore_question_2(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d264c0-19e6-41fe-8449-6eea639066cd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Takeaways</b>\n",
    "    \n",
    "Unigrams: \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c715492d-275b-4c99-a163-ffca96a726fd",
   "metadata": {},
   "source": [
    "### Is there a relationship between the length of a book and its appearing on the NYT Best Seller list?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7595e33b-cf69-447d-95f4-0c7034561a36",
   "metadata": {},
   "source": [
    "Exploring length and successs:\n",
    "\n",
    "$H_O$ : There is no relationship between the length of a book and its landing on the NYT Best Seller list.  \n",
    "$H_a$ : There is a relationship between the length of a book and its landing on the NYT Best Seller list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee52459-485f-4867-a50c-f3f1a61ec74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to visualize success vs book length\n",
    "ex.book_len_success(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8da1b-1d14-44be-aa97-78292191ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining two groups for chi squared function\n",
    "a = train['length']\n",
    "b = train['year_published']\n",
    "#calling the chi squared function\n",
    "ex.chi_sq(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c688648c-85a4-4a87-b3ce-5b3f3174bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above, defining groups for the chi squared test\n",
    "r = train['length']\n",
    "s = train['successful']\n",
    "#calling the function for the chi squared test\n",
    "ex.chi_sq(r, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc4216-aaa2-4872-ad6f-1e939c6f4c14",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Takeaways</b>\n",
    "    \n",
    "There is a relationship between the length of the book (positive correlation) and the year that it was published, particularly for books not on the NYT Best Seller list, and for the train dataset. The length of the book and the year that it was published did not have a relationship for NYT Best Sellers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1da12bd-9c25-40f1-a815-4d414ec25b26",
   "metadata": {},
   "source": [
    "### What is the relationship between summary sentiment score and book length?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5615d93-22b8-45c2-b77c-bc49fe273df7",
   "metadata": {},
   "source": [
    "$H_0$ : There is no relationship between the books length and the summary's sentiment score.  \n",
    "$H_a$ : There is some kind of relationship between the book length and the summary's sentiment score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48699523-6ccb-4f0a-b7b8-bc34928521e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to call a visual created\n",
    "ex.sent_vs_len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293356ee-a550-4d72-8ed6-1edc593f76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to run a statistical test\n",
    "ex.pearsonr_report(train['length'], train['compound'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a73274-3e9e-4142-ba12-f1ee4a25f322",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Takeaways</b>\n",
    "    \n",
    "Going by the visual here we can see that, if there is a relationship here, it's pretty insignificant. After running a Pearson R statistical test on the two features, that is confirmed. We are able to reject the null hypothesis here that there isn't a relationship, but it **is** a weak relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb89271-b82f-486a-a382-9527585c44f3",
   "metadata": {},
   "source": [
    "## Exploration Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73640f25-fda6-4513-9484-4ac5dd9a3fbd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Key Takeaways</b>\n",
    "    \n",
    "- A lot of the most used words, bigrams, and trigrams had the words 'new', 'york', 'times', and 'bestseller', so on our next iteration we plan on creating a more robust set of stopwords.\n",
    "    \n",
    "- There is a weak positive correlation between book length and year published\n",
    "    \n",
    "- The book length and year published did not have a significant relationship with the success rate of a book when compared directly.\n",
    "    \n",
    "- There is weak negative relationship between the length of a book and the sentiment analysis of the book summary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0560667-b258-4245-93d2-667de10d7509",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6407907-fce3-46f6-87c5-964998b2c846",
   "metadata": {},
   "source": [
    "### Preparing the data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06db6ab-154f-42a5-9741-e2a4b9792163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to prep df for scaling and splitting by making dummies and removing uneeded categorical columns\n",
    "df = m.ready_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a979c44c-9d56-404c-848c-618ff557d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db219de-ceeb-4d99-ac75-fdec2bb04678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting df into train and test\n",
    "train, test = ex.split(df, 'successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f02a57-5fa1-476a-a891-68a3d5b894d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick shape to check the sizes\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b803738-d6b4-4834-89f5-a63f12ba24a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create our x/y subsets\n",
    "X_train, y_train, X_test, y_test = m.Xy_set(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72265dd8-30be-4d20-bf19-fa91dfcaff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick peak\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5678aef6-f434-4c11-9141-874b442fd9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to scale our numerical data\n",
    "X_train_scaled, X_test_scaled = m.scaling(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178cb895-fa6e-4969-86e6-0f7133458368",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb067f21-2a9f-4dae-b01c-7e88678506dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ef52be-2370-4dad-b5fa-2b4c5d031f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to \n",
    "y_pred = m.XGBclf(X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebb2bc8-1227-4874-ade2-35a1b6a68bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.roc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265755f8-0395-4b04-87e5-c1d234bd5cdd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Takeaways</b>\n",
    "    \n",
    "- Our baseline recall was 0% and our accuracy 95%\n",
    "    \n",
    "- Through many iterations of XGBoost models, our best model gave us a recall of 34% and an accuracy of 96%.\n",
    "    \n",
    "- Overall, while there's room for improvement, we have beaten both of our baseline metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaefc9a-1626-4e56-914e-410feeb95e45",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e86467f-66b4-4a73-93a8-6ef0d24f93ac",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44384667-9b90-4651-b6ca-154167943707",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b></b>\n",
    "    \n",
    "- Our text data for the book summaries was not helpful in this iteration of the project. \n",
    "\n",
    "- We accurately predicted 11 of the 32 bestsellers in our test dataframe, giving us a recall score of 34.3%. \n",
    "\n",
    "- Our accuracy score was 96%, only missing 8 out of over 700 books in our test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfed139-ccea-4636-95b8-41de3a375a47",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6d752e-b6b8-4380-b9b8-710b3fdf495d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b></b>\n",
    "    \n",
    "- Pay attention to the style of books written by authors whose books frequently appear on the New York Times Best Seller list.\n",
    "\n",
    "- As a publisher, make efforts to get as many Goodreads ratings as possible, as the higher the number of reader ratings on Goodreads, the higher the overall star rating score and the more likely the book was to be on the New York Times Best Seller list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eb3e43-288a-4b8d-b230-d30c3cf6601e",
   "metadata": {},
   "source": [
    "### Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac3dc0e-0031-4921-a373-e9456c2b3e7f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b></b>\n",
    "    \n",
    "For future iterations of this project:\n",
    "- Obtain the publishers of each book and multiple Goodreads user reviews for each book. \n",
    "\n",
    "    - This would be used for natural language processing (NLP) modeling on the text of the reviews. Feature engineering review sentiment scores would be another option.\n",
    "\n",
    "    - Information on publishers would, likewise, be used as a feature in determining what contributes to a book being a NYT Best Seller title.\n",
    "    \n",
    "- Add a selection of new stopwords to try while cleaning the text data\n",
    "\n",
    "- Model *seemed* to work better with a small selection of children's books, we would like to add those back in and find out why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece7e444-a4c1-4103-9ca8-8c969b8c7e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
